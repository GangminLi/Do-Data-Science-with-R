<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.2 Titanic prediciton with a Random Forest | 08-Random-Forest.utf8</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="1.2 Titanic prediciton with a Random Forest | 08-Random-Forest.utf8" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.2 Titanic prediciton with a Random Forest | 08-Random-Forest.utf8" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="steps-to-build-a-random-forest.html"/>
<link rel="next" href="summary.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Authoring Books with R Markdown</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="titiannic-prediction-with-random-forest.html"><a href="titiannic-prediction-with-random-forest.html"><i class="fa fa-check"></i><b>1</b> Titiannic Prediction with Random Forest</a><ul>
<li class="chapter" data-level="1.1" data-path="steps-to-build-a-random-forest.html"><a href="steps-to-build-a-random-forest.html"><i class="fa fa-check"></i><b>1.1</b> Steps to Build a Random Forest</a></li>
<li class="chapter" data-level="1.2" data-path="titanic-prediciton-with-a-random-forest.html"><a href="titanic-prediciton-with-a-random-forest.html"><i class="fa fa-check"></i><b>1.2</b> Titanic prediciton with a Random Forest</a><ul>
<li class="chapter" data-level="" data-path="titanic-prediciton-with-a-random-forest.html"><a href="titanic-prediciton-with-a-random-forest.html#random-forest-with-the-default-settings-on-dataset"><i class="fa fa-check"></i>Random Forest with the default settings on dataset</a></li>
<li class="chapter" data-level="" data-path="titanic-prediciton-with-a-random-forest.html"><a href="titanic-prediciton-with-a-random-forest.html#random-forest-with-more-variables"><i class="fa fa-check"></i>Random Forest with more variables</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1.3</b> Summary</a></li>
<li class="chapter" data-level="1.4" data-path="excercise-8.html"><a href="excercise-8.html"><i class="fa fa-check"></i><b>1.4</b> Excercise 8</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="titanic-prediciton-with-a-random-forest" class="section level2">
<h2><span class="header-section-number">1.2</span> Titanic prediciton with a Random Forest</h2>
<p>Let’s now look at how we can implement the random forest algorithm for our Titanic prediction.
R provides <code>'randomForest'</code> package. You can check the details of the package for full usage. We will start with direct function call with its default settings and we may change settings later. We will also use the original attributes first and then use re-engineered attributes to see if we can improve on the model.</p>
<div id="random-forest-with-the-default-settings-on-dataset" class="section level3 unnumbered">
<h3>Random Forest with the default settings on dataset</h3>
<p>The process of using <code>randomForest</code> package to build a RF model is same with the decision tree package “rpart”. Note also if a dependent (response) variable is a factor, classification is assumed, otherwise regression is assumed. So to uses randomForest, we need to convert dependent variable into factor.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="titanic-prediciton-with-a-random-forest.html#cb2-1"></a><span class="co"># convert variables into factor</span></span>
<span id="cb2-2"><a href="titanic-prediciton-with-a-random-forest.html#cb2-2"></a>train<span class="op">$</span>Survived &lt;-<span class="st"> </span><span class="kw">as.factor</span>(train<span class="op">$</span>Survived)</span>
<span id="cb2-3"><a href="titanic-prediciton-with-a-random-forest.html#cb2-3"></a><span class="co"># convert other attributes which really are categorical data but in for m of numbers</span></span>
<span id="cb2-4"><a href="titanic-prediciton-with-a-random-forest.html#cb2-4"></a>train<span class="op">$</span>Pclass &lt;-<span class="st"> </span><span class="kw">as.factor</span>(train<span class="op">$</span>Pclass)</span>
<span id="cb2-5"><a href="titanic-prediciton-with-a-random-forest.html#cb2-5"></a>train<span class="op">$</span>Group_size &lt;-<span class="st"> </span><span class="kw">as.factor</span>(train<span class="op">$</span>Group_size)</span>
<span id="cb2-6"><a href="titanic-prediciton-with-a-random-forest.html#cb2-6"></a><span class="co">#confirm types</span></span>
<span id="cb2-7"><a href="titanic-prediciton-with-a-random-forest.html#cb2-7"></a><span class="kw">sapply</span>(train, class)</span></code></pre></div>
<pre><code>##  PassengerId     Survived       Pclass          Sex          Age        SibSp 
##    &quot;integer&quot;     &quot;factor&quot;     &quot;factor&quot;     &quot;factor&quot;    &quot;numeric&quot;    &quot;integer&quot; 
##        Parch       Ticket     Embarked  HasCabinNum  Friend_size      Fare_pp 
##    &quot;integer&quot;     &quot;factor&quot;     &quot;factor&quot;     &quot;factor&quot;    &quot;integer&quot;    &quot;numeric&quot; 
##        Title         Deck Ticket_class  Family_size   Group_size    Age_group 
##     &quot;factor&quot;     &quot;factor&quot;     &quot;factor&quot;    &quot;integer&quot;     &quot;factor&quot;     &quot;factor&quot;</code></pre>
<p>Let us use the same three most related attributes: Pclass, Sex and Fare_pp in the decision tree model4. We use all default parameters of the <em>randomForest</em>.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="titanic-prediciton-with-a-random-forest.html#cb4-1"></a><span class="co"># Build the random forest model only uses pclass, sex and Fare_pp</span></span>
<span id="cb4-2"><a href="titanic-prediciton-with-a-random-forest.html#cb4-2"></a><span class="kw">set.seed</span>(<span class="dv">1234</span>) <span class="co">#for reproduction </span></span>
<span id="cb4-3"><a href="titanic-prediciton-with-a-random-forest.html#cb4-3"></a>RF_model1 &lt;-<span class="st"> </span><span class="kw">randomForest</span>(Survived <span class="op">~</span><span class="st"> </span>Sex <span class="op">+</span><span class="st"> </span>Pclass <span class="op">+</span><span class="st"> </span>Fare_pp, <span class="dt">data=</span>train, <span class="dt">importance=</span><span class="ot">TRUE</span>)</span></code></pre></div>
<p>Let us check model’s prediction accuracy.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="titanic-prediciton-with-a-random-forest.html#cb5-1"></a>RF_model1</span></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = Survived ~ Sex + Pclass + Fare_pp, data = train,      importance = TRUE) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 1
## 
##         OOB estimate of  error rate: 20.76%
## Confusion matrix:
##     0   1 class.error
## 0 504  45  0.08196721
## 1 140 202  0.40935673</code></pre>
<p>We can see that the model uses default parameters: <em>ntree</em> = 500 and <em>mtry</em> = 1. The model’s estimated accuracy is <strong>79%</strong>. It is 1 - 0.21 (OOB error).</p>
<p>Let us make a prediction on train dataset and check the accuracy.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="titanic-prediciton-with-a-random-forest.html#cb7-1"></a><span class="co"># Make your prediction using the validate dataset</span></span>
<span id="cb7-2"><a href="titanic-prediciton-with-a-random-forest.html#cb7-2"></a><span class="co">#set.seed(1234)</span></span>
<span id="cb7-3"><a href="titanic-prediciton-with-a-random-forest.html#cb7-3"></a>RF_prediction1 &lt;-<span class="st"> </span><span class="kw">predict</span>(RF_model1, train)</span>
<span id="cb7-4"><a href="titanic-prediciton-with-a-random-forest.html#cb7-4"></a><span class="co">#check up</span></span>
<span id="cb7-5"><a href="titanic-prediciton-with-a-random-forest.html#cb7-5"></a><span class="kw">confusionMatrix</span>(RF_prediction1, train<span class="op">$</span>Survived)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 518 135
##          1  31 207
##                                           
##                Accuracy : 0.8137          
##                  95% CI : (0.7865, 0.8387)
##     No Information Rate : 0.6162          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.5822          
##                                           
##  Mcnemar&#39;s Test P-Value : 1.303e-15       
##                                           
##             Sensitivity : 0.9435          
##             Specificity : 0.6053          
##          Pos Pred Value : 0.7933          
##          Neg Pred Value : 0.8697          
##              Prevalence : 0.6162          
##          Detection Rate : 0.5814          
##    Detection Prevalence : 0.7329          
##       Balanced Accuracy : 0.7744          
##                                           
##        &#39;Positive&#39; Class : 0               
## </code></pre>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="titanic-prediciton-with-a-random-forest.html#cb9-1"></a><span class="co"># Misclassification error</span></span>
<span id="cb9-2"><a href="titanic-prediciton-with-a-random-forest.html#cb9-2"></a><span class="kw">paste</span>(<span class="st">&#39;Error =&#39;</span>, <span class="kw">round</span>(<span class="kw">mean</span>(train<span class="op">$</span>Survived <span class="op">!=</span><span class="st"> </span>RF_prediction1), <span class="dv">4</span>)) </span></code></pre></div>
<pre><code>## [1] &quot;Error = 0.1863&quot;</code></pre>
<p>We can see that prediction on train dataset has achieved <strong>81.4%</strong> accuracy.
It has made 135 wrong prediction and 518 correct prediction on death. The error rate is 20.67% (accuracy is 79.33%). The prediction on survived is 31 wrong prediction out of 207 correct predictions. The error rate is about 13.03% and the accuracy is 86.97%.</p>
<p>The model has an accuracy of 79% after training, but our evaluation on the train dataset achieves 81.4%. It has increased a bit. Compare with the decision tree model4, which the the same attributes were used and the prediction accuracy on the train data was 81.48%, the accuracy is almost identical. Let us make a predciton on test dataset and submit to Kaggle to obtain an accuracy score.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="titanic-prediciton-with-a-random-forest.html#cb11-1"></a><span class="co"># produce a submit with Kaggle required format that is only two attributes: PassengerId and Survived</span></span>
<span id="cb11-2"><a href="titanic-prediciton-with-a-random-forest.html#cb11-2"></a>test<span class="op">$</span>Pclass &lt;-<span class="st"> </span><span class="kw">as.factor</span>(test<span class="op">$</span>Pclass)</span>
<span id="cb11-3"><a href="titanic-prediciton-with-a-random-forest.html#cb11-3"></a>test<span class="op">$</span>Group_size &lt;-<span class="st"> </span><span class="kw">as.factor</span>(test<span class="op">$</span>Group_size)</span>
<span id="cb11-4"><a href="titanic-prediciton-with-a-random-forest.html#cb11-4"></a></span>
<span id="cb11-5"><a href="titanic-prediciton-with-a-random-forest.html#cb11-5"></a><span class="co">#make prediction</span></span>
<span id="cb11-6"><a href="titanic-prediciton-with-a-random-forest.html#cb11-6"></a>RF_prediction &lt;-<span class="st"> </span><span class="kw">predict</span>(RF_model1, test)</span>
<span id="cb11-7"><a href="titanic-prediciton-with-a-random-forest.html#cb11-7"></a>submit &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">PassengerId =</span> test<span class="op">$</span>PassengerId, <span class="dt">Survived =</span> RF_prediction)</span>
<span id="cb11-8"><a href="titanic-prediciton-with-a-random-forest.html#cb11-8"></a><span class="co"># Write it into a file &quot;RF_Result.CSV&quot;</span></span>
<span id="cb11-9"><a href="titanic-prediciton-with-a-random-forest.html#cb11-9"></a><span class="kw">write.csv</span>(submit, <span class="dt">file =</span> <span class="st">&quot;RF_Result1.CSV&quot;</span>, <span class="dt">row.names =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<p>We can see our random forest model has scored <strong>0.76555</strong> by the Kaggle competition. It is interesting to know that the random forest model has a slight higher accuracy on the test dataset compare with the decision tree model with the same predictors. The accuracy was <strong>0.75837</strong>.</p>
<p>let us record these accuracies,</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="titanic-prediciton-with-a-random-forest.html#cb12-1"></a>RF_model1_accuracy &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">79</span>, <span class="fl">81.4</span>, <span class="fl">76.555</span>)</span></code></pre></div>
</div>
<div id="random-forest-with-more-variables" class="section level3 unnumbered">
<h3>Random Forest with more variables</h3>
<p>Now let us see if We can obtain a better model if we use more variables. Note that the <code>randomForest</code> cannot handle attribute which is not a factor and has over 53 levels.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="titanic-prediciton-with-a-random-forest.html#cb13-1"></a><span class="kw">set.seed</span>(<span class="dv">2222</span>)</span>
<span id="cb13-2"><a href="titanic-prediciton-with-a-random-forest.html#cb13-2"></a>RF_model2 &lt;-<span class="st"> </span><span class="kw">randomForest</span>(Survived <span class="op">~</span><span class="st"> </span>Pclass <span class="op">+</span><span class="st"> </span>Title <span class="op">+</span><span class="st"> </span>Sex <span class="op">+</span><span class="st"> </span>Age_group <span class="op">+</span><span class="st"> </span>Group_size <span class="op">+</span><span class="st"> </span>Ticket_class  <span class="op">+</span><span class="st"> </span>Fare_pp <span class="op">+</span><span class="st"> </span>Deck <span class="op">+</span><span class="st"> </span>HasCabinNum <span class="op">+</span><span class="st"> </span>Embarked, <span class="dt">data =</span> train, <span class="dt">importance=</span><span class="ot">TRUE</span>)</span></code></pre></div>
<p>We can assess the new model,</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="titanic-prediciton-with-a-random-forest.html#cb14-1"></a>RF_model2</span></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = Survived ~ Pclass + Title + Sex + Age_group +      Group_size + Ticket_class + Fare_pp + Deck + HasCabinNum +      Embarked, data = train, importance = TRUE) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 3
## 
##         OOB estimate of  error rate: 16.27%
## Confusion matrix:
##     0   1 class.error
## 0 496  53  0.09653916
## 1  92 250  0.26900585</code></pre>
<p>Notice that the default parameter <em>mtry</em> = 3 and ntree = 500. It means the number of variable tried at each split is now 3 and number of trees can be built is 500. The model’s estimated OOB error rate is 16%. It has a huge increase in comparison with the first model which was 21%. So the overall accuracy of the model has reached 84%.</p>
<p>Let us make a prediction on train Data to verify the model’s training accuracy.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="titanic-prediciton-with-a-random-forest.html#cb16-1"></a>RF_prediction2 &lt;-<span class="st"> </span><span class="kw">predict</span>(RF_model2, train)</span>
<span id="cb16-2"><a href="titanic-prediciton-with-a-random-forest.html#cb16-2"></a><span class="co">#check up</span></span>
<span id="cb16-3"><a href="titanic-prediciton-with-a-random-forest.html#cb16-3"></a><span class="kw">confusionMatrix</span>(RF_prediction2, train<span class="op">$</span>Survived)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 534  43
##          1  15 299
##                                           
##                Accuracy : 0.9349          
##                  95% CI : (0.9167, 0.9502)
##     No Information Rate : 0.6162          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.8602          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.0003922       
##                                           
##             Sensitivity : 0.9727          
##             Specificity : 0.8743          
##          Pos Pred Value : 0.9255          
##          Neg Pred Value : 0.9522          
##              Prevalence : 0.6162          
##          Detection Rate : 0.5993          
##    Detection Prevalence : 0.6476          
##       Balanced Accuracy : 0.9235          
##                                           
##        &#39;Positive&#39; Class : 0               
## </code></pre>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="titanic-prediciton-with-a-random-forest.html#cb18-1"></a><span class="co"># Misclassification error</span></span>
<span id="cb18-2"><a href="titanic-prediciton-with-a-random-forest.html#cb18-2"></a><span class="kw">paste</span>(<span class="st">&#39;Error =&#39;</span>, <span class="kw">round</span>(<span class="kw">mean</span>(train<span class="op">$</span>Survived <span class="op">!=</span><span class="st"> </span>RF_prediction2), <span class="dv">4</span>)) </span></code></pre></div>
<pre><code>## [1] &quot;Error = 0.0651&quot;</code></pre>
<p>We can see the accuracy on train dataset ahs reached 93.5%. The result shows that the prediction on survive has 43 wrong predictions out of 534 correct predictions, the error rate is 7.5%, and the accuracy is 92.5%. The prediction on death has 299 correct predictions and 15 wrong predictions, the error rate is 4.8%, the accuracy is 95.2%. The overall accuracy reaches <strong>93.5%</strong>. It is again higher than the model training accuracy <strong>84%</strong>.</p>
<p>It has also increased a bit comparing with the accuracy on the estimated accuracy <strong>79%</strong> and the accuracy on train dataset <strong>81.4%</strong> of the random forest RF_model1.</p>
<p>Let us make another submit to Kaggle to see if the prediction on unseen data has been improved.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="titanic-prediciton-with-a-random-forest.html#cb20-1"></a><span class="co"># produce a submit with Kaggle </span></span>
<span id="cb20-2"><a href="titanic-prediciton-with-a-random-forest.html#cb20-2"></a>test<span class="op">$</span>Pclass &lt;-<span class="st"> </span><span class="kw">as.factor</span>(test<span class="op">$</span>Pclass)</span>
<span id="cb20-3"><a href="titanic-prediciton-with-a-random-forest.html#cb20-3"></a>test<span class="op">$</span>Group_size &lt;-<span class="st"> </span><span class="kw">as.factor</span>(test<span class="op">$</span>Group_size)</span>
<span id="cb20-4"><a href="titanic-prediciton-with-a-random-forest.html#cb20-4"></a></span>
<span id="cb20-5"><a href="titanic-prediciton-with-a-random-forest.html#cb20-5"></a><span class="co">#make prediction</span></span>
<span id="cb20-6"><a href="titanic-prediciton-with-a-random-forest.html#cb20-6"></a>RF_prediction &lt;-<span class="st"> </span><span class="kw">predict</span>(RF_model2, test)</span>
<span id="cb20-7"><a href="titanic-prediciton-with-a-random-forest.html#cb20-7"></a>submit &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">PassengerId =</span> test<span class="op">$</span>PassengerId, <span class="dt">Survived =</span> RF_prediction)</span>
<span id="cb20-8"><a href="titanic-prediciton-with-a-random-forest.html#cb20-8"></a><span class="co"># Write it into a file &quot;RF_Result.CSV&quot;</span></span>
<span id="cb20-9"><a href="titanic-prediciton-with-a-random-forest.html#cb20-9"></a><span class="kw">write.csv</span>(submit, <span class="dt">file =</span> <span class="st">&quot;RF_Result2.CSV&quot;</span>, <span class="dt">row.names =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<p>Unfortunately, the feedback shows the prediction only scored 0.76794! It has improved on the RF_model1, but it is still not as good as the decision tree model3! The gap between the model estimated accuracy and the varified accuracy has increased a lot! The model’s estimated accuracy and accuracy on train dataset were 84% and 93.5% respectively!</p>
<p>let us record these various accuracy.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="titanic-prediciton-with-a-random-forest.html#cb21-1"></a>RF_model2_accuracy &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">84</span>, <span class="fl">93.5</span>, <span class="fl">76.794</span>)</span></code></pre></div>
<p>There are two possible reasons for this dramatic accuracy fall. One reason is the model was constructed by using inappropriate predictors. This includes the wrong number of the predictors and the test conditions formed by the predictor are not appropriate; a model used too many predictors can pick up outliers and noise data, so the prediction accuracy will be decreased when used for unseen data. This can be discovered by the cross validation. Another possible reason is the model’s parameter are not set to the most appropriate values. there are methods can be used to fine tune model’s parameters. Both issues and the methods for resolving issues will be discussed in the next Chapter.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="steps-to-build-a-random-forest.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="summary.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown/edit/master/inst/examples/%s",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "none"
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
