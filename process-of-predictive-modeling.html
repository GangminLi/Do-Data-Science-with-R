<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.1 Process of Predictive Modeling | 06-data-analysis.utf8</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="1.1 Process of Predictive Modeling | 06-data-analysis.utf8" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.1 Process of Predictive Modeling | 06-data-analysis.utf8" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="data-analysis.html"/>
<link rel="next" href="predictor-selection.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Authoring Books with R Markdown</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="data-analysis.html"><a href="data-analysis.html"><i class="fa fa-check"></i><b>1</b> Data Analysis</a><ul>
<li class="chapter" data-level="1.1" data-path="process-of-predictive-modeling.html"><a href="process-of-predictive-modeling.html"><i class="fa fa-check"></i><b>1.1</b> Process of Predictive Modeling</a></li>
<li class="chapter" data-level="1.2" data-path="predictor-selection.html"><a href="predictor-selection.html"><i class="fa fa-check"></i><b>1.2</b> Predictor Selection</a><ul>
<li class="chapter" data-level="1.2.1" data-path="predictor-selection.html"><a href="predictor-selection.html#attributes-correlation-analysis"><i class="fa fa-check"></i><b>1.2.1</b> Attributes Correlation Analysis</a></li>
<li class="chapter" data-level="1.2.2" data-path="predictor-selection.html"><a href="predictor-selection.html#pca-analysis"><i class="fa fa-check"></i><b>1.2.2</b> PCA Analysis</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="prediction-model-constructions.html"><a href="prediction-model-constructions.html"><i class="fa fa-check"></i><b>1.3</b> Prediction Model Constructions</a><ul>
<li class="chapter" data-level="1.3.1" data-path="prediction-model-constructions.html"><a href="prediction-model-constructions.html#math-model."><i class="fa fa-check"></i><b>1.3.1</b> Math model.</a></li>
<li class="chapter" data-level="1.3.2" data-path="prediction-model-constructions.html"><a href="prediction-model-constructions.html#rule-based-model"><i class="fa fa-check"></i><b>1.3.2</b> Rule-based model</a></li>
<li class="chapter" data-level="1.3.3" data-path="prediction-model-constructions.html"><a href="prediction-model-constructions.html#machine-learning-model"><i class="fa fa-check"></i><b>1.3.3</b> Machine Learning Model</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="prediction-with-decision-trees.html"><a href="prediction-with-decision-trees.html"><i class="fa fa-check"></i><b>1.4</b> Prediction with Decision Trees</a><ul>
<li class="chapter" data-level="1.4.1" data-path="prediction-with-decision-trees.html"><a href="prediction-with-decision-trees.html#build-a-decision-tree-in-hunts-algorithm"><i class="fa fa-check"></i><b>1.4.1</b> Build a decision tree in Hunt’s Algorithm</a></li>
<li class="chapter" data-level="1.4.2" data-path="prediction-with-decision-trees.html"><a href="prediction-with-decision-trees.html#best_split"><i class="fa fa-check"></i><b>1.4.2</b> How to Determine the Best Split Condition?</a></li>
<li class="chapter" data-level="1.4.3" data-path="prediction-with-decision-trees.html"><a href="prediction-with-decision-trees.html#the-simplest-decision-tree-for-titanic"><i class="fa fa-check"></i><b>1.4.3</b> The Simplest Decision Tree for Titanic</a></li>
<li class="chapter" data-level="1.4.4" data-path="prediction-with-decision-trees.html"><a href="prediction-with-decision-trees.html#the-most-complecated-decision-tree-for-titanic"><i class="fa fa-check"></i><b>1.4.4</b> The Most Complecated Decision Tree for Titanic</a></li>
<li class="chapter" data-level="1.4.5" data-path="prediction-with-decision-trees.html"><a href="prediction-with-decision-trees.html#the-rational-decision-tree-for-titanic"><i class="fa fa-check"></i><b>1.4.5</b> The Rational Decision tree for Titanic</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="process-of-predictive-modeling" class="section level2">
<h2><span class="header-section-number">1.1</span> Process of Predictive Modeling</h2>
<p>The process of constructing a prediction model is called <strong>predictive modeling</strong>. Predictive modeling is generally involves three steps: <strong>Predictor selection</strong>, <strong>model construction</strong> and <strong>model evaluation</strong>.</p>
<div id="step-1.-predictor-selection" class="section level4 unnumbered">
<h4>Step 1. Predictor Selection</h4>
<p>Predictor, in data science, is an attribute that a prediction model used to predict values of another attribute. The attribute to be predicted is called <strong>consequencer</strong> (or dependent). Generally, an data object can have a large number of attributes, which can potentially be used as predictors by a model to produce consequencer. Most models do not use all of the data attributes, instead only a number of selected attributes are used. The selection is based on the relationship between predictor and the consequencer and also the relationship among predictors. <em>Filter</em> and <em>wrapper</em> are the most common methods used in the attributes selection:</p>
<ul>
<li><p><strong>Filters</strong>. Filters is a method that examines each predictor in turn. A numerical measure is calculated, representing the strength of the correlation<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> between the predictor attribute and the consequencer. This correlation is conventionally called prediction power of a predictor in the prediction modeling. Only predictor attributes where the correlation measure<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> exceeds a given threshold are selected or simple select the fixed number of the top attributes which has higher correlation measure.</p></li>
<li><p><strong>Wrappers</strong>. A wrapper takes a group of predictors and considers the “value add” of each attribute compared to other attributes in the group. If two attributes tell you more or less the same thing (e.g. age and date of birth) then one will be discarded because it adds no value. Step-wise linear regression<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> and principal component analysis<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> are two popular wrapper methods.</p></li>
</ul>
<p>Attribute selection is a parsimonious process that aims to identify a minimal set of predictors for the maximum gain (predictive accuracy). This approach is the opposite of data pre-process where as many meaningful attributes as possible are considered for potential use.</p>
<p>It is also important to recognize that attribute selection cloud be an iterative process that occurs throughout the model building process. It finishes after no more improvement can be achieved in terms of model accuracy.</p>
</div>
<div id="step-2.-model-construction" class="section level4 unnumbered">
<h4>Step 2. Model Construction</h4>
<p>Model construction normally involves two phases: <strong>induction</strong> and <strong>deduction</strong>.</p>
<ul>
<li><p>Induction is also called model learning, which means learn to predict;</p></li>
<li><p>Deduction is called model apply, which means model applied to predict.</p></li>
</ul>
<p>The division of model learn and model apply allows a predictive model to be mature while induction using <strong>training dataset</strong> to construct a model and deduction using <strong>testing dataset</strong> to test and adjust the model constructed.</p>
<p>Depends on applications different prediction models can use different mathematical approach and algorithms. Model constricted for classification problem can use decision trees while scoring prediction model can use regressions. There are also <strong>rule based models</strong> and <strong>machine learning</strong> models.</p>
</div>
<div id="step-3.-model-validation" class="section level4 unnumbered">
<h4>Step 3. Model Validation</h4>
<p>As explained earlier, a major problem when building predictive models is that it is easy to find relationships that are the result of random patterns in the training and testing datasets, but which may not exist in the unseen datasets. This problem is called model “over-fitting”. The result is that if you measure the performance of the model using the test dataset the results will be over-optimistic. The <strong>over-fitting problem</strong> will affect model’s performance when presented with new data when the model is deployed.</p>
<p>To determine if over-fitting has occurred, the model needs to be tested on “<strong>validation dataset</strong>”. Validation datasets is a subset from the given datasets that have targeted attributes values. This subset was not used to construct the model. Validation dataset is genially taken from the training datasets with certain percentage.</p>
<p>Over-fitting is quite common and this is not necessarily a problem. However, if the degree of over-fitting is large, the model may need to be reconstructed using a different set of attributes.</p>
<p>Apart from checking model’s over-fitting, Depends on the model being constructed, there a number of evaluation methods are available to perform the model validation such as <strong>Confusion Matrix</strong> for nominal output like class labels, AUC (Area Under Curve),accuracy and other evaluation metrics are used fo r evaluate other models.</p>
<p>Predictive data analysis is the most advanced data analysis method. It largely overlaps with model building and machine learning. the overall procedure is predictor selection, model construction and model validation. Until a model is fine tuned and validated it can be put in use. Prediction can never be 100 percent accurate because we are facing unknown. Therefore prediction can always be improved once a moistake is made. That is a new concept emerged in the last a few years called “continue learning” or “life-ling learning”. In the rest of this chapter, we will explain each step of predictive analysis in detail and using our Titanic problem to illustrate how they can be done.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Correlation, in statistics, is a measurement of any statistical relationship two attributes. It can be any associations. It commonly refers to the degree to which a pair of attributes are linearly related.<a href="process-of-predictive-modeling.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>The most commonly used measurement of correlation between two attributes is the “Pearson’s correlation coefficient”, commonly called simply “the correlation coefficient”.<a href="process-of-predictive-modeling.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>In statistics, step-wise linear regression is a method of fitting regression models in which the selection of predictors is carried out by a procedure that in each step, one attribute is considered for addition to or subtraction from the set of selected attributes based on some pre-specified criterion.<a href="process-of-predictive-modeling.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Principal component analysis (PCA) is the process of computing the principal components and using only the first few principal components and ignoring the rest in a prediction or data dimension reduction. The principal components are often computed by eigendecomposition of the data covariance matrix or singular value decomposition of the data matrix.<a href="process-of-predictive-modeling.html#fnref4" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="data-analysis.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="predictor-selection.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown/edit/master/inst/examples/%s",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "none"
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
