<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.2 Titanic prediciton with a Random Forest | 08-Random-Forest.utf8</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="1.2 Titanic prediciton with a Random Forest | 08-Random-Forest.utf8" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.2 Titanic prediciton with a Random Forest | 08-Random-Forest.utf8" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="steps-to-build-a-random-forest.html"/>
<link rel="next" href="summary.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Authoring Books with R Markdown</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="titiannic-prediction-with-random-forest.html"><a href="titiannic-prediction-with-random-forest.html"><i class="fa fa-check"></i><b>1</b> Titiannic Prediction with Random Forest</a><ul>
<li class="chapter" data-level="1.1" data-path="steps-to-build-a-random-forest.html"><a href="steps-to-build-a-random-forest.html"><i class="fa fa-check"></i><b>1.1</b> Steps to Build a Random Forest</a></li>
<li class="chapter" data-level="1.2" data-path="titanic-prediciton-with-a-random-forest.html"><a href="titanic-prediciton-with-a-random-forest.html"><i class="fa fa-check"></i><b>1.2</b> Titanic prediciton with a Random Forest</a><ul>
<li class="chapter" data-level="" data-path="titanic-prediciton-with-a-random-forest.html"><a href="titanic-prediciton-with-a-random-forest.html#random-forest-with-key-predictors"><i class="fa fa-check"></i>Random Forest with Key Predictors</a></li>
<li class="chapter" data-level="" data-path="titanic-prediciton-with-a-random-forest.html"><a href="titanic-prediciton-with-a-random-forest.html#random-forest-with-more-variables"><i class="fa fa-check"></i>Random Forest with More Variables</a></li>
<li class="chapter" data-level="" data-path="titanic-prediciton-with-a-random-forest.html"><a href="titanic-prediciton-with-a-random-forest.html#random-forest-with-all-variables"><i class="fa fa-check"></i>Random Forest with All Variables</a></li>
<li class="chapter" data-level="1.2.1" data-path="titanic-prediciton-with-a-random-forest.html"><a href="titanic-prediciton-with-a-random-forest.html#comparision-the-three-random-forest-models"><i class="fa fa-check"></i><b>1.2.1</b> Comparision the Three Random Forest Models</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1.3</b> Summary</a></li>
<li class="chapter" data-level="1.4" data-path="excercise-8.html"><a href="excercise-8.html"><i class="fa fa-check"></i><b>1.4</b> Excercise 8</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="titanic-prediciton-with-a-random-forest" class="section level2">
<h2><span class="header-section-number">1.2</span> Titanic prediciton with a Random Forest</h2>
<p>Let’s now look at how we can implement the random forest algorithm for our Titanic prediction.
R provides <code>'randomForest'</code> package. You can check the details of the package for full usage. We will start with direct function call with its default settings and we may change settings later. We will also use the original attributes first and then use re-engineered attributes to see if we can improve on the model.</p>
<div id="random-forest-with-key-predictors" class="section level3 unnumbered">
<h3>Random Forest with Key Predictors</h3>
<p>The process of using <code>randomForest</code> package to build a RF model is same with the decision tree package “rpart”. Note also if a dependent (response) variable is a factor, classification is assumed, otherwise regression is assumed. So to uses randomForest, we need to convert dependent variable into factor.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="titanic-prediciton-with-a-random-forest.html#cb2-1"></a><span class="co"># convert variables into factor</span></span>
<span id="cb2-2"><a href="titanic-prediciton-with-a-random-forest.html#cb2-2"></a>train<span class="op">$</span>Survived &lt;-<span class="st"> </span><span class="kw">as.factor</span>(train<span class="op">$</span>Survived)</span>
<span id="cb2-3"><a href="titanic-prediciton-with-a-random-forest.html#cb2-3"></a><span class="co"># convert other attributes which really are categorical data but in form of numbers</span></span>
<span id="cb2-4"><a href="titanic-prediciton-with-a-random-forest.html#cb2-4"></a>train<span class="op">$</span>Pclass &lt;-<span class="st"> </span><span class="kw">as.factor</span>(train<span class="op">$</span>Pclass)</span>
<span id="cb2-5"><a href="titanic-prediciton-with-a-random-forest.html#cb2-5"></a>train<span class="op">$</span>Group_size &lt;-<span class="st"> </span><span class="kw">as.factor</span>(train<span class="op">$</span>Group_size)</span>
<span id="cb2-6"><a href="titanic-prediciton-with-a-random-forest.html#cb2-6"></a><span class="co">#confirm types</span></span>
<span id="cb2-7"><a href="titanic-prediciton-with-a-random-forest.html#cb2-7"></a><span class="kw">sapply</span>(train, class)</span></code></pre></div>
<pre><code>##  PassengerId     Survived       Pclass          Sex          Age        SibSp 
##    &quot;integer&quot;     &quot;factor&quot;     &quot;factor&quot;     &quot;factor&quot;    &quot;numeric&quot;    &quot;integer&quot; 
##        Parch       Ticket     Embarked  HasCabinNum  Friend_size      Fare_pp 
##    &quot;integer&quot;     &quot;factor&quot;     &quot;factor&quot;     &quot;factor&quot;    &quot;integer&quot;    &quot;numeric&quot; 
##        Title         Deck Ticket_class  Family_size   Group_size    Age_group 
##     &quot;factor&quot;     &quot;factor&quot;     &quot;factor&quot;    &quot;integer&quot;     &quot;factor&quot;     &quot;factor&quot;</code></pre>
<p>Let us use the same five most related attributes: <code>Pclass</code>,<code>Sex</code>, <code>HasCabinNum</code>, <code>Deck</code> and <code>Fare_pp</code> in the decision tree model2. We use all default parameters of the <em>randomForest</em>.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="titanic-prediciton-with-a-random-forest.html#cb4-1"></a><span class="co"># Build the random forest model uses pclass, sex, HasCabinNum, Deck and Fare_pp</span></span>
<span id="cb4-2"><a href="titanic-prediciton-with-a-random-forest.html#cb4-2"></a><span class="kw">set.seed</span>(<span class="dv">1234</span>) <span class="co">#for reproduction </span></span>
<span id="cb4-3"><a href="titanic-prediciton-with-a-random-forest.html#cb4-3"></a>RF_model1 &lt;-<span class="st"> </span><span class="kw">randomForest</span>(Survived <span class="op">~</span><span class="st"> </span>Sex <span class="op">+</span><span class="st"> </span>Pclass <span class="op">+</span><span class="st"> </span>HasCabinNum <span class="op">+</span><span class="st"> </span>Deck <span class="op">+</span><span class="st"> </span>Fare_pp, <span class="dt">data=</span>train, <span class="dt">importance=</span><span class="ot">TRUE</span>)</span></code></pre></div>
<p>Let us check model’s prediction accuracy.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="titanic-prediciton-with-a-random-forest.html#cb5-1"></a>RF_model1</span></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = Survived ~ Sex + Pclass + HasCabinNum +      Deck + Fare_pp, data = train, importance = TRUE) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 20.43%
## Confusion matrix:
##     0   1 class.error
## 0 493  56   0.1020036
## 1 126 216   0.3684211</code></pre>
<p>We can see that the model uses default parameters: <em>ntree</em> = 500 and <em>mtry</em> = 1. The model’s estimated accuracy is <strong>80%</strong>. It is 1 - 0.20 (OOB error).</p>
<p>Let us make a prediction on train dataset and check the accuracy.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="titanic-prediciton-with-a-random-forest.html#cb7-1"></a><span class="co"># Make your prediction using the validate dataset</span></span>
<span id="cb7-2"><a href="titanic-prediciton-with-a-random-forest.html#cb7-2"></a><span class="co">#set.seed(1234)</span></span>
<span id="cb7-3"><a href="titanic-prediciton-with-a-random-forest.html#cb7-3"></a>RF_prediction1 &lt;-<span class="st"> </span><span class="kw">predict</span>(RF_model1, train)</span>
<span id="cb7-4"><a href="titanic-prediciton-with-a-random-forest.html#cb7-4"></a><span class="co">#check up</span></span>
<span id="cb7-5"><a href="titanic-prediciton-with-a-random-forest.html#cb7-5"></a>conMat&lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(RF_prediction1, train<span class="op">$</span>Survived)</span>
<span id="cb7-6"><a href="titanic-prediciton-with-a-random-forest.html#cb7-6"></a>conMat<span class="op">$</span>table</span></code></pre></div>
<pre><code>##           Reference
## Prediction   0   1
##          0 516 107
##          1  33 235</code></pre>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="titanic-prediciton-with-a-random-forest.html#cb9-1"></a><span class="co"># Misclassification error</span></span>
<span id="cb9-2"><a href="titanic-prediciton-with-a-random-forest.html#cb9-2"></a><span class="kw">paste</span>(<span class="st">&#39;Accuracy =&#39;</span>, <span class="kw">round</span>(conMat<span class="op">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>],<span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] &quot;Accuracy = 0.84&quot;</code></pre>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="titanic-prediciton-with-a-random-forest.html#cb11-1"></a><span class="kw">paste</span>(<span class="st">&#39;Error =&#39;</span>, <span class="kw">round</span>(<span class="kw">mean</span>(train<span class="op">$</span>Survived <span class="op">!=</span><span class="st"> </span>RF_prediction1), <span class="dv">2</span>)) </span></code></pre></div>
<pre><code>## [1] &quot;Error = 0.16&quot;</code></pre>
<p>We can see that prediction on train dataset has achieved <strong>84%</strong> accuracy.
It has made 107 wrong prediction and 516 correct prediction on death. The prediction on survived is 33 wrong prediction out of 235 correct predictions.</p>
<p>The model has an accuracy of 80% after learning, but our evaluation on the train dataset achieves 84%. It has been increased. Compare with the decision tree model2, which the the same attributes were used and the prediction accuracy on the train data was 81%, the accuracy is also increased. Let us make a prediction on test dataset and submit to Kaggle to obtain an accuracy score.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="titanic-prediciton-with-a-random-forest.html#cb13-1"></a><span class="co"># produce a submit with Kaggle required format that is only two attributes: PassengerId and Survived</span></span>
<span id="cb13-2"><a href="titanic-prediciton-with-a-random-forest.html#cb13-2"></a>test<span class="op">$</span>Pclass &lt;-<span class="st"> </span><span class="kw">as.factor</span>(test<span class="op">$</span>Pclass)</span>
<span id="cb13-3"><a href="titanic-prediciton-with-a-random-forest.html#cb13-3"></a>test<span class="op">$</span>Group_size &lt;-<span class="st"> </span><span class="kw">as.factor</span>(test<span class="op">$</span>Group_size)</span>
<span id="cb13-4"><a href="titanic-prediciton-with-a-random-forest.html#cb13-4"></a></span>
<span id="cb13-5"><a href="titanic-prediciton-with-a-random-forest.html#cb13-5"></a><span class="co">#make prediction</span></span>
<span id="cb13-6"><a href="titanic-prediciton-with-a-random-forest.html#cb13-6"></a>RF_prediction &lt;-<span class="st"> </span><span class="kw">predict</span>(RF_model1, test)</span>
<span id="cb13-7"><a href="titanic-prediciton-with-a-random-forest.html#cb13-7"></a>submit &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">PassengerId =</span> test<span class="op">$</span>PassengerId, <span class="dt">Survived =</span> RF_prediction)</span>
<span id="cb13-8"><a href="titanic-prediciton-with-a-random-forest.html#cb13-8"></a><span class="co"># Write it into a file &quot;RF_Result.CSV&quot;</span></span>
<span id="cb13-9"><a href="titanic-prediciton-with-a-random-forest.html#cb13-9"></a><span class="kw">write.csv</span>(submit, <span class="dt">file =</span> <span class="st">&quot;RF_Result1.CSV&quot;</span>, <span class="dt">row.names =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<p>We can see our random forest model has scored <strong>0.76555</strong> by the Kaggle competition. It is interesting to know that the random forest model has not impoprved on the test dataset compare with the decision tree model with the same predictors. The accuracy was also 0.76555.</p>
<p>let us record these accuracies,</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="titanic-prediciton-with-a-random-forest.html#cb14-1"></a>RF_model1_accuracy &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">80</span>, <span class="dv">84</span>, <span class="fl">76.555</span>)</span></code></pre></div>
</div>
<div id="random-forest-with-more-variables" class="section level3 unnumbered">
<h3>Random Forest with More Variables</h3>
<p>Now let us see if We can obtain a better model if we use more variables. The predictor we are using is identical to the decision tree model3.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="titanic-prediciton-with-a-random-forest.html#cb15-1"></a><span class="kw">set.seed</span>(<span class="dv">2222</span>)</span>
<span id="cb15-2"><a href="titanic-prediciton-with-a-random-forest.html#cb15-2"></a>RF_model2 &lt;-<span class="st"> </span><span class="kw">randomForest</span>(Survived <span class="op">~</span><span class="st"> </span>Sex <span class="op">+</span><span class="st"> </span>Pclass <span class="op">+</span><span class="st"> </span>HasCabinNum <span class="op">+</span><span class="st"> </span>Deck <span class="op">+</span><span class="st"> </span>Group_size <span class="op">+</span><span class="st"> </span>Title, <span class="dt">data =</span> train, <span class="dt">importance=</span><span class="ot">TRUE</span>)</span></code></pre></div>
<p>We can assess the new model,</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="titanic-prediciton-with-a-random-forest.html#cb16-1"></a>RF_model2</span></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = Survived ~ Sex + Pclass + HasCabinNum +      Deck + Group_size + Title, data = train, importance = TRUE) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 17.62%
## Confusion matrix:
##     0   1 class.error
## 0 485  64   0.1165756
## 1  93 249   0.2719298</code></pre>
<p>Notice that the default parameter <em>mtry</em> = 2 and ntree = 500. It means the number of variable tried at each split is now 2 and number of trees can be built is 500. The model’s estimated OOB error rate is 18%. It has a increase in comparison with the first model which was 20%. So the overall accuracy of the model has reached <strong>82%</strong>.</p>
<p>Let us make a prediction on train Data to verify the model’s training accuracy.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="titanic-prediciton-with-a-random-forest.html#cb18-1"></a>RF_prediction2 &lt;-<span class="st"> </span><span class="kw">predict</span>(RF_model2, train)</span>
<span id="cb18-2"><a href="titanic-prediciton-with-a-random-forest.html#cb18-2"></a><span class="co">#check up</span></span>
<span id="cb18-3"><a href="titanic-prediciton-with-a-random-forest.html#cb18-3"></a>conMat&lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(RF_prediction2, train<span class="op">$</span>Survived)</span>
<span id="cb18-4"><a href="titanic-prediciton-with-a-random-forest.html#cb18-4"></a>conMat<span class="op">$</span>table</span></code></pre></div>
<pre><code>##           Reference
## Prediction   0   1
##          0 493  83
##          1  56 259</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="titanic-prediciton-with-a-random-forest.html#cb20-1"></a><span class="co"># Misclassification error</span></span>
<span id="cb20-2"><a href="titanic-prediciton-with-a-random-forest.html#cb20-2"></a><span class="kw">paste</span>(<span class="st">&#39;Accuracy =&#39;</span>, <span class="kw">round</span>(conMat<span class="op">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>],<span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] &quot;Accuracy = 0.84&quot;</code></pre>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="titanic-prediciton-with-a-random-forest.html#cb22-1"></a><span class="kw">paste</span>(<span class="st">&#39;Error =&#39;</span>, <span class="kw">round</span>(<span class="kw">mean</span>(train<span class="op">$</span>Survived <span class="op">!=</span><span class="st"> </span>RF_prediction2), <span class="dv">2</span>)) </span></code></pre></div>
<pre><code>## [1] &quot;Error = 0.16&quot;</code></pre>
<p>We can see the accuracy on train dataset has reached 87%. The result shows that the prediction on survive has 70 wrong predictions out of 505 correct predictions; The prediction on death has 272 correct predictions and 44 wrong predictions. The overall accuracy reaches <strong>87%</strong>. It is again higher than the model learning accuracy <strong>82%</strong>.</p>
<p>It has also increased a bit comparing with the accuracy on the estimated accuracy <strong>80%</strong> and the accuracy on train dataset <strong>84%</strong> of the random forest RF_model1. Compare with the decision tree model3, which has the identical predictors, the accuracy was <strong>85%</strong> on the train dataset.</p>
<p>Let us make another submit to Kaggle to see if the prediction on unseen data has been improved.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="titanic-prediciton-with-a-random-forest.html#cb24-1"></a><span class="co"># produce a submit with Kaggle </span></span>
<span id="cb24-2"><a href="titanic-prediciton-with-a-random-forest.html#cb24-2"></a>test<span class="op">$</span>Pclass &lt;-<span class="st"> </span><span class="kw">as.factor</span>(test<span class="op">$</span>Pclass)</span>
<span id="cb24-3"><a href="titanic-prediciton-with-a-random-forest.html#cb24-3"></a>test<span class="op">$</span>Group_size &lt;-<span class="st"> </span><span class="kw">as.factor</span>(test<span class="op">$</span>Group_size)</span>
<span id="cb24-4"><a href="titanic-prediciton-with-a-random-forest.html#cb24-4"></a></span>
<span id="cb24-5"><a href="titanic-prediciton-with-a-random-forest.html#cb24-5"></a><span class="co">#make prediction</span></span>
<span id="cb24-6"><a href="titanic-prediciton-with-a-random-forest.html#cb24-6"></a>RF_prediction &lt;-<span class="st"> </span><span class="kw">predict</span>(RF_model2, test)</span>
<span id="cb24-7"><a href="titanic-prediciton-with-a-random-forest.html#cb24-7"></a>submit &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">PassengerId =</span> test<span class="op">$</span>PassengerId, <span class="dt">Survived =</span> RF_prediction)</span>
<span id="cb24-8"><a href="titanic-prediciton-with-a-random-forest.html#cb24-8"></a><span class="co"># Write it into a file &quot;RF_Result.CSV&quot;</span></span>
<span id="cb24-9"><a href="titanic-prediciton-with-a-random-forest.html#cb24-9"></a><span class="kw">write.csv</span>(submit, <span class="dt">file =</span> <span class="st">&quot;RF_Result2.CSV&quot;</span>, <span class="dt">row.names =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<p>The feedback shows the prediction only increased a lot with a scored 0.78229! It has improved on the RF_model1 (0.76555) and decision tree model3 (0.75837).</p>
<p>let us record these various accuracy.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="titanic-prediciton-with-a-random-forest.html#cb25-1"></a>RF_model2_accuracy &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">82</span>, <span class="dv">87</span>, <span class="dv">78</span>)</span></code></pre></div>
</div>
<div id="random-forest-with-all-variables" class="section level3 unnumbered">
<h3>Random Forest with All Variables</h3>
<p>Now let use random forest to build a model with the maximum predictors that can be used from attributes. We may not be able to use all the attributes since the <code>randomForest</code> function cannot handle attribute which is not a factor and has over 53 levels. So, we will not use attribute <code>Ticket</code>.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="titanic-prediciton-with-a-random-forest.html#cb26-1"></a><span class="kw">set.seed</span>(<span class="dv">2233</span>)</span>
<span id="cb26-2"><a href="titanic-prediciton-with-a-random-forest.html#cb26-2"></a>xTrain =<span class="st"> </span>train[ , <span class="kw">c</span>(<span class="st">&quot;Survived&quot;</span>, <span class="st">&quot;Pclass&quot;</span>,<span class="st">&quot;Title&quot;</span>, <span class="st">&quot;Sex&quot;</span>,<span class="st">&quot;Age_group&quot;</span>,<span class="st">&quot;Group_size&quot;</span>, <span class="st">&quot;Ticket_class&quot;</span>, <span class="st">&quot;Fare_pp&quot;</span>, <span class="st">&quot;Deck&quot;</span>, <span class="st">&quot;HasCabinNum&quot;</span>, <span class="st">&quot;Embarked&quot;</span>)]</span>
<span id="cb26-3"><a href="titanic-prediciton-with-a-random-forest.html#cb26-3"></a><span class="co">#RF_model3 &lt;- randomForest(Survived ~ Sex + Pclass + HasCabinNum + Deck + Group_size + Family_size + Friend_size + Title + Embarked + Ticket_class+ Age_group + Fare_pp, data = train, importance=TRUE)</span></span>
<span id="cb26-4"><a href="titanic-prediciton-with-a-random-forest.html#cb26-4"></a>RF_model3 &lt;-<span class="st"> </span><span class="kw">randomForest</span>(Survived <span class="op">~</span><span class="st"> </span>Sex <span class="op">+</span><span class="st"> </span>Pclass <span class="op">+</span><span class="st"> </span>Age <span class="op">+</span><span class="st"> </span>SibSp <span class="op">+</span><span class="st"> </span>Parch <span class="op">+</span><span class="st"> </span>Embarked <span class="op">+</span><span class="st"> </span>HasCabinNum <span class="op">+</span><span class="st"> </span>Friend_size <span class="op">+</span><span class="st"> </span>Fare_pp <span class="op">+</span><span class="st"> </span>Title <span class="op">+</span><span class="st"> </span>Deck <span class="op">+</span><span class="st"> </span>Ticket_class <span class="op">+</span><span class="st"> </span>Family_size <span class="op">+</span><span class="st"> </span>Group_size <span class="op">+</span><span class="st"> </span>Age_group, <span class="dt">data =</span> train, <span class="dt">importance=</span><span class="ot">TRUE</span>)</span></code></pre></div>
<p>We can assess the new model,</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="titanic-prediciton-with-a-random-forest.html#cb27-1"></a>RF_model3</span></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = Survived ~ Sex + Pclass + Age + SibSp +      Parch + Embarked + HasCabinNum + Friend_size + Fare_pp +      Title + Deck + Ticket_class + Family_size + Group_size +      Age_group, data = train, importance = TRUE) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 3
## 
##         OOB estimate of  error rate: 17.4%
## Confusion matrix:
##     0   1 class.error
## 0 483  66   0.1202186
## 1  89 253   0.2602339</code></pre>
<p>Notice that the default parameter <em>mtry</em> = 3 and ntree = 500. It means the number of variable tried at each split is now 3 and number of trees can be built is 500. The model’s estimated OOB error rate is 17%. It has a increase in comparison with the model2 which was 18%. So the overall accuracy of the model has reached <strong>83%</strong>.</p>
<p>Let us make a prediction on train Data to verify the model’s training accuracy.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="titanic-prediciton-with-a-random-forest.html#cb29-1"></a>RF_prediction3 &lt;-<span class="st"> </span><span class="kw">predict</span>(RF_model3, train)</span>
<span id="cb29-2"><a href="titanic-prediciton-with-a-random-forest.html#cb29-2"></a><span class="co">#check up</span></span>
<span id="cb29-3"><a href="titanic-prediciton-with-a-random-forest.html#cb29-3"></a>conMat&lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(RF_prediction3, train<span class="op">$</span>Survived)</span>
<span id="cb29-4"><a href="titanic-prediciton-with-a-random-forest.html#cb29-4"></a>conMat<span class="op">$</span>table</span></code></pre></div>
<pre><code>##           Reference
## Prediction   0   1
##          0 536  38
##          1  13 304</code></pre>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="titanic-prediciton-with-a-random-forest.html#cb31-1"></a><span class="co"># Misclassification error</span></span>
<span id="cb31-2"><a href="titanic-prediciton-with-a-random-forest.html#cb31-2"></a><span class="kw">paste</span>(<span class="st">&#39;Accuracy =&#39;</span>, <span class="kw">round</span>(conMat<span class="op">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>],<span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] &quot;Accuracy = 0.94&quot;</code></pre>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="titanic-prediciton-with-a-random-forest.html#cb33-1"></a><span class="kw">paste</span>(<span class="st">&#39;Error =&#39;</span>, <span class="kw">round</span>(<span class="kw">mean</span>(train<span class="op">$</span>Survived <span class="op">!=</span><span class="st"> </span>RF_prediction3), <span class="dv">2</span>)) </span></code></pre></div>
<pre><code>## [1] &quot;Error = 0.06&quot;</code></pre>
<p>We can see the accuracy on train dataset has reached 95%. The result shows that the prediction on survive has 38 wrong predictions out of 536 correct predictions; The prediction on death has 304 correct predictions and 13 wrong predictions. The overall accuracy reaches <strong>95%</strong>. It is again higher than the model learning accuracy <strong>83%</strong>.</p>
<p>Let us make another submit to Kaggle to see if the prediction on unseen data has been improved.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="titanic-prediciton-with-a-random-forest.html#cb35-1"></a><span class="co"># produce a submit with Kaggle </span></span>
<span id="cb35-2"><a href="titanic-prediciton-with-a-random-forest.html#cb35-2"></a>test<span class="op">$</span>Pclass &lt;-<span class="st"> </span><span class="kw">as.factor</span>(test<span class="op">$</span>Pclass)</span>
<span id="cb35-3"><a href="titanic-prediciton-with-a-random-forest.html#cb35-3"></a>test<span class="op">$</span>Group_size &lt;-<span class="st"> </span><span class="kw">as.factor</span>(test<span class="op">$</span>Group_size)</span>
<span id="cb35-4"><a href="titanic-prediciton-with-a-random-forest.html#cb35-4"></a></span>
<span id="cb35-5"><a href="titanic-prediciton-with-a-random-forest.html#cb35-5"></a><span class="co">#make prediction</span></span>
<span id="cb35-6"><a href="titanic-prediciton-with-a-random-forest.html#cb35-6"></a>RF_prediction &lt;-<span class="st"> </span><span class="kw">predict</span>(RF_model3, test)</span>
<span id="cb35-7"><a href="titanic-prediciton-with-a-random-forest.html#cb35-7"></a>submit &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">PassengerId =</span> test<span class="op">$</span>PassengerId, <span class="dt">Survived =</span> RF_prediction)</span>
<span id="cb35-8"><a href="titanic-prediciton-with-a-random-forest.html#cb35-8"></a><span class="co"># Write it into a file &quot;RF_Result.CSV&quot;</span></span>
<span id="cb35-9"><a href="titanic-prediciton-with-a-random-forest.html#cb35-9"></a><span class="kw">write.csv</span>(submit, <span class="dt">file =</span> <span class="st">&quot;RF_Result3.CSV&quot;</span>, <span class="dt">row.names =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<p>The feedback score is 0.77033. It shows decrease of the accuracy.</p>
<p>let us record these various accuracy.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="titanic-prediciton-with-a-random-forest.html#cb36-1"></a>RF_model3_accuracy &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">83</span>, <span class="dv">94</span>, <span class="dv">77</span>)</span></code></pre></div>
</div>
<div id="comparision-the-three-random-forest-models" class="section level3">
<h3><span class="header-section-number">1.2.1</span> Comparision the Three Random Forest Models</h3>
<p>We have produced three random forest models, each has different performance in terms of prediction accuracy on the test dataset. Let us make a quick comparison among them.</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="titanic-prediciton-with-a-random-forest.html#cb37-1"></a><span class="kw">library</span>(tidyr)</span></code></pre></div>
<pre><code>## Warning: package &#39;tidyr&#39; was built under R version 3.6.3</code></pre>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="titanic-prediciton-with-a-random-forest.html#cb39-1"></a>Model &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;RF_Model1&quot;</span>,<span class="st">&quot;RF_Model2&quot;</span>,<span class="st">&quot;RF_Model3&quot;</span>)</span>
<span id="cb39-2"><a href="titanic-prediciton-with-a-random-forest.html#cb39-2"></a>Pre &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Sex, Pclass, HasCabinNum, Deck, Fare_pp&quot;</span>, <span class="st">&quot;Sex, Pclass, HasCabinNum, Deck, Fare_pp,  Group_size, Title&quot;</span>, <span class="st">&quot;Sex, Pclass, Age, SibSp, Parch, Embarked, HasCabinNum, Friend_size, Fare_pp, Title, Deck, Ticket_class, Family_size, Group_size, Age_group&quot;</span>)</span>
<span id="cb39-3"><a href="titanic-prediciton-with-a-random-forest.html#cb39-3"></a></span>
<span id="cb39-4"><a href="titanic-prediciton-with-a-random-forest.html#cb39-4"></a>Learn &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">80.0</span>, <span class="fl">82.0</span>, <span class="fl">83.0</span>)</span>
<span id="cb39-5"><a href="titanic-prediciton-with-a-random-forest.html#cb39-5"></a>Train &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">84</span>, <span class="dv">87</span>, <span class="dv">78</span>)</span>
<span id="cb39-6"><a href="titanic-prediciton-with-a-random-forest.html#cb39-6"></a>Test &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">76.555</span>, <span class="fl">78.23</span>, <span class="fl">77.03</span>)</span>
<span id="cb39-7"><a href="titanic-prediciton-with-a-random-forest.html#cb39-7"></a>df1 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(Model, Pre, Learn, Train, Test)</span>
<span id="cb39-8"><a href="titanic-prediciton-with-a-random-forest.html#cb39-8"></a>df2 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(Model, Learn, Train, Test)</span>
<span id="cb39-9"><a href="titanic-prediciton-with-a-random-forest.html#cb39-9"></a>knitr<span class="op">::</span><span class="kw">kable</span>(df1, <span class="dt">longtable =</span> <span class="ot">TRUE</span>, <span class="dt">booktabs =</span> <span class="ot">TRUE</span>, <span class="dt">digits =</span> <span class="dv">2</span>, <span class="dt">col.names =</span><span class="kw">c</span>(<span class="st">&quot;Models&quot;</span>, <span class="st">&quot;Predictors&quot;</span>, <span class="st">&quot;Accuracy on Learn&quot;</span>, <span class="st">&quot;Accuracy on Train&quot;</span>, <span class="st">&quot;Accuracy on Test&quot;</span>), </span>
<span id="cb39-10"><a href="titanic-prediciton-with-a-random-forest.html#cb39-10"></a>  <span class="dt">caption =</span> <span class="st">&#39;The Comparision among 3 Random Forest models&#39;</span></span>
<span id="cb39-11"><a href="titanic-prediciton-with-a-random-forest.html#cb39-11"></a>)</span></code></pre></div>
<table style="width:100%;">
<caption><span id="tab:unnamed-chunk-18">Table 1.1: </span>The Comparision among 3 Random Forest models</caption>
<colgroup>
<col width="4%" />
<col width="68%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Models</th>
<th align="left">Predictors</th>
<th align="right">Accuracy on Learn</th>
<th align="right">Accuracy on Train</th>
<th align="right">Accuracy on Test</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">RF_Model1</td>
<td align="left">Sex, Pclass, HasCabinNum, Deck, Fare_pp</td>
<td align="right">80</td>
<td align="right">84</td>
<td align="right">76.56</td>
</tr>
<tr class="even">
<td align="left">RF_Model2</td>
<td align="left">Sex, Pclass, HasCabinNum, Deck, Fare_pp, Group_size, Title</td>
<td align="right">82</td>
<td align="right">87</td>
<td align="right">78.23</td>
</tr>
<tr class="odd">
<td align="left">RF_Model3</td>
<td align="left">Sex, Pclass, Age, SibSp, Parch, Embarked, HasCabinNum, Friend_size, Fare_pp, Title, Deck, Ticket_class, Family_size, Group_size, Age_group</td>
<td align="right">83</td>
<td align="right">78</td>
<td align="right">77.03</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="titanic-prediciton-with-a-random-forest.html#cb40-1"></a>df.long &lt;-<span class="st"> </span><span class="kw">gather</span>(df2, Dataset, Accuracy, <span class="op">-</span>Model, <span class="dt">factor_key =</span><span class="ot">TRUE</span>)</span>
<span id="cb40-2"><a href="titanic-prediciton-with-a-random-forest.html#cb40-2"></a><span class="kw">ggplot</span>(<span class="dt">data =</span> df.long, <span class="kw">aes</span>(<span class="dt">x =</span> Model, <span class="dt">y =</span> Accuracy, <span class="dt">fill =</span> Dataset)) <span class="op">+</span></span>
<span id="cb40-3"><a href="titanic-prediciton-with-a-random-forest.html#cb40-3"></a><span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">position =</span> <span class="kw">position_dodge</span>()) </span></code></pre></div>
<div class="figure"><span id="fig:RFmodelcompare"></span>
<img src="08-Random-Forest_files/figure-html/RFmodelcompare-1.svg" alt="Random Froest models' accuracy on model learning, Train dataset and Test dataset." width="672" />
<p class="caption">
Figure 1.2: Random Froest models’ accuracy on model learning, Train dataset and Test dataset.
</p>
</div>
<p>From the comparison, we can see that:</p>
<ol style="list-style-type: decimal">
<li>It is not true that the more predictors the better performance with Random Forest models.</li>
<li>The result of the model validation on the training dataset is not reliable. The higher accuracy on the train dataset does not mean a higher accuracy on the test dataset.</li>
<li>All the model has a degree of overfitting. That is the accuracy on the test data is lower than the train dataset and even lower than the model its own estimated accuracy while learn or construct it.</li>
<li>the cause of the overfitting is complicated issue. It may related with all the factors: number of predictors used to build the model, the dataset used to build the model and the model default parameters.</li>
</ol>
<p>In comparison with the decision tree models we have built in the previous Chapter. The random forest models over performs all the four models on the test dataset. The lowest accuracy is the same with the highest accuracy with the decision tree models (76.55%).</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="steps-to-build-a-random-forest.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="summary.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown/edit/master/inst/examples/%s",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "none"
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
