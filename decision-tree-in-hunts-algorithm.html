<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.1 Decision tree in Hunt’s Algorithm | 07-decision-tree.utf8</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="1.1 Decision tree in Hunt’s Algorithm | 07-decision-tree.utf8" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.1 Decision tree in Hunt’s Algorithm | 07-decision-tree.utf8" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="prediction-with-decision-trees.html"/>
<link rel="next" href="the-simplest-decision-tree-for-titanic.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Authoring Books with R Markdown</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="prediction-with-decision-trees.html"><a href="prediction-with-decision-trees.html"><i class="fa fa-check"></i><b>1</b> Prediction with Decision Trees</a><ul>
<li class="chapter" data-level="1.1" data-path="decision-tree-in-hunts-algorithm.html"><a href="decision-tree-in-hunts-algorithm.html"><i class="fa fa-check"></i><b>1.1</b> Decision tree in Hunt’s Algorithm</a><ul>
<li class="chapter" data-level="1.1.1" data-path="decision-tree-in-hunts-algorithm.html"><a href="decision-tree-in-hunts-algorithm.html#test_condition"><i class="fa fa-check"></i><b>1.1.1</b> How to Form a Test Condition?</a></li>
<li class="chapter" data-level="1.1.2" data-path="decision-tree-in-hunts-algorithm.html"><a href="decision-tree-in-hunts-algorithm.html#best_split"><i class="fa fa-check"></i><b>1.1.2</b> How to Determine the Best Split Condition?</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="the-simplest-decision-tree-for-titanic.html"><a href="the-simplest-decision-tree-for-titanic.html"><i class="fa fa-check"></i><b>1.2</b> The Simplest Decision Tree for Titanic</a></li>
<li class="chapter" data-level="1.3" data-path="the-decision-tree-with-core-predictors.html"><a href="the-decision-tree-with-core-predictors.html"><i class="fa fa-check"></i><b>1.3</b> The Decision Tree with Core Predictors</a></li>
<li class="chapter" data-level="1.4" data-path="the-decision-tree-with-more-predictors.html"><a href="the-decision-tree-with-more-predictors.html"><i class="fa fa-check"></i><b>1.4</b> The Decision Tree with More Predictors</a></li>
<li class="chapter" data-level="1.5" data-path="the-decision-tree-with-full-predictors.html"><a href="the-decision-tree-with-full-predictors.html"><i class="fa fa-check"></i><b>1.5</b> The Decision Tree with Full Predictors</a></li>
<li class="chapter" data-level="1.6" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1.6</b> Summary</a></li>
<li class="chapter" data-level="1.7" data-path="excerces.html"><a href="excerces.html"><i class="fa fa-check"></i><b>1.7</b> Excerces</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="decision-tree-in-hunts-algorithm" class="section level2">
<h2><span class="header-section-number">1.1</span> Decision tree in Hunt’s Algorithm</h2>
<p>Hunt’s algorithm builds a decision tree in a recursive fashion by partitioning the training dataset into successively <strong>purer</strong> subsets. Hunt’s algorithm takes three input values:</p>
<ol style="list-style-type: decimal">
<li>A training dataset, <span class="math inline">\(D\)</span> with a number of attributes,</li>
<li>A subset of attributes <span class="math inline">\(Att_{list}\)</span> and its testing criterion together to form a <code>'test condition'</code>, such as <code>'age&gt;=25'</code> is a test condition, where, <code>'age'</code> is the attribute and <code>'&gt;=25'</code> is the test criterion.</li>
<li>A <code>Attribute_selection_method</code>, it refers a procedure to determine the best splitting.</li>
</ol>
<p>The general recursive procedure is defined as below <span class="citation">[@Tan2005]</span>:</p>
<ol style="list-style-type: decimal">
<li>Create a node <span class="math inline">\(N\)</span>, suppose the training dataset when reach to note <span class="math inline">\(N\)</span> is <span class="math inline">\(D_{N}\)</span>. Initially, <span class="math inline">\(D_{N}\)</span> is the entire training set <span class="math inline">\(D\)</span>. Do the following:</li>
<li>If <span class="math inline">\(D_{t}\)</span> contains records that belong the same class <span class="math inline">\(y_{t}\)</span>, then <span class="math inline">\(t\)</span> is a leaf node labeled as <span class="math inline">\(y_{t}\)</span>;</li>
<li>If <span class="math inline">\(D_{t}\)</span> is not empty set but <span class="math inline">\(Att_{list}\)</span> is empty, (there is no more test attributes left untested), then <span class="math inline">\(t\)</span> is a leaf node labeled by the the label of the majority records in the dataset;</li>
<li>If <span class="math inline">\(D_{t}\)</span> contains records that belong to more than one class and <span class="math inline">\(Att_{list}\)</span> is not empty, use <code>Attribute_selection_method</code> to choose next <strong>best attribute</strong> from the <span class="math inline">\(Att_{list}\)</span> and remove that list from <span class="math inline">\(Att_{list}\)</span>. use the attribute and its condition as next test condition.</li>
<li>Repeat steps 2,3 and 4 until all the records in the subset belong to the same class.</li>
</ol>
<p>There are two fundamental problems needs to be sorted before the Hunt’s algorithm can work:
1. How to form a ‘test condition’? particularly when non-binary attributes exists?
2. How to define the ‘best test conditions’, so very loop the best test condition can be used in a decision tree?</p>
<div id="test_condition" class="section level3">
<h3><span class="header-section-number">1.1.1</span> How to Form a Test Condition?</h3>
<p>Decision tree algorithms must provide a method for expressing an test condition and its corresponding outcomes for different attribute types.</p>
<ol style="list-style-type: decimal">
<li>Binary Attributes. The test condition for a binary attribute is simple because it only generates two potential outcomes, as shown in figure <a href="decision-tree-in-hunts-algorithm.html#fig:sex">1.2</a>.</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:sex"></span>
<img src="images/Sex.PNG" alt="Test condition for binary attributes." width="50%" />
<p class="caption">
Figure 1.2: Test condition for binary attributes.
</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>No-binary attributes. No-binary attributes depends on the types of nominal or ordinal, it can have different ways of split. A nominal attribute can have many values, its test condition can be expressed in two ways, as shown in Figure <a href="decision-tree-in-hunts-algorithm.html#fig:age2">1.3</a>. For a multiway split , see Figure <a href="decision-tree-in-hunts-algorithm.html#fig:age2">1.3</a>(a), the number of outcomes depends on the number of distinct values for the corresponding attribute. For example, if an attribute such as age has three distinct values: youth, m_aged, or senior. Its test condition will produce a three-way split or a binary split. Figure <a href="decision-tree-in-hunts-algorithm.html#fig:age2">1.3</a>(b) illustrates three different ways of grouping the attribute values for age into two subsets.</li>
</ol>
<img src="images/age1.PNG" width="50%" style="display: block; margin: auto;" />
<div class="figure" style="text-align: center"><span id="fig:age2"></span>
<img src="images/age2.PNG" alt="Test condition for no-binary attributes." width="100%" />
<p class="caption">
Figure 1.3: Test condition for no-binary attributes.
</p>
</div>
<ol start="3" style="list-style-type: decimal">
<li>Continuous Attributes. For continuous attributes, the test condition can be constructed as a comparison test <span class="math inline">\((A&lt;v)\)</span> or <span class="math inline">\((A≥v)\)</span> with binary outcomes, or a range query with outcomes of the form <span class="math inline">\(v_i≤A&lt;v_{i+1}\)</span>, For <span class="math inline">\(i=1,…,k\)</span>. The difference between these approaches is shown in Figure 11.34. For the binary case, the decision tree algorithm must consider all possible split positions v, and it selects the one that produces the best partition. For the multiway split, the algorithm must consider all possible ranges of continuous values.</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:fare"></span>
<img src="images/Fare.PNG" alt="Test condition for continuous attributes." width="100%" />
<p class="caption">
Figure 1.4: Test condition for continuous attributes.
</p>
</div>
</div>
<div id="best_split" class="section level3">
<h3><span class="header-section-number">1.1.2</span> How to Determine the Best Split Condition?</h3>
<p>The method used to define the best split makes different decision tree algorithms. There are many measures that can be used to determine the best way to split the records. These measures are defined in terms of the class distribution of the records before and after splitting. The best splitting is the one that has more <strong>purity</strong> after the splitting. If we were to split <span class="math inline">\(D\)</span> into smaller partitions according to the outcomes of the splitting criterion, ideally each partition after splitting would be pure (i.e., all the records that fall into a given partition would belong to the same class). Instead of define a split’s purity, the impurity of its child node is used. There are a number of commonly used impurity measurements: <strong>Entropy</strong>, <strong>Gini Index</strong> and <strong>Classification Error</strong>.</p>
<p><strong>Entropy:</strong> measures the degree of uncertainty, impurity, or disorder. The formula for calculate entropy is as shown below:</p>
<p><span class="math display" id="eq:entropy">\[\begin{equation} 
E(x)= ∑_{i=1}^{n}p_ilog_2(p_i),
  \tag{1.1}
\end{equation}\]</span></p>
<p>Where <span class="math inline">\(p\)</span> represents the probability, and <span class="math inline">\(E(x)\)</span> represents the entropy.</p>
<p><strong>Gini Index:</strong> also called Gini impurity, measures the degree of probability of a particular variable being incorrectly classified when it is chosen randomly. The degree of the Gini index varies between zero and one, where zero denotes that all elements belong to a certain class or only one class exists, and one denotes that the elements are randomly distributed across various classes. A Gini index of 0.5 denotes equally distributed elements into some classes.</p>
<p>The formula used to calculate Gini index is shown below:</p>
<p><span class="math display" id="eq:Gini">\[\begin{equation} 
GINI(x) = 1- ∑_{i=1}^{n}p_i^2,
  \tag{1.2}
\end{equation}\]</span></p>
<p>Where <span class="math inline">\(p_i\)</span> is the probability of an object being classified to a particular class.</p>
<p><strong>Classification Error</strong> measures the misclassified class labels. It is calculated with the formula shows below:
<span class="math display" id="eq:clerror">\[\begin{equation} 
Classification error(x)= 1 - max_{i}p_i.
  \tag{1.3}
\end{equation}\]</span></p>
<p>Among these three impurity measurements, Gini is Used by the CART (classification and regression tree) algorithm for classification trees, and Entropy is Used by the ID3, C4.5 and C5.0 tree-generation algorithms.</p>
<p>With above explanation we can now say that the aims of a decision tree algorithm is to reduce Entropy level from the root to the leaves and the best tree is the one that takes order from the most to the least in reducing Entropy level.</p>
<p>The good news is that we do not need to calculate impurity of each test condition to build a decision tree manually. The most tools have the tree construction built-in already. We will use R package called <em>rpart</em> to build decision tress for our Titanic prediction problem.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="prediction-with-decision-trees.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="the-simplest-decision-tree-for-titanic.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown/edit/master/inst/examples/%s",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "none"
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
