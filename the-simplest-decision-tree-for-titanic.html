<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.2 The Simplest Decision Tree for Titanic | 07-decision-tree.utf8</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="1.2 The Simplest Decision Tree for Titanic | 07-decision-tree.utf8" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.2 The Simplest Decision Tree for Titanic | 07-decision-tree.utf8" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="decision-tree-in-hunts-algorithm.html"/>
<link rel="next" href="the-decision-tree-with-core-predictors.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Authoring Books with R Markdown</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="prediction-with-decision-trees.html"><a href="prediction-with-decision-trees.html"><i class="fa fa-check"></i><b>1</b> Prediction with Decision Trees</a><ul>
<li class="chapter" data-level="1.1" data-path="decision-tree-in-hunts-algorithm.html"><a href="decision-tree-in-hunts-algorithm.html"><i class="fa fa-check"></i><b>1.1</b> Decision tree in Hunt’s Algorithm</a><ul>
<li class="chapter" data-level="1.1.1" data-path="decision-tree-in-hunts-algorithm.html"><a href="decision-tree-in-hunts-algorithm.html#test_condition"><i class="fa fa-check"></i><b>1.1.1</b> How to Form a Test Condition?</a></li>
<li class="chapter" data-level="1.1.2" data-path="decision-tree-in-hunts-algorithm.html"><a href="decision-tree-in-hunts-algorithm.html#best_split"><i class="fa fa-check"></i><b>1.1.2</b> How to Determine the Best Split Condition?</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="the-simplest-decision-tree-for-titanic.html"><a href="the-simplest-decision-tree-for-titanic.html"><i class="fa fa-check"></i><b>1.2</b> The Simplest Decision Tree for Titanic</a></li>
<li class="chapter" data-level="1.3" data-path="the-decision-tree-with-core-predictors.html"><a href="the-decision-tree-with-core-predictors.html"><i class="fa fa-check"></i><b>1.3</b> The Decision Tree with Core Predictors</a></li>
<li class="chapter" data-level="1.4" data-path="the-decision-tree-with-more-predictors.html"><a href="the-decision-tree-with-more-predictors.html"><i class="fa fa-check"></i><b>1.4</b> The Decision Tree with More Predictors</a></li>
<li class="chapter" data-level="1.5" data-path="the-decision-tree-with-full-predictors.html"><a href="the-decision-tree-with-full-predictors.html"><i class="fa fa-check"></i><b>1.5</b> The Decision Tree with Full Predictors</a></li>
<li class="chapter" data-level="1.6" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1.6</b> Summary</a></li>
<li class="chapter" data-level="1.7" data-path="excerces.html"><a href="excerces.html"><i class="fa fa-check"></i><b>1.7</b> Excerces</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="the-simplest-decision-tree-for-titanic" class="section level2">
<h2><span class="header-section-number">1.2</span> The Simplest Decision Tree for Titanic</h2>
<p>In the Titanic problem, Let’s quickly review the possible attributes. Previously, we have understood that there are a few attributes that have a little prediction power or we say they have a little association with the dependent variable <code>Survivded</code>. These attributes include <code>PassengerID</code>, <code>Name</code> and <code>Ticket</code>. That is why we re-engineered some of them like passenger’s name has been re-engineered into title,etc. Other attributes can all be used to predict a passenger’s death or survival since they all have some power of prediction. So, which one to use and in what an order? We will use Titanic problem to demonstrate how to build decision trees for prediction.</p>
<p>Let us consider a simple decision tree firstly.</p>
<p>The simplest decision tree perhaps is the one only has one test condition and two possible outcomes. In terms of a tree, we called it one internal node and two branches. There are only one attribute meet with the requirements. That is <em>Sex</em>, so our decision tree will be build only base on passenger’s gender.</p>
<p>We need a number of libraries to make our code works.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="the-simplest-decision-tree-for-titanic.html#cb1-1"></a><span class="co">#load rpart the library which support decision tree </span></span>
<span id="cb1-2"><a href="the-simplest-decision-tree-for-titanic.html#cb1-2"></a><span class="kw">library</span>(rpart)</span>
<span id="cb1-3"><a href="the-simplest-decision-tree-for-titanic.html#cb1-3"></a><span class="co"># Build our first model. we only use Sex attribute, check help on rpart, This model only takes Sex as predictor and Survived as the consequencer</span></span>
<span id="cb1-4"><a href="the-simplest-decision-tree-for-titanic.html#cb1-4"></a><span class="co"># load our re-engineered data set and seperate train and test datasets</span></span>
<span id="cb1-5"><a href="the-simplest-decision-tree-for-titanic.html#cb1-5"></a>RE_data &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;RE_data.csv&quot;</span>, <span class="dt">header =</span> <span class="ot">TRUE</span>)</span>
<span id="cb1-6"><a href="the-simplest-decision-tree-for-titanic.html#cb1-6"></a>train &lt;-<span class="st"> </span>RE_data[<span class="dv">1</span><span class="op">:</span><span class="dv">891</span>, ]</span>
<span id="cb1-7"><a href="the-simplest-decision-tree-for-titanic.html#cb1-7"></a>test &lt;-<span class="st"> </span>RE_data[<span class="dv">892</span><span class="op">:</span><span class="dv">1309</span>, ]</span>
<span id="cb1-8"><a href="the-simplest-decision-tree-for-titanic.html#cb1-8"></a><span class="co">#build a decision tree model use rpart. </span></span>
<span id="cb1-9"><a href="the-simplest-decision-tree-for-titanic.html#cb1-9"></a>model1 &lt;-<span class="st"> </span><span class="kw">rpart</span>(Survived <span class="op">~</span><span class="st"> </span>Sex, <span class="dt">data =</span> train, <span class="dt">method=</span><span class="st">&quot;class&quot;</span>)</span></code></pre></div>
<p>Simple! isn’t it? There are only three lines of code. you can see we have the first two lines to build two variables ‘train’ and ‘test’ to hold our training dataset and testing dataset. The model is simple a function invocation, the function is called ‘rpart’.</p>
<p>R function did the job for us so we do not need go through the model construction phase manually to build our classifier. The decision tree has been already built. Now we can use our model making predictions on the test dataset.</p>
<p>For Kaggle competition, you can produce predictions on the test dataset provided and can submit to Kaggle. Kaggle will award a score for a model based on the prediction’s accuracy on the test dataset.</p>
<p>In practice, people would not build a prediction model and use it to produce a prediction on the test dataset blandly to finish the job. We want know how our model is performing before use it to do prediction on the test dataset. One way to get to know about the model’s performance is to make a prediction on the training dataset or part of it. So we can compare the model’s prediction with the original value.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="the-simplest-decision-tree-for-titanic.html#cb2-1"></a><span class="co">#library caret is a comprehensive library support all sorts of model analysis</span></span>
<span id="cb2-2"><a href="the-simplest-decision-tree-for-titanic.html#cb2-2"></a><span class="kw">library</span>(caret)</span>
<span id="cb2-3"><a href="the-simplest-decision-tree-for-titanic.html#cb2-3"></a><span class="kw">options</span>(<span class="dt">digits=</span><span class="dv">4</span>)</span>
<span id="cb2-4"><a href="the-simplest-decision-tree-for-titanic.html#cb2-4"></a><span class="co"># assess the model&#39;s accuracy with train dataset by make a prediction on the train data. </span></span>
<span id="cb2-5"><a href="the-simplest-decision-tree-for-titanic.html#cb2-5"></a>Predict_model1_train &lt;-<span class="st"> </span><span class="kw">predict</span>(model1, train, <span class="dt">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb2-6"><a href="the-simplest-decision-tree-for-titanic.html#cb2-6"></a><span class="co">#build a confusion matrix to make comparison</span></span>
<span id="cb2-7"><a href="the-simplest-decision-tree-for-titanic.html#cb2-7"></a>conMat &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(<span class="kw">as.factor</span>(Predict_model1_train), <span class="kw">as.factor</span>(train<span class="op">$</span>Survived))</span>
<span id="cb2-8"><a href="the-simplest-decision-tree-for-titanic.html#cb2-8"></a><span class="co">#show confusion matrix </span></span>
<span id="cb2-9"><a href="the-simplest-decision-tree-for-titanic.html#cb2-9"></a>conMat<span class="op">$</span>table</span></code></pre></div>
<pre><code>##           Reference
## Prediction   0   1
##          0 468 109
##          1  81 233</code></pre>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="the-simplest-decision-tree-for-titanic.html#cb4-1"></a><span class="co">#show percentage of same values - accuracy</span></span>
<span id="cb4-2"><a href="the-simplest-decision-tree-for-titanic.html#cb4-2"></a>predict_train_accuracy &lt;-<span class="st"> </span>conMat<span class="op">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>]</span>
<span id="cb4-3"><a href="the-simplest-decision-tree-for-titanic.html#cb4-3"></a>predict_train_accuracy</span></code></pre></div>
<pre><code>## Accuracy 
##   0.7868</code></pre>
<p>A brief assessment shows our model1’s accuracy is 79%. It is not bad! Let us use this model to make a prediction on test dataset.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="the-simplest-decision-tree-for-titanic.html#cb6-1"></a><span class="co"># The firs prediction produced by the first decision tree which only used one predictor Sex</span></span>
<span id="cb6-2"><a href="the-simplest-decision-tree-for-titanic.html#cb6-2"></a>Prediction1 &lt;-<span class="st"> </span><span class="kw">predict</span>(model1, test, <span class="dt">type =</span> <span class="st">&quot;class&quot;</span>)</span></code></pre></div>
<p>Our prediction is produced. Let us submit to Kaggle for an evaluation. We need to convert our prediction into Kaggle required format and save it into a file and name it as “Tree_Model1.CSV”. Here, the importance is knowing the procedure.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="the-simplest-decision-tree-for-titanic.html#cb7-1"></a><span class="co"># produce a submit with Kaggle required format that is only two attributes: PassengerId and Survived</span></span>
<span id="cb7-2"><a href="the-simplest-decision-tree-for-titanic.html#cb7-2"></a>submit1 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">PassengerId =</span> test<span class="op">$</span>PassengerId, <span class="dt">Survived =</span> Prediction1)</span>
<span id="cb7-3"><a href="the-simplest-decision-tree-for-titanic.html#cb7-3"></a><span class="co"># Write it into a file &quot;Tree_Model1.CSV&quot;</span></span>
<span id="cb7-4"><a href="the-simplest-decision-tree-for-titanic.html#cb7-4"></a><span class="kw">write.csv</span>(submit1, <span class="dt">file =</span> <span class="st">&quot;Tree_Model1.CSV&quot;</span>, <span class="dt">row.names =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<p>Once we submit this result to Kaggle. Kaggle will evaluate our results and provide a feedback score. That is a good way to know how good the model performed for unknown data. The Kaggle feedback tells us that we have scored <strong>0.76555</strong>. It means our prediction’s accuracy is <strong>76.555%</strong>. This accuracy is lower than the accuracy we have assessed with the training dataset, which was <strong>78.68%</strong>.</p>
<p>Let us look a bit more into our prediction model’s performance. We check our prediction’s death and survive ratio on the test dataset and compare with the same ratio on the train dataset.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="the-simplest-decision-tree-for-titanic.html#cb8-1"></a><span class="co"># Inspect prediction</span></span>
<span id="cb8-2"><a href="the-simplest-decision-tree-for-titanic.html#cb8-2"></a><span class="kw">summary</span>(submit1<span class="op">$</span>Survived)</span></code></pre></div>
<pre><code>##   0   1 
## 266 152</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="the-simplest-decision-tree-for-titanic.html#cb10-1"></a><span class="kw">prop.table</span>(<span class="kw">table</span>(submit1<span class="op">$</span>Survived, <span class="dt">dnn=</span><span class="st">&quot;Test survive percentage&quot;</span>))</span></code></pre></div>
<pre><code>## Test survive percentage
##      0      1 
## 0.6364 0.3636</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="the-simplest-decision-tree-for-titanic.html#cb12-1"></a><span class="co">#train survive ratio</span></span>
<span id="cb12-2"><a href="the-simplest-decision-tree-for-titanic.html#cb12-2"></a><span class="kw">prop.table</span>(<span class="kw">table</span>(<span class="kw">as.factor</span>(train<span class="op">$</span>Survived), <span class="dt">dnn=</span><span class="st">&quot;Train survive percentage&quot;</span>))</span></code></pre></div>
<pre><code>## Train survive percentage
##      0      1 
## 0.6162 0.3838</code></pre>
<p>The result shows that among total of 418 passenger in the test dataset, 266 passenger predicted perished (with survived value 0), which counts as 64% and 152 passenger predicted to be survived (with survived value 1) and which count as 36%. This is not too far from the radio on the training dataset, which was 62% survived and 38% perished see <a href="#survive"><strong>??</strong></a>.</p>
<p>We know that our model only had one test condition which is <em>Sex</em>. From the train dataset we knew that the gender ratio was very similar to this number.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="the-simplest-decision-tree-for-titanic.html#cb14-1"></a><span class="co"># add Sex back to the submit and form a new data frame called compare</span></span>
<span id="cb14-2"><a href="the-simplest-decision-tree-for-titanic.html#cb14-2"></a>compare &lt;-<span class="st"> </span><span class="kw">data.frame</span>(submit1[<span class="dv">1</span>], <span class="dt">Sex =</span> test<span class="op">$</span>Sex, submit1[<span class="dv">2</span>])</span>
<span id="cb14-3"><a href="the-simplest-decision-tree-for-titanic.html#cb14-3"></a><span class="co"># Check train sex and Survived ratios</span></span>
<span id="cb14-4"><a href="the-simplest-decision-tree-for-titanic.html#cb14-4"></a><span class="kw">prop.table</span>(<span class="kw">table</span>(train<span class="op">$</span>Sex, train<span class="op">$</span>Survived), <span class="dt">margin =</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>##         
##               0      1
##   female 0.2580 0.7420
##   male   0.8111 0.1889</code></pre>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="the-simplest-decision-tree-for-titanic.html#cb16-1"></a><span class="co"># Check predicted sex radio</span></span>
<span id="cb16-2"><a href="the-simplest-decision-tree-for-titanic.html#cb16-2"></a><span class="kw">prop.table</span>(<span class="kw">table</span>(compare<span class="op">$</span>Sex, <span class="dt">dnn=</span><span class="st">&quot;Gender ratio in Test&quot;</span>))</span></code></pre></div>
<pre><code>## Gender ratio in Test
## female   male 
## 0.3636 0.6364</code></pre>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="the-simplest-decision-tree-for-titanic.html#cb18-1"></a><span class="co">#check predicted Survive and Sex radio</span></span>
<span id="cb18-2"><a href="the-simplest-decision-tree-for-titanic.html#cb18-2"></a><span class="kw">prop.table</span>(<span class="kw">table</span>(compare<span class="op">$</span>Sex, compare<span class="op">$</span>Survived), <span class="dt">margin =</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>##         
##          0 1
##   female 0 1
##   male   1 0</code></pre>
<p>It is clear that our model is too simple: it predicts any male will be perished and every female will be survived! This is approved by the gender (male and female) ratio in the test dataset is identical to the death ratio in our prediction result.</p>
<p>Further, our predicted results’ survival ratio on sex is 0% male and 100% female. It makes sense, doesn’t it? Since our model was trained using the train dataset. The survive ratio based on gender were as: only 19% male survived and 81% of male perished. Similarly, Female survival rate was 74% survived and only 26% was perished.</p>
<p>Any prediction model will have to go for majority. But, we cannot be satisfied with this simple model that only looking into sex of given dataset and predict a passenger’s fate with sex!</p>
<p>This is only the starting, we can improve on it later. But before we do, let us have a close look into our model (the tree structure) and have a sense of the results it produced. R has a lot of functions to help. Plot is a visual tool we can use to visual our model.</p>
<div class="figure" style="text-align: center"><span id="fig:tree1"></span>
<img src="07-decision-tree_files/figure-html/tree1-1.svg" alt="The decision tree only has *Sex* test condition." width="672" />
<p class="caption">
Figure 1.5: The decision tree only has <em>Sex</em> test condition.
</p>
</div>
<p>This graph is pretty and informative. The first box top number is the voting (either 0 - dead or 1-survived). The two percentages shows the value of the splitting (also called <strong>voting</strong> or <strong>confidence</strong>). The final number on each node shows the percent of population which resides in this node. Also the color of nodes signify the two classes here. For example, the root node, “0” (death) shows the way root node is voting; “.62” and “.38” represents the proportion of those who die and those who survive; 100% implies that the entire population resides in root node.</p>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="decision-tree-in-hunts-algorithm.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="the-decision-tree-with-core-predictors.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown/edit/master/inst/examples/%s",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "none"
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
