---
title: "Plotting"
output:
  pdf_document:
    fig_caption: yes
---


# Understand Data


```{r fig.align = 'center', out.width = "80%", echo=FALSE, fig.cap ="" }

knitr::include_graphics(here::here("images", "buildingmaterial.png"))

```

Understand your building raw materials can help you choose correct tools and make the most use of them to construct your ideal buildings. 

**Understand data** is the foundation for solving analytical problems. The two major purposes of understand data are: 

1. Access data quantity 
2. Access data quality 
3. Set up objects for **data preprocess**

In practice the two initial data assessments can be done together or separately. The purpose of them is to setup objective for **data preprocess** to accomplish. The methods used to understand data can be both Descriptive analysis and Exploratory analysis.

## Load data 

Here are my initial plan for understand Titanic data:

1. Get Titanic data load into RStudio
2. Assess Data quantity (number of files, size of each file in number of records, number of attributes in each record)
3. Attributes types assessment
4. Attributes value assessment (numbers and summary, description).

Now, get your RStudio ready. 

If you have not done the Exercises 2.5, which asked you to create a new R project named "MyDataScienceProject". You can do it now.

Open your RStudio, Click File-> New project->New Directory -> choose New R Project", then, enter "MyDataScienceProject" in the Directory name box and select your directory. Click "Create Project" at the right bottom as shown in Figure \@ref(fig:newproject) 


```{r newproject, fig.align = 'center', out.width = "95%", fig.cap = "Create a new project in RStudio ", echo=FALSE }
knitr::include_graphics(here::here("img", "NewProject.png"))
```

Load file "TitanicDataScience1.R" into RStudio. create a new R file and name it "MyTitanicDataScience1". 

The protocol is you copy lines indicated from this tutorial "chunk" by "chunk" into your R file and run them. 

Okay let us start,

In your RStudio (WorkSpace), copy lines from "TitanicDataScience1.R" into your file "MyTitanicDataScience1",

```{r}
# Load raw data
train <- read.csv("train.csv", header = TRUE)
test <- read.csv("test.csv", header = TRUE)
```
You will see this in your Console,

```markdown
> train <- read.csv("train.csv", header = TRUE)
Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") :
  cannot open file 'train.csv': No such file or directory
> test <- read.csv("test.csv", header = TRUE)
Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") :
  cannot open file 'test.csv': No such file or directory
> 
```
Don't panic. let us look into it.

The first thing I want you to learn is to use RStudio help. Remember how to use it?

Now type **`? read.cvs`** in your Console, look at the Multifunction pane, the tab **Help** is auto selected and help message for **`read.cvs`** is appeared. See Figure \@ref(fig:Rhelp)


```{r Rhelp, fig.cap='Screen capture of Error and Help', out.width='95%', fig.asp=.75, fig.align='center', echo=FALSE }

knitr::include_graphics("img/Rhelp.png")

```

Now, notice that the error message says, "`cannot open file 'test.csv': No such file or directory`". We don't have file `train.csv` and `test.csv` in our working directory.

Now, Download the `traon.csv` and `test.csv` from Kaggle (if you did not download already) and stored into our project working directory^[The data files were asked to be downloaded and unzipped in the previous chapter \@ref(act-download) . If you simply unzip it into the working directory, it will exists in "~/Titanic/" directory. In this case, you need to move them into your working directory.].


Please note that it is a common practice that data scientist download datasets from data sources and save to a local drive. Having a local version of the raw datasets is good idea. But a lot of times, it is unfeasible to do so either because the data is too big or there are some access restriction prevent you have a local version. So, you have to using service provider's API or data URI through HTTP protocol or other protocol like FTP etc. 

Once, you have download the datasets from Kaggle website and unzipped (or moved) them into your local working directory, run the same code again by select them all and click "Run" or type "Ctr + Enter" .

You will see the two new attributes have been created and displayed in the **WorkSpace pane**. See Figure \@ref(fig:importdata).

```{r importdata, fig.cap='Screen capture of import raw data', out.width='95%', fig.asp=.75, fig.align='center', echo=FALSE }

knitr::include_graphics("img/importdata.png")

```


```{block2, ToDo41, type='rmdaction'}
Try yourself:

Import data from **WorkSpace pane** by click "**Import Dataset**" button.
```

## Assess Data Quantity 

After we have load the raw data into our WorkSpace, we can start to explore and exam the raw data.

In R code, the best way to explore a dataset and get the first impression on its size (number of records and numbers of attributes) is using `str()` function. If you wan tot know more about it, as I mentioned earlier, using help by typing `? str()` in your Console. There is an equivalent R code is called `help <statement>`, you can try `help str()`.

Now let us run the following code,

```
# Exam train and test datasets
train <- read.csv("train.csv", header = TRUE)
test <- read.csv("test.csv", header = TRUE)
```
You will see this in your console, Figure \@ref(fig:Rstr).

```{r Rstr, fig.cap='Screen capture of str(tain) and str(test)', out.width='130%', fig.asp=.75, fig.align='center', echo=FALSE }

knitr::include_graphics("img/RstrResult.png")

```

Firstly, you will see the size of the two datasets: 

- train has **891 records** and each record has **12 attributes**. Okay, R uses statistics terminology, observation is record in data science term. properties of an observation are attributes of a record. Notice that train has a type of data.from. Data.frame is the most used data type in R. (Try `?data.frame` to explore)
- test has **418 records** and each record has **11 attributes**, which are less than train's in both number of records and attributes. 

Dataset `test` has less number of records makes sense because any model you need large data to train and less data to test ( it will become clear later). However, why `test` has one less attribute? compare with `train`, it is easy to find out that the missing attribute is *Survived*. Do you understand now? The dataset `test` is supposedly to be used for testing our model (we will have it later) for predicting passengers' have lived and dead. So, it should not have a value now. The entire problem is for us to come up with a value on the attribute.   

RStudio has a conveniently build-in function to explore data size. At the **WorkSpace pane**, you can see the under **Environment** tab, the two attributes we have created are listed there. In font of each attribute there is a 
![](img/arrow.png) sign. click it you can exam its size and structure. It is equivalent to run `str()` R instruction. You can also lick on the attribute name to explore the entire dataset. 

```{block2,  type='rmdaction'}
Try yourself:

At RStudio **WorkSpace pane**, 

Click varaible name `train` and `test` to explore the contents of datasets.

Click on the ![](img/arrow.png) sign in front of attribute to explore it sstructure. 
```

## General Data Attributes Assessment

After a brief assessment on the data quantity, we know that the both datasets are not too big in terms of both number records (891 and 418) and number of attributes (12 and 11). We also have an intuitive understanding about the attributes, some obvious names like *Name*, *Sex* and *Age*; and some not so obvious names like *SibSp* and *Parch*. 

Before we looking into individual attributes (single variate analysis) in our datasets, let us get some general sense of all attributes and make sure we understand each of them.

We knew that dataset `test` has 11 attributes and `train` has 12 attributes. The one attribute short is the *Survived*. The rest are the same. Let us look into those attributes, the following is from the Kaggel web site:

```{r  out.width='100%', fig.cap= "Data Dectionary from Kaggle website.", fig.asp=.75, fig.align='center', echo=FALSE }

knitr::include_graphics("img/DatafrKaggle.png")

```

```
attribute Notes
*Pclass*: A proxy for socio-economic status (SES)
1st = Upper
2nd = Middle
3rd = Lower

*Age*: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5

*Sibsp*: The dataset defines family relations in this way...
*Sibling* = brother, sister, stepbrother, stepsister
*Spouse* = husband, wife (mistresses and fiancÃ©s were ignored)

*Parch*: The dataset defines family relations in this way...
Parent = mother, father
Child = daughter, son, stepdaughter, stepson
Some children travelled only with a nanny, therefore parch=0 for them.
```
Just looking into these attributes' description, a few thoughts are occurred:

1. Attribute types

There are attributes should be categorical types. The values of those attributes can be any types but the importance is that they can classify the records into sets of similar groups and this grouping make sense to the problem to be solved. In Titanic datasets, attributes should have **categorical** type are: *Survived*, *Sex*, *Embarked*, and *Pclass*.

Other attribute perhaps should have numerical type. Thsi is because these attributes values change from record  to record. They can be  the values of discrete, continuous, or timeseries. One thing in common is that these values can be manipulated and applied with many math functions and plotting tools for visualization. In Titanic datasets, attributes should have **numerical** type are: *Age*, *Fare*, *SibSp*, *Parch*. 

2. Contribution to Survive

The final goal is to predict passenger's survived or not. It makes sense to assess the prediction power of each attribute. which is the contribution of an attribute to attrribute *Survived*. In other words, the potential relationships among these attributes and with the attribute *Survived* need to be assessed. Here are some thoughts:

- *Pclass* should somehow linked with *Fare* and *Cabin*. Generally, the higher the class is and the more expensive of the fare will be and the better cabin locations are. So those should have some sort of correlations among them. they together should have some affect on survive. You would think that the expensive ticket, means better cabin location and has privilege to escape first in the disaster.  

- What is the ticket number to do with survive? Is it just a random number? Or is associated with cabin? Or anything else like Port of embarkation? ticket number in some other systems could have more information rather than just an unique number. 

- Is the *Fair* in someways associated with journey length, which means the Port of embarkation and the port of disembarkation? Or cabin location and condition? 

You can have other thoughts too. To prove or disprove these assumptions and thoughts, we need to look into the actual datasets at least to see:

1. What are the data types for various attributes?

  - Which attributes are available in the dataset?
  - Which attributes are categorical?
  - Which attributes are numerical?
  - Which attributes are mixed data types?

2. Any errors in the attributes values?

  - Which features may contain errors or typos?
  - Which features contain blank, null or empty values?

These questions will be answered in the following two sections. 


## Actual Attributes Types Examination

Since we have our raw data in RStudio, We can exam attributes' types. From figure \@ref(fig:Rstr), we can see that all the attributes have three types, `int`, `Factor`, `num`.

Attributes have `int` types are: *PassengerId*, *Survived*, *SibSp*, *Parch*.

Attributes has  `Factor` types are: *Name*, *Sex*, *Ticket*, *Cabin* and *Embarked*.

Attributes has `num` types are: *Age* and *Fare*. 

We know that, the type `int` is for attribute that has an integer value; and `num` is for an numeric attribute, which has the values of real numbers.

Type `Factor` is R language's way to say category type. It is a attribute that can take on one of a limited, and usually fixed, number of possible values, such as blood type.

Attributes types affect the operations we can apply on that attributes. In other words inappropriate types can prevent us to do proper analysis on that attribute. For example, it doe's not make sense to calculate average on sex, so it is better to be with a type of Category, in R is a `Factor`. Similarly, *Survived* will have only two values 0 or 1, to represent death or live. It makes sense to be an `Factor` too. Being a `int` type, it will prevent us to apply many methods that only works for a `Factor` type attribute. 

Another example is *Name*, its original type is *Factor* to reflect on its uniqueness. However, Type "Factor" is not good for string processing. It has been prevented that to apply regular expression^[A regular expression is a sequence of characters that define a search pattern, which is used by string-searching algorithms to find a particular string or validate a input string.] on it. So, it is appropriate to change it into *chr* as a character.

There are other inappropriate or wrong attribute's types too such as *SibSp* and *Parch* are currently typed *int*. May be they should be considered as *Factor*. It is a common practice that data scientists apply different analyses on a attribute and change the attribute type to apply other different algorithms again. The goal is to dig the insight out of data.   

So, looking into data attributes types, compare with the original meaning of each attributes can help us to spot any inappropriate types or wrong types. 


```{block2,  type='rmdthinking'}
Thinking:

Is **Servived typed** `int` approriate?
  
What other attributes do you think are in a wrong type?
  
```

## Actual Data Attributes Value Examination {#attvalue}

To understand given datasets needs to carefully examine the values of each data attributes to:

- find any errors and missing values
- find value distribution 
- find potential relation with the attribute to be predicted (also called dependent variable)

Finding errors, typos and missing values can set up the goals for data prepsocess. 

Since the examine covers both datesets `train` and `test`, it make sense to combine the two datasets into one big dataset, so it can save us to run the same code twice on the different datasets.

Copy the following code into your script,

```{r}
# Add a "Survived" attribute to the test dataset to allow for combining with train dataset

test <- data.frame(test[1], Survived = rep("NA", nrow(test)), test[ ,2:ncol(test)])

# Combine data sets. Append test.survived to train
data <- rbind(train, test)

```
Now we have a dataset `data`, which combines both datasets `train` and `test` datasets. We assigned the value of attribute *Survived* in the original dataset `test` as "NA". You can check them in the **WorkSpace pane** by click variable data.  

```{block2,  type='rmdtry'}
Thinking:

1. Can we combine `train` and `test` without add *Survived* attribute to the test? Like,

```data <- rbind(train, test)```

2. Why add attibute *Survived* as the second attribute? Can we add it as the first one? Like,

```test <- data.frame(Survived = rep("NA", nrow(test)), test[,])```

```

It is good idea to have bird eye's view on our combined dataset.

```{r sofdata, fig.align = 'center', out.width = "95%" }
# check out data with a summary
summary(data)
```

This summary \ref{fig:sofdata} tell us a lot of information. Most obvious are:

1. *PassengerID* is useless in terms of predicting survived or not. in addition, it is not much help that provide a statistical summary on it. 
2. *Survived* and *Pclass* numbers are useful and interesting.
3. *Name* is mostly unique, which comes a surprise that only 2 names are repeated twice.
4. *Gender* distribution among passenger is unbalanced that male overweight female.
5. *Age* is interesting that minimum age 0.17 is alarming and there is 263 missing values.
6. *SibSp* tells us the largest relatives travel together is 8.
7. *ParCh* tells us the largest family travel together is 9.
8. There are a number of *ticket* has the same number. The most repeat number is CA. 2343, which has 11 duplicates. 
9. Ticket *Fare* shows the minimum is 0, which is interesting that someone take a free ride. The maximum is over 512, which is far too expensive when the mean value is only about 33. 
10. *Cabin* has a large number of missing values (identified by "").
11. *Embarked* only has three values which is not a good sign for prediction. it also has 2 missing value.

You can see now one function can provide so much information. Quantitative summary is a great tool for a data scientist. 

Now, Let us exam each attribute, 

### PassengerID. 

*PassengerId* is an identifier, So only its uniqueness and missing value are considered.
 
There are many ways you can use to find out. I simply check its total number and its unique number. If the both equal to the number of records in the dataset, it shows that there is no duplication and no missing values in the attribute. 

So we do,
 
```{r}
# Exam PassengerID

length(data$PassengerId)
length(unique(data$PassengerId))

```
The results shows the both number 1309, which is equal to the total number of records in the dataset. It proves the *PassengerID* has not missing value and duplication. 

### Survived

*Survived* is the attribute that its value will be produced by a model for the dataset `test`. It is called **Consequencer** in modeling contrast with other attributes. which are used to produce a prediction, are called **Predictor**.  So, our exam will be conducted only on dataset `train`. Again we can check the numbers whether they can add up or not. As we already mentioned that it makes sense to change the *Servived* from type `chr` into `Factor`. We do,

```{r} 
# Exam Survived
data$Survived <- as.factor(data$Survived)
table(data$Survived)
```
The results proved that the *Survived* value has the correct numbers: 

- 418 'NA' values are the *Survived*'s value in the  dataset `test`, and
- the 549 death and 342 survived, together maded up the total number of dataset `train `, which is 891. 

So we know the value of *Survived* in the dataset `train` are correct and has no missing values. It is interesting here to think about the survive rate. How to calculate? 

I will do this,
```{r}
# Calculate the survive rate in train data is 38% and the death rate is 61.61%
prop.table(table(as.factor(train$Survived)))
```
So we know the survive rate in the dataset `train` is about 61%. This is interesting because it reflects the overall survival rate.

### Pclass

*Pclass* is the feature which splits the passengers into three division namely class-1, class-2, class-3. As we understood it should be in type of `Factor` rather than `int`. We shall change its type first and then to see if there missing value or errors. It is also good to know the survival rate in each class. So. we can compare with the overall survival rate in the dataset `train`.

Copy the following code into your script.
```{r}
# Examine Pclass value,
# Look into Kaggle's explanation about Pclass: it is a proxy for social class i.e. rich or poor
# It should be factor and it does not make sense to stay in int.
data$Pclass <- as.factor(data$Pclass)
test$Pclass <- as.factor(test$Pclass)
train$Pclass <- as.factor(train$Pclass)

# Distribution across classes
table(data$Pclass)

```
If you want, you can check the total of the three classes which is 1309. It equals to the total number of records in the `data` (total number fo passenger). And there is no other numbers than 1,2 and 3. So we can conclude that there is no missing value and no errors in *Pcalss*.

It will be interesting to see the survival rate for each class,
```{r}
# Distribution across classes with survive
table(data$Pclass, data$Survived)
```
These numbers tell us many things: 

1. **The death distribution**. Among the three classes from class-1 to class-3 is: 80, 97 and 379. It confirms that the passenger in Class-3 has largest number of death (372);

2. **The survival distribution**. Among the three classes, class-1 has the highest number of survival (136);

3. **The passengers distribution**. Among the three classes, class-3 has the largest passenger numbers (372+119+218) in total, and overtaking other two classes together for both datasets `train` and `test` (372+119) > ((80+97) + (136+87)). 

4. The last column is the pasenger distribution among the three glasses for dataset `test`. This is because its *Survived* value is "NA" (not defined).

We can calculate distributions among the three classes in terms of percentage. 

1. The overall passenger's distribution among the three classes:
```{r}
# Calculate the distribution on Pclass
# Overall passenger distribution on classes.
prop.table(table(as.factor(data$Pclass)))
```
That is 24.67% passenger in Class-1, 21.16% passenger is class-2 and 54.16% of passenger in class-3.

2. The passenger's distribution among the three classes given by dataset `train`:
```{r}
# Train data passenger distribution on classes.
prop.table(table(as.factor(train$Pclass)))
```
The number tells us the distribution of passengers from  dataset `train` is: class-1, 24.24%; class-2, 20.65% and class-3 has 55.1%.

3. The passenger's distribution among the three classes given by dataset `test`:

```{r}
# Test data passenger distribution on classes.
prop.table(table(as.factor(test$Pclass)))
```
Lastly, the passenger distribution from dataset `test` are: 25.6% in class-1, 22.24% in class-2 and 52.15% percent in class-3.

We can see that the distribution of passengers, in terms of percentage, among the three classes are almost identical both in order and in proportion. That is the most passenger are in class-3, then class-1 and finally class-2.

Let us look into death and survive distribution among the three classes^[This code is not brilliant. It used many intermediate variables, you can check their structure and contents from **WorkSpace pane**. You can come up with a better code.],
```{r}
# Calculate death distribution across classes with Train data
SurviveOverClass <- table(train$Pclass, train$Survived)
# Convert SurviveOverClass into data frame
SoC.data.fram <- data.frame(SurviveOverClass) 
# Retrieve death distribution in classes
Death.distribution.on.class <- SoC.data.fram$Freq[SoC.data.fram$Var2==0]
prop.table(Death.distribution.on.class)
```
These numbers tell us the distribution of death among the three classes are: 14.57% death from class-1, 17.66% from class-2 and 67.75% death from class-3. 

Similarly, we can calculate survive distribution among the three classes, 

```{r}
# calculate survive distribution among the three classes
Survive.distribution.on.class <- SoC.data.fram$Freq[SoC.data.fram$Var2==1]
prop.table(Survive.distribution.on.class)
```
The results tell us that 39.76% of survived passenger are from class-1, and 25.43% from class-2, and 34.79% from class-3.

Let us thinking about this numbers. Class-3 has 55.1% of passenger distribution but has 34.79% passenger survival distribution. Clearly, the survive rate in class-3 is lower than other two classes. It is equivalent to say, **the survival chances of a passenger who is in class-1 are higher than who is a class-2 and class-3**.

```{block2,  type='rmdaction'}
Do it yourself:
  
Calculate the Survival rate among the three classes. What conclusion you have by compare them?
```

Numbers are good to provide summary and test some assumptions. Analyzing given data by means of statistical summary and other numbering methods is called **Descriptive analysis**. See section \@ref(analyse) .

Perhaps, it is a good time to introduce **Exploratory analysis**, on the contrast with the Descriptive analysis, it uses graphical tools to explore the inside of given datasets.

To do so, we need to import some useful graphical tools provided by R community. We can then use them to plot *Survived* as an factor on *Pclass* numbers.

```{r Survivalrate, fig.cap = "Total count and survive rate of passenger on Pcalss."}

# Load up ggplot2 package to use for visualizations
library(ggplot2)

ggplot(train, aes(x = Pclass, fill = factor(Survived))) +
  geom_bar(width = 0.3) +
  xlab("Pclass") +
  ylab("Total Count") +
  labs(fill = "Survived")
```

Graph is better, isn't it? It is very intuative. 

Let's briefly interpret this graph. The graph shown \@ref(fig:Survivalrate) tells us that the survive rate in Class-3 is the worst, and followed by class-2 and lastly, class-1. More people perished in the class-3 than any other two classes. It provides an important point that the chance of survive is associated with the **social glass**, if we can prove the Class-3 ticket is cheaper. 

To sum up the analysis with Pclass, We have used both **Descriptive analysis** and **Exploratory analysis**. The results suggested that **the *Pclass* has a strong relation with death rate**. That is passengers in Class-3 have a higher chance of death. The correlation with social class (richer or poor) is waiting to be proved if the class-3 ticket is cheaper than others.  

### Name
 
*Name* attribute by definition shows peoples' name. It should not have any impact on passengers' live and death. Never heard of someone was survived because one's name! 
 However we still need to asess its quality. Fir
 
Firstly, you may notice that the type of *Name* is a `Factor`, which is contradicted with the conventional understanding that name is a string or a list characters. Type `chr` would be more appropriate. Change its type to `chr` will help us to apply character functions to it and get it contents easily. Factor shows the uniqueness. it could help us to assess if there is missing value or duplicated values. 

Notice that attribute *Name* only has 1307 levels (can be observed from the `data` structure on the **WorkSpace pane**). In addition, the `data` summary, see Figure \@ref(fig:summaryofdata), not only confirmed this but also identified the two shorts because of the value "Connolly, Miss. Kate" and "Kelly, Mr. James" have been repeated twice each. 

Let us explore *Name* values in details.
Firstly, let us convert *Name* type into `chr`. Then we can check duplicated names using `which` function in R to get the duplicate names and store them into a vector `dup.names`. And echo them out. 

```{r}
# Convert Name type
data$Name <- as.character(data$Name)
# Find the two duplicate names
# First used which function to get the duplicate names and store them as a vector dup.names 
# check it up ?which.
dup.names <- data[which(duplicated(data$Name)), "Name"]

# Echo out 
dup.names
```
Our code confirmed that the two duplicated names are indeed ""Kelly, Mr. James" and "Connolly, Miss. Kate". It comes no surprise that the both names are pretty common in UK and USA.

One discovery though is that the names appeared has a title in it! **Mr.** is used in Kelly James and **Miss.** is used in Connolly Kate. This could be interesting. We can leave this for **Preprocess** to explore more. For the quality assessment it is mission accomplished. 
 
### Sex

*Sex* attribute value assessment is simple. Its type `Factor` helps a lot. Since it only has two values "male" and "female", we could easily check if there are missing values and any errors.   


```{r}
# Use summary to check numbers and distribution
summary(data$Sex)
# If you prefer you can use data.table functions
```
It is obvious that there is no error and missing values. The result confirms this: male 843 and female 466, together we have 1309 passengers, which is the total numbers of the passenger.  

It is also simple to explore the relationship between gender and the survival rate. We had an assumption that the male passengers have a high death rate. We have plot tools in our disposal, let's make use of it. Since only dataset `train` has the values on *Survived*, it makes sense that we only plot relation between gender and survival on dataset `train`.

```{r Survivalrateonsex, fig.cap = "Total count and survive rate of passenger on sex."}
# plot Survived over Sex on dataset train
ggplot(data[1:891,], aes(x = Sex, fill = Survived)) +
  geom_bar(width = 0.3) +
  xlab("Sex") +
  ylab("Total Count") +
  labs(fill = "Survived")

```

The graph shows that the male death rate is much higher than female passengers. 

```{block2,  type='rmdthinking'}
Thinking:

We have used `data[1:891,]` in our `ggplot` code. Why we do not use dataset `train` instead? What are the differnce if there is any?
  
```

### Age

To examine values of attribute *Age*, we do this,

```{r}
# Examine Age over data, train and test.
summary(data$Age)
summary(train$Age)
summary(test$Age)
```
These summary tell us that the minimum, median, mean, maximum and missing values (as NA). They are useful. but they failed telling us on the value distribution. 

```{r eval=FALSE, include=FALSE}
#it makes sense to change age type to Factor to see distribution
summary(as.factor(data$Age))
```

```{r ats, fig.cap="*Age* summary as categorical data.", fig.align = 'center', out.width = "80%", echo=FALSE} 

knitr::include_graphics(here::here("img", "ageresult.png"))

```

From Figure \@ref(fig:ats), we can see a few problems:

1. Age values have decimal point which is a sort of surprise and not sure if it is a mistake.

2. There are large number of missing values: 177 missing value in dataset `train` and 86 missing value in dataset `test`, in total of 263, which count as 263/1309 = 20%. large number of missing values sets up a task for **data preprocess** to deal with. In the same time, it make you think whether it is a valid predictor or not.

We can assess its impact on survive rate. So we need to look into dataset `train`.

```{r age, fig.align = 'center', fig.show="hold", out.width = "50%", fig.cap = "*Age* ditribution and its Survive rate of passenger"}
# plot distribution of age group
ggplot(data, aes(x = Age)) +
  geom_histogram(binwidth = 10, fill="steelblue") +
  xlab("Age") +
  ylab("Total Count")

# plot Survived on age group using train dataset
ggplot(data[1:891,], aes(x = Age, fill = Survived)) +
  geom_histogram(binwidth = 10) +
  xlab("Age") +
  ylab("Total Count")

```

The graph shows the relationship between *Age* and survival rate. It becomes apparent that age group between 15 and 25 has the worst survival rate. It is also interesting to know that there are some age has values less than 0! 

With this, we could conclude that.

The attribute *Age* has a serious quality problem: some age values are negative and large number 177 values are missing. If it is to be used as a predictor in our model for prediction, it needs a lot of work in the stage of preprocess. 

### SibSp 

Attribute *SibSp* represents passenger's siblings and sprouts who travels with the passenger. We will a have pretty good idea about its values. This will help us to spot any errors and missing values.

We do this,
```{r}
### Exam SibSp, Its original type is int
summary((data$SibSp))

# How many possible unique values?
length(unique(data$SibSp))

#is there an y missing values? check the total number
length(data$SibSp)

# Treat it as a factor, so we know the value distribution
data$SibSp <- as.factor(data$SibSp)
summary(data$SibSp)
```
The results have provided us with good evidence for access its values. Firstly, we know the minimum value is 0, and there are 891 records have 0 values. It means that there are 891 passenger who travel without siblings and sprouts; secondly, apart from the value 0, the 3 quarters of the passenger who has 1 company; and lastly the maximum number of the company a passenger had is 8. There are 9 of them. There are totally 7 kinds of company in terms of the numbers of company a passenger can have.

It has not error or missing value since the total number are correct. 

We can assess its prediction power by looking into the relationship between *SibSp* and *Suvivied*,

```{r SibSp, fig.align = 'center', fig.show="hold", out.width = "50%", fig.cap = "Plot *SibSp* distribution among the 7 values and its survive rate."}
# plot entire SibSp distribution among the 7 values
ggplot(data, aes(x = SibSp)) +
  geom_bar(width = 0.5) +
  xlab("SibSp") +
  ylab("Total Count")+
  coord_cartesian()

# Plot on the survive on SibSp
ggplot(data[1:891,], aes(x = SibSp, fill = Survived)) +
  geom_bar(width = 0.5) +
  xlab("SibSp") +
  ylab("Total Count")  +
  labs(fill = "Survived")
```
We run two plots: the first one is the value distribution on entire dataset to have an impression on its distribution shape; and the second one is checking the survival rate over its distribution groups by dataset `train`. It seems that passenger who have two companies tend to have a better survival rate. This could be an interesting pattern to explore. 

```{block2,  type='rmdaction'}
Do it yourself:
  
Calculate the Survival rate among the 7 possibilities in terms of have siblings or sprouds treval with them. What conclusion you have by compare them?
```

We can conclude that the value of `SibSp` have a pretty good quality and there is no apparent error and missing values. Its predication power needs further investigation but it is informative.

### Parch 

Attribute *Parch*, similar with *SibSp*, is representing the travel company or groups. *Parch* specifically represents parents or children. I don't know why Kaggle separate them but it seems reasonable to think they together represent one thing that is "travel with family". 

To access its value, we will do the same as we did on `SibSp`.

```{r}
### Exam Parch, Its original type is int
summary((data$Parch))

# How many possible unique values?
length(unique(data$Parch))

#is there an y missing values? check the total number
length(data$Parch)

# Treat it as a factor, so we know the value distribution
data$Parch <- as.factor(data$Parch)
summary(data$Parch)
```
The discovery is similar again with *SibSp*, that is:
1. The minimum value is 0, and there are 1002 records have 0 values. It means that there are 1002 passenger who travel without without parents or children (we still cannot see the passenger travel alone, he or she could travel with a sibling or a sprout, However, this rise an idea to look into passenger who travel alone, which means no sibling, sprout, parents and children.); 
2. The maximum number is 9. There are 2 of them.
3. Apart from the value 0, the largest company number is 1. There are 170.
4. There are totally 8 possibilities in terms of the numbers of company a passenger can have.
5. It has not error or missing value since the total number are correct. 

We can assess its prediction power too by looking into the relationship between *Parch* and *Survived*,

```{r Parch, fig.align = 'center', fig.show="hold", out.width = "50%", fig.cap = "Plot *Parch* distribution among the 8 values and its survive rate."}
# plot entire Parch distribution among the 7 values
ggplot(data, aes(x = Parch)) +
  geom_bar(width = 0.5) +
  xlab("Parch") +
  ylab("Total Count")+
  coord_cartesian()

# Plot on the survive on Parch
ggplot(data[1:891,], aes(x = Parch, fill = Survived)) +
  geom_bar(width = 0.5) +
  xlab("Parch") +
  ylab("Total Count")  +
  labs(fill = "Survived")
```
The plot shows us that it is definitely have impact on survival. But it i snot clear the prediction power in comparison with *SibSp*. I am not sure there are difference between "travel with parents or children" and "travel with siblings and sprout". In addition, value 0 in each attributes does not excludes other attributes. Travel without parents or children does not mean travel without siblings or sprout. If we try to see the impact on survived in terms travel alone or with a company, we need to re-engineer these attributes. It is a good point anyway and give another task for **data preprocess ** to do.

### Ticket
Intuitively, as mentioned before, ticket number like passenger names, should not be considered as bounded with the survival of a passenger. Unless the ticket number has other hidden information such as class or location on the boat. Bearing this in mind, let us assess its value.
```{r }
head(summary(data$Ticket),50)
# Take a look at the ticket value
str(data$Ticket)
which(is.na(data$Ticket))
```
The value of *Ticket* appears has no missing value and there are 929 different numbers and some with letters and some with special characters like "." and "/". There is no immediately apparent structure in the data.
 Let us plot them and also see if there is any pattern with survival.
 
```{r  tecket, fig.align = 'center', fig.show="hold", out.width = "50%", fig.cap = "Plot of *Ticket* distribution and survival rate."}
#plot it value 
ggplot(data[1:891,], aes(x = Ticket)) +
  geom_bar() +
  xlab("Ticket") +
  ylab("Total Count")
# Plot on the survive on Ticket
ggplot(data[1:891,], aes(x = Ticket, fill = Survived)) +
  geom_bar() +
  xlab("Ticket Number") +
  ylab("Total Count")  +
  labs(fill = "Survived")
```
The same tickets number has such a small number. It does not have any statistical meaning. It is possible to reengineer *ticket* number into groups like "number only" vs "with letter" or "with special characters", or simply group them with the length of the ticket or with the initials, etc. There is a lot of thing you can do to see if there is any patterns connected with the survival. 

Over all, *Ticket* has a good quality and has no missing value and errors (we dont count repeated ticket number is an error). However, there is no obvious relations with the survive rate.

### Fare
The value of *Fare* are expected associated with "passenger's wealth". You would naturally associate its value with cabin condition and perhaps location of he cabin. Let us assess its value quality.

```{r}
summary(data$Fare)
length(unique(data$Fare))
```
The initial assessment tells us that:
1. The value of `Fare` has one missing value.
2. They are 282 different prices among 1308 tickets.
3. The minimum value is 0 (Free ride?) and the maximum value is 512.329. 
4. The mean value is 33.295 and the median is only 14.454. 
5. There are two potential issues in here: 512.329 is extremely higher than others, it could be considered as an outlier or an error; another potential issue is the precision. Any currency cannot have a physical money which carry value three digits after the decimal point. so any value has three digits after decimal point could be an error.  

Let us examine the prediction power of attribute *Fare*.

```{r  Fareplot, fig.align = 'center', fig.show="hold", out.width = "50%", fig.cap = "Plot of *Fare* distribution and survival rate."}

ggplot(data, aes(x = Fare)) +
  geom_histogram(binwidth = 5) +
  ggtitle("Fare Distribution") +
  xlab("Fare") +
  ylab("Total Count") +
  ylim(0,200)
# Let's check to see if fare has predictive power
ggplot(data[1:891,], aes(x = Fare, fill = Survived)) +
  geom_histogram(binwidth = 5) +
  xlab("Fare") +
  ylab("Total Count") +
  ylim(0,50) + 
  labs(fill = "Survived")
```
It is not clear about *Fare* prediction power. One thing is clear that to be useful for predcition, Fare needs more engineer such as group it in different groups like <5, 5 to 10, 10 to 15, ..., etc.

### Cabin

*Cabin* has a large number of missing values as we noticed from the beginning of this section \@ref(attvalue). So its quality is expected to be bed. let us find out how many missing values is the dataset `train`, so we can assess its predictive power over survive. 

Firstly, by looking into the structure of the dataset, 

```{r}
# Examine cabin values
str(data$Cabin)
# Cabin really isn't a factor, make a string and the display first 100
data$Cabin <- as.character(data$Cabin)
data$Cabin[1:100]
```

we find out that *Cabin* is in a type of `Factor` and has 187 unique values with empty string "" and string start with letter like "A10".

By looking actual 100 values, we have a pretty good understand its contents. Notice that some string looks like multiple numbers, for instance "C23 C25 C27", it is odd in comparison with others. 

let us have a close look at the dataset `train` and assess its prediction power.
```{r}
# Find out number of the missing value in the train
train$Cabin <- as.character(train$Cabin)
# number of the missing value in the train
table(train[which(train$Cabin ==""), "Cabin"])
# percentage of the missing value in the train
table(train[which(train$Cabin ==""), "Cabin"])/length(train$Cabin)*100
```
The above code tells us that in the dataset `train`, there are 687 missing value and it count as 71 percent of total value. This is significant number. Generally it will write off the attribute for any meaning for use. However, like its relation with survive with the consideration of the missing value.

Since the small number of passenger in each cabin, we accumulate passenger with the first latter of the cabin number. That means we bin the passengers based on the first letter of their cabin number. Then we plot the survived number over the total number.

```{r Cabin, fig.align = 'center',  out.width = "90%", fig.cap = "Plot of the passenger number and  the survived number based on the first letter of their cabin number."}
# Take a look at just the first char as a factor and add to data as a new attribute
data$cabin.first.char<- as.factor(substr(data$Cabin, 1, 1))

# first cabin letter survival plot
ggplot(data[1:891,], aes(x = cabin.first.char, fill = Survived)) +
  geom_bar() +
  xlab("First Cabin Letter") +
  ylab("Total Count") +
  ylim(0,750) +
  labs(fill = "Survived")
```
To sumup, *Cabin* attribute has large number of missing value. The dataset `train` has 687 missing value and it counts as 71 percent of total value. Its prediction power is in serious doubt since it only has very small number for each cabin. To use it in any possible predictio model, it needs some re-engineering. 

### Embarkded

Attribute *Embarked* records where a passenger get on board. From the Kaggle data description we know that there are three possible values for Embark â Southampton (S), Cherbourg (C), and Queenstown (Q). Let's check the data quality.
```{r}
# Examine Embark values
summary(data$Embarked)
length(data$Embarked)
```
The results confirms that there two missing values and three ports. Southampton as its initial depart port has largest passengers get on board. Let's see its distribution and the survival rate.
```{r  Fare, fig.align = 'center', fig.show="hold", out.width = "50%", fig.cap = "Plot of *Embarked* distribution and survival rate."}
# Plot data distribution and the survival rate for analysis
ggplot(data, aes(x = Embarked)) +
  geom_bar(width=0.5) +
  xlab("Passenger embarked port") +
  ylab("Total Count") 


ggplot(data[1:891,], aes(x = Embarked, fill = Survived)) +
  geom_bar(width=0.5) +
   xlab("Embarked port") +
  ylab("Total Count") +
  labs(fill = "Survived")
```

The graph shows that about 70% of the people boarded from Southampton (914/1309 = 0.698). Just over 20% boarded from Cherbourg (270/1309 = 0.206) and the rest boarded from Queenstown about 10%.

```{r  embark, fig.align = 'center', fig.show="hold", out.width = "30%", fig.cap = "Plots of death distribution, survive distribution and death rate comparision over embarked port."}

# Calculate death distribution over Embarked port with Train data
# creat Embarked and Survived contingency table
SurviveOverEmbarkedTable <- table(train$Embarked, train$Survived)
# Death-0/survived-1 value distribution (percentage) based on embarked ports
# prop.table(mytable, 2) give us column (Survived) percentages
Deathandsurvivepercentage <- prop.table(SurviveOverEmbarkedTable, 2)
# Plot
M <- c("c-Cherbourg", "Q-Queenstown", "S-Southampton")
barplot(Deathandsurvivepercentage[2:4,1]*100, xlab =(""), ylim=c(0,100), ylab="Death distribution in percentage %",  names.arg = M, col="steelblue", main="Death distribution", border="black", beside=TRUE)
barplot(Deathandsurvivepercentage[2:4,2]*100, xlab =(""), ylim=c(0,100), ylab="Death distribution in percentage %",  names.arg = M, col="blue", main="Death distribution", border="black", beside=TRUE)

## Calculate survived RATE distribution based on embarked ports
# Death-0/survived-1 value distribution (percentage) based on embarked ports
# prop.table(mytable, 1) give us row (Port) percentages
# col-1 (Survived=0, perished) and col-2 (Survived =1, survived)
DeathandsurviveRateforeachport <- prop.table(SurviveOverEmbarkedTable, 1)
#plot
barplot(Deathandsurvivepercentage[2:4,1]*100, xlab =(""), ylim=c(0,100), ylab="Death rate in percentage %",  names.arg = M, col="red", main="Death rate comparison among mebarked ports", border="black", beside=TRUE)
```

The plot shows that both death and survive number distribution are similar. Southampton takes most death and survive portion because it has the largest number of passenger get on board, then Cherbourg, and last is Queenstown. However, in terms of death rate, which is the death/total from the passenger who get on board, southampton is the is the highest and then Queenstown, teh last is Cherbourg. That is to say, people who boarded from Cherbourg had a higher chance of survival than people who boarded from Southampton or Queenstown.

In summary, we have explored all attributes through descriptive analysis, which is mainly using numbers and through exploratory analysis, which is using plot. We have examined the quality of each attributes by finding missing values and duplication. We have spoted some outliars and odd values. 

We have also assessed relationship between attribute *Survived* and all other attributes. The prediction power of each attributes have been understand to some extend. More prediction power study such as combination of two or three attributes are needed. 

The findings of each attributes provide tasks and goals for data preprocess step to accomplish. 

## Data Recods Level Assessment

Although we have examined the raw datasets records' numbers in attributes level. We have a good knowledge about the record numbers in each given dataset. It is still necessary to check at the record level. It means if there some records have too many missing attributes' value, for example, although some records have ids and may be names but most of the useful attributes' value are missing.  These records are bed or invalid records, should be removed or solve the missing values. 

On other hand some records have most attributes values are identical. These could be considered as duplicates. depends on the problem to be solved, they could be problematic and need to be dealt with. 

In our Titanic problem, record level assessment is not an issue. Since we have almost all the records are different. This does not mean we should completely ignore this step and doing the checking.   

## Summary {-}

All the analyses actions provide demonstrations how to  access the raw data and understand their quantity and data quality. Notice that the understanding data is never a single one-off action. You never fully understood the given data. once the analytical process moving on, you may need to come back to apply some new decomposition on some attributes to explore more. 

Since our raw data is not too big in terms of both the number of records and the number of attributes. So it is relatively easy to assess their quality. In a real world project the raw data can be huge or can be too little. To perform an effective analysis you may need to reduce the data size or in other cases to increase the size. It means you need to do sampling on the given datasets and probably attributes selection too. Other cases you may need to create new attributes or combine a few attribute together. These are called attributes re-engineering. They are the part of important tasks in data preprocess , which is covered in the next chapter on **data preprocess**.  

```{block2,  type='rmdinfo'}
The entire R code in this chapter is avalable in the file "TitanicDataAnalysis_UnderstandData.R" and it can be find in the appendix. 
```

## Exercises 4 {-}

1. Identify the code in this tutorial which can be conceptually categorized as Descriptive analysis and which one can be Exploratory analysis?

2. Find out what is "rt" mean in R `train <- read.csv("train.csv", header = TRUE)` error message. Explore how to load files other than *csv* file.

3. Explore load data through RStudio build-in functions. Check "File -> Import Dataset", also check how to load data from a databases like MySql.

4. Calculate survival rate among the three Pclass.

5. Calculate the percentage of survival among different SibSp` and Parch` groups.

6. Plot distributions of Fare, Embarked of passengers who survived or did not survive.

7. Plot survival rate by Sex, Plot survival rate by Pclass, Plot survival rate by SibSp,Plot survival rate by Parch.

8. Plot survival rate (percentage of survived over total number) by over Embarked ports.



