<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.2 General Cross Validation Methods | 09-Model-Cross-Validation.utf8</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="1.2 General Cross Validation Methods | 09-Model-Cross-Validation.utf8" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.2 General Cross Validation Methods | 09-Model-Cross-Validation.utf8" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="models-underfitting-and-overfitting.html"/>
<link rel="next" href="multiple-models-comparison.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Authoring Books with R Markdown</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="model-cross-validation.html"><a href="model-cross-validation.html"><i class="fa fa-check"></i><b>1</b> Model Cross Validation</a><ul>
<li class="chapter" data-level="1.1" data-path="models-underfitting-and-overfitting.html"><a href="models-underfitting-and-overfitting.html"><i class="fa fa-check"></i><b>1.1</b> Model’s Underfitting and Overfitting</a></li>
<li class="chapter" data-level="1.2" data-path="general-cross-validation-methods.html"><a href="general-cross-validation-methods.html"><i class="fa fa-check"></i><b>1.2</b> General Cross Validation Methods</a><ul>
<li class="chapter" data-level="1.2.1" data-path="general-cross-validation-methods.html"><a href="general-cross-validation-methods.html#single-model-cross-validation"><i class="fa fa-check"></i><b>1.2.1</b> Single model Cross Validation</a></li>
<li class="chapter" data-level="1.2.2" data-path="general-cross-validation-methods.html"><a href="general-cross-validation-methods.html#general-procedure-of-cross-validation"><i class="fa fa-check"></i><b>1.2.2</b> General Procedure of Cross-validation</a></li>
<li class="chapter" data-level="1.2.3" data-path="general-cross-validation-methods.html"><a href="general-cross-validation-methods.html#cross-validation-on-decision-tree-models"><i class="fa fa-check"></i><b>1.2.3</b> Cross Validation on Decision Tree Models</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="multiple-models-comparison.html"><a href="multiple-models-comparison.html"><i class="fa fa-check"></i><b>1.3</b> Multiple Models Comparison</a><ul>
<li class="chapter" data-level="1.3.1" data-path="multiple-models-comparison.html"><a href="multiple-models-comparison.html#regression-model-for-titanic"><i class="fa fa-check"></i><b>1.3.1</b> Regression Model for Titanic</a></li>
<li class="chapter" data-level="1.3.2" data-path="multiple-models-comparison.html"><a href="multiple-models-comparison.html#support-vector-machine-model-for-titanic"><i class="fa fa-check"></i><b>1.3.2</b> Support Vector Machine Model for Titanic</a></li>
<li class="chapter" data-level="1.3.3" data-path="multiple-models-comparison.html"><a href="multiple-models-comparison.html#neural-network-models"><i class="fa fa-check"></i><b>1.3.3</b> Neural Network Models</a></li>
<li class="chapter" data-level="1.3.4" data-path="multiple-models-comparison.html"><a href="multiple-models-comparison.html#comparision-among-different-models"><i class="fa fa-check"></i><b>1.3.4</b> Comparision among different models</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1.4</b> Summary</a></li>
<li class="chapter" data-level="1.5" data-path="excersis.html"><a href="excersis.html"><i class="fa fa-check"></i><b>1.5</b> Excersis</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="general-cross-validation-methods" class="section level2">
<h2><span class="header-section-number">1.2</span> General Cross Validation Methods</h2>
<p>There are two general Cross validation methods can be used to valid a prediction model:</p>
<ol style="list-style-type: decimal">
<li>Single model cross-validation</li>
<li>Multiple models comparison</li>
</ol>
<div id="single-model-cross-validation" class="section level3">
<h3><span class="header-section-number">1.2.1</span> Single model Cross Validation</h3>
<p>The goal of single model cross-validation is to test the model’s ability to predict new data that was not seen and not used in model construction. So, the problem can be spotted like overfitting or selection bias, in addition it can also give an insight on how the model will generalize to an independent dataset or an unknown dataset.</p>
<p>One round of cross-validation involves partitioning a sample of data into complementary subsets, performing the analysis on one subset (called the training set), and validating the analysis on the other subset (called the validation set). To reduce variability, in most methods multiple rounds of cross-validation are performed using different partitions, and the validation results are combined (e.g. averaged) over the rounds to give an estimate of the model’s predictive performance.</p>
<p>There are two major cross validation methods: exhaustive Cross-validation and non-exhaustive Cross-validation.</p>
<ul>
<li><p><strong>Exhaustive cross-validation</strong> learn and test on all possible ways to divide the original sample into a training and a validation set. <strong>Leave-p-out cross-validation (LpO CV)</strong> is an exhaustive cross validation method. It involves using <span class="math inline">\(p\)</span> data samples as the validation dataset and the remaining data samples as the training dataset. This is repeated over and over until all possible ways to divide the original data sample into a training and a validation dataset <span class="math inline">\(p\)</span>.</p></li>
<li><p><strong>Non-exhaustive cross validation</strong>, in the contrary, does not compute all the possible ways of splitting the original data sample but still has a certain coverage. <strong><span class="math inline">\(k\)</span>-fold cross-validation</strong> is a typical non-exhaustive cross validation. In <span class="math inline">\(k\)</span>-fold cross-validation, the original data sample is randomly partitioned into <span class="math inline">\(k\)</span> equal sized subsamples. Of the k subsamples, a single subsample is retained as the validation dataset for testing the model, and the remaining <span class="math inline">\(k\)</span> − 1 subsamples are used as training data. The cross-validation process is then repeated <span class="math inline">\(k\)</span> times, with each of the <span class="math inline">\(k\)</span> subsamples used exactly once as the validation data. The <span class="math inline">\(k\)</span> results can then be averaged to produce a single estimation. The advantage of this method over repeated random sub-sampling is that all observations are used for both training and validation, and each observation is used for validation exactly once. 10-fold cross-validation is commonly used in practice.</p></li>
</ul>
</div>
<div id="general-procedure-of-cross-validation" class="section level3">
<h3><span class="header-section-number">1.2.2</span> General Procedure of Cross-validation</h3>
<p>The general procedure of use of Cross validation is as follows:
1. Define cross validation folds <span class="math inline">\(K\)</span> and create training dataset and validation dataset by Shuffle the dataset randomly.
2. Specify parameters for Cross validation.
3. Create model from training dataset
4. Create list of predicted values on validation dataset
5. Check prediction error and prediction accuracy</p>
<p>We will use examples to demonstrate this procedure.</p>
</div>
<div id="cross-validation-on-decision-tree-models" class="section level3">
<h3><span class="header-section-number">1.2.3</span> Cross Validation on Decision Tree Models</h3>
<p>We have produced 4 decision tree models in Chapter 8. Let us do Cross validation on model2 and model3 since they have identical predictors with the random forest RF_model1 and RF_model2 which we will do Cross validation later.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="general-cross-validation-methods.html#cb1-1"></a><span class="kw">library</span>(caret)</span></code></pre></div>
<pre><code>## Warning: package &#39;caret&#39; was built under R version 3.6.3</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## Warning: package &#39;lattice&#39; was built under R version 3.6.3</code></pre>
<pre><code>## Loading required package: ggplot2</code></pre>
<pre><code>## Warning: package &#39;ggplot2&#39; was built under R version 3.6.3</code></pre>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="general-cross-validation-methods.html#cb7-1"></a><span class="kw">library</span>(rpart)</span>
<span id="cb7-2"><a href="general-cross-validation-methods.html#cb7-2"></a><span class="kw">library</span>(rpart.plot)</span></code></pre></div>
<pre><code>## Warning: package &#39;rpart.plot&#39; was built under R version 3.6.3</code></pre>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="general-cross-validation-methods.html#cb9-1"></a><span class="co">#read Re-engineered dataset</span></span>
<span id="cb9-2"><a href="general-cross-validation-methods.html#cb9-2"></a>RE_data &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;RE_data.csv&quot;</span>, <span class="dt">header =</span> <span class="ot">TRUE</span>)</span>
<span id="cb9-3"><a href="general-cross-validation-methods.html#cb9-3"></a></span>
<span id="cb9-4"><a href="general-cross-validation-methods.html#cb9-4"></a><span class="co">#Factorize response variable</span></span>
<span id="cb9-5"><a href="general-cross-validation-methods.html#cb9-5"></a>RE_data<span class="op">$</span>Survived &lt;-<span class="st"> </span><span class="kw">factor</span>(RE_data<span class="op">$</span>Survived)</span>
<span id="cb9-6"><a href="general-cross-validation-methods.html#cb9-6"></a>RE_data<span class="op">$</span>Survived &lt;-<span class="st"> </span><span class="kw">factor</span>(RE_data<span class="op">$</span>Survived)</span>
<span id="cb9-7"><a href="general-cross-validation-methods.html#cb9-7"></a><span class="co">#Separate Train and test data.</span></span>
<span id="cb9-8"><a href="general-cross-validation-methods.html#cb9-8"></a>train &lt;-<span class="st"> </span>RE_data[<span class="dv">1</span><span class="op">:</span><span class="dv">891</span>, ]</span>
<span id="cb9-9"><a href="general-cross-validation-methods.html#cb9-9"></a>test &lt;-<span class="st"> </span>RE_data[<span class="dv">892</span><span class="op">:</span><span class="dv">1309</span>, ]</span>
<span id="cb9-10"><a href="general-cross-validation-methods.html#cb9-10"></a></span>
<span id="cb9-11"><a href="general-cross-validation-methods.html#cb9-11"></a><span class="co">#setup model&#39;s train and valid dataset</span></span>
<span id="cb9-12"><a href="general-cross-validation-methods.html#cb9-12"></a><span class="kw">set.seed</span>(<span class="dv">1000</span>)</span>
<span id="cb9-13"><a href="general-cross-validation-methods.html#cb9-13"></a>samp &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">nrow</span>(train), <span class="fl">0.8</span> <span class="op">*</span><span class="st"> </span><span class="kw">nrow</span>(train))</span>
<span id="cb9-14"><a href="general-cross-validation-methods.html#cb9-14"></a>trainData &lt;-<span class="st"> </span>train[samp, ]</span>
<span id="cb9-15"><a href="general-cross-validation-methods.html#cb9-15"></a>validData &lt;-<span class="st"> </span>train[<span class="op">-</span>samp, ]</span></code></pre></div>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="general-cross-validation-methods.html#cb10-1"></a><span class="co"># set random for reproduction</span></span>
<span id="cb10-2"><a href="general-cross-validation-methods.html#cb10-2"></a><span class="kw">set.seed</span>(<span class="dv">3214</span>)</span>
<span id="cb10-3"><a href="general-cross-validation-methods.html#cb10-3"></a><span class="co"># specify parameters for cross validation</span></span>
<span id="cb10-4"><a href="general-cross-validation-methods.html#cb10-4"></a>control &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>, </span>
<span id="cb10-5"><a href="general-cross-validation-methods.html#cb10-5"></a>                        <span class="dt">number =</span> <span class="dv">10</span>, <span class="co"># number of folds</span></span>
<span id="cb10-6"><a href="general-cross-validation-methods.html#cb10-6"></a>                        <span class="dt">repeats =</span> <span class="dv">5</span>, <span class="co"># repeat times</span></span>
<span id="cb10-7"><a href="general-cross-validation-methods.html#cb10-7"></a>                        <span class="dt">search =</span> <span class="st">&quot;grid&quot;</span>)</span></code></pre></div>
<p>Our cross validation settings are: 10 folds, and repeat 5 times, with “Grid” search the optimal parameter. The detailed meaning of each settings refers to <a href="http://topepo.github.io/caret/data-splitting.html" class="uri">http://topepo.github.io/caret/data-splitting.html</a>.</p>
<p>Let us to Cross validation for Tree model2,</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="general-cross-validation-methods.html#cb11-1"></a><span class="kw">set.seed</span>(<span class="dv">1010</span>)</span>
<span id="cb11-2"><a href="general-cross-validation-methods.html#cb11-2"></a><span class="co">#create model from cross validation data</span></span>
<span id="cb11-3"><a href="general-cross-validation-methods.html#cb11-3"></a>Tree_model2_cv &lt;-<span class="st"> </span><span class="kw">train</span>(Survived <span class="op">~</span><span class="st"> </span>Sex <span class="op">+</span><span class="st"> </span>Pclass <span class="op">+</span><span class="st"> </span>HasCabinNum <span class="op">+</span><span class="st"> </span>Deck <span class="op">+</span><span class="st"> </span>Fare_pp,</span>
<span id="cb11-4"><a href="general-cross-validation-methods.html#cb11-4"></a>                      <span class="dt">data =</span> trainData, </span>
<span id="cb11-5"><a href="general-cross-validation-methods.html#cb11-5"></a>                      <span class="dt">method =</span> <span class="st">&quot;rpart&quot;</span>, </span>
<span id="cb11-6"><a href="general-cross-validation-methods.html#cb11-6"></a>                      <span class="dt">trControl =</span> control)</span></code></pre></div>
<p>Display details of the cross validation,</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="general-cross-validation-methods.html#cb12-1"></a><span class="co">#Visualize cross validation tree</span></span>
<span id="cb12-2"><a href="general-cross-validation-methods.html#cb12-2"></a><span class="kw">rpart.plot</span>(Tree_model2_cv<span class="op">$</span>finalModel, <span class="dt">extra=</span><span class="dv">4</span>)</span>
<span id="cb12-3"><a href="general-cross-validation-methods.html#cb12-3"></a><span class="kw">print.train</span>(Tree_model2_cv)</span></code></pre></div>
<pre><code>## CART 
## 
## 712 samples
##   5 predictor
##   2 classes: &#39;0&#39;, &#39;1&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 5 times) 
## Summary of sample sizes: 641, 640, 640, 641, 641, 642, ... 
## Resampling results across tuning parameters:
## 
##   cp          Accuracy   Kappa    
##   0.00887199  0.8253404  0.6003541
##   0.03041825  0.7955233  0.5418574
##   0.43726236  0.6908918  0.2281378
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was cp = 0.00887199.</code></pre>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="general-cross-validation-methods.html#cb14-1"></a><span class="kw">plot.train</span>(Tree_model2_cv)</span>
<span id="cb14-2"><a href="general-cross-validation-methods.html#cb14-2"></a>model_accuracy &lt;-<span class="st"> </span>Tree_model2_cv<span class="op">$</span>results<span class="op">$</span>Accuracy[<span class="dv">1</span>]</span>
<span id="cb14-3"><a href="general-cross-validation-methods.html#cb14-3"></a><span class="co"># accuracy is 81.48.</span></span></code></pre></div>
<div class="figure">
<img src="09-Model-Cross-Validation_files/figure-html/tree_model2_CV-1.svg" alt="Decision Tree CV model2." width="32.8%" /><img src="09-Model-Cross-Validation_files/figure-html/tree_model2_CV-2.svg" alt="Decision Tree CV model2." width="32.8%" />
<p class="caption">
(#fig:tree_model2_CV)Decision Tree CV model2.
</p>
</div>
<p>let us record the model’s accuracy on <em>trainData</em>, <em>validData</em>, and <em>test</em> dataset. Remember <em>trainData</em> and <em>validData</em> are randomly partitioned from the train dataset.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="general-cross-validation-methods.html#cb15-1"></a><span class="co">### Access accuracy on different datasets</span></span>
<span id="cb15-2"><a href="general-cross-validation-methods.html#cb15-2"></a><span class="co">#predict on train</span></span>
<span id="cb15-3"><a href="general-cross-validation-methods.html#cb15-3"></a>predict_train &lt;-<span class="kw">predict</span>(Tree_model2_cv, trainData)</span>
<span id="cb15-4"><a href="general-cross-validation-methods.html#cb15-4"></a>conMat &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(predict_train, trainData<span class="op">$</span>Survived)</span>
<span id="cb15-5"><a href="general-cross-validation-methods.html#cb15-5"></a>conMat<span class="op">$</span>table</span></code></pre></div>
<pre><code>##           Reference
## Prediction   0   1
##          0 431 104
##          1  18 159</code></pre>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="general-cross-validation-methods.html#cb17-1"></a><span class="co">#conMat$overall</span></span>
<span id="cb17-2"><a href="general-cross-validation-methods.html#cb17-2"></a>predict_train_accuracy &lt;-<span class="st"> </span>conMat<span class="op">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>]</span>
<span id="cb17-3"><a href="general-cross-validation-methods.html#cb17-3"></a>predict_train_accuracy</span></code></pre></div>
<pre><code>##  Accuracy 
## 0.8286517</code></pre>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="general-cross-validation-methods.html#cb19-1"></a><span class="co">#predict on valid</span></span>
<span id="cb19-2"><a href="general-cross-validation-methods.html#cb19-2"></a>predict_valid &lt;-<span class="kw">predict</span>(Tree_model2_cv, validData)</span>
<span id="cb19-3"><a href="general-cross-validation-methods.html#cb19-3"></a>conMat &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(predict_valid, validData<span class="op">$</span>Survived)</span>
<span id="cb19-4"><a href="general-cross-validation-methods.html#cb19-4"></a>conMat<span class="op">$</span>table</span></code></pre></div>
<pre><code>##           Reference
## Prediction  0  1
##          0 93 36
##          1  7 43</code></pre>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="general-cross-validation-methods.html#cb21-1"></a><span class="co">#conMat$overall</span></span>
<span id="cb21-2"><a href="general-cross-validation-methods.html#cb21-2"></a>predict_valid_accuracy &lt;-<span class="st"> </span>conMat<span class="op">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>]</span>
<span id="cb21-3"><a href="general-cross-validation-methods.html#cb21-3"></a>predict_valid_accuracy</span></code></pre></div>
<pre><code>##  Accuracy 
## 0.7597765</code></pre>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="general-cross-validation-methods.html#cb23-1"></a><span class="co">#predict on test</span></span>
<span id="cb23-2"><a href="general-cross-validation-methods.html#cb23-2"></a>predict_test &lt;-<span class="kw">predict</span>(Tree_model2_cv, test)</span>
<span id="cb23-3"><a href="general-cross-validation-methods.html#cb23-3"></a>submit &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">PassengerId =</span> test<span class="op">$</span>PassengerId, <span class="dt">Survived =</span> <span class="kw">as.factor</span>(predict_test))</span>
<span id="cb23-4"><a href="general-cross-validation-methods.html#cb23-4"></a><span class="kw">write.csv</span>(submit, <span class="dt">file =</span> <span class="st">&quot;Tree_model2_CV.CSV&quot;</span>, <span class="dt">row.names =</span> <span class="ot">FALSE</span>)</span>
<span id="cb23-5"><a href="general-cross-validation-methods.html#cb23-5"></a></span>
<span id="cb23-6"><a href="general-cross-validation-methods.html#cb23-6"></a><span class="co">## test accuracy 75837</span></span>
<span id="cb23-7"><a href="general-cross-validation-methods.html#cb23-7"></a><span class="co"># accumulate model&#39;s accuracy</span></span>
<span id="cb23-8"><a href="general-cross-validation-methods.html#cb23-8"></a>Tree_model2_CV_accuracy &lt;-<span class="st"> </span><span class="kw">c</span>(model_accuracy, predict_train_accuracy, predict_valid_accuracy, <span class="fl">0.75837</span>)</span></code></pre></div>
<p>We can see the tree differences from Figure @ref(fig:tree_model2_CV) and Figure <a href="#fig:tree2"><strong>??</strong></a>. We can also see that despite the model tried the best parameters, the prediction accuracy on the test dataset is dropped from 0.76555 (default decision tree) to 0.75837. It shows that the model construction has reached the best since the change of the tree structure does not increase the accuracy. The drop of the accuracy may caused by the reduction of the size of the training dataset. It reflects the second possible cause of the overfitting, that is the size of the training sample. Recall that decision tree model2 was trained on the tran dataset and noe it is trained on the trainData. the later is a random subset of the train dataset and only has 80 percent of the data samples. That is to say, the smaller of the training dataset the more chance of the inaccurate prediction accuracy on the test dataset (overfitting or underfitting).</p>
<p>Let us do cross validation on tree model3,</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="general-cross-validation-methods.html#cb24-1"></a><span class="kw">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb24-2"><a href="general-cross-validation-methods.html#cb24-2"></a>tree_model3_cv &lt;-<span class="st"> </span><span class="kw">train</span>(Survived <span class="op">~</span><span class="st"> </span>Sex <span class="op">+</span><span class="st"> </span>Fare_pp <span class="op">+</span><span class="st"> </span>Pclass <span class="op">+</span><span class="st"> </span>Title <span class="op">+</span><span class="st"> </span>Age_group <span class="op">+</span><span class="st"> </span>Group_size <span class="op">+</span><span class="st"> </span>Ticket_class  <span class="op">+</span><span class="st"> </span>Embarked,</span>
<span id="cb24-3"><a href="general-cross-validation-methods.html#cb24-3"></a></span>
<span id="cb24-4"><a href="general-cross-validation-methods.html#cb24-4"></a>                       <span class="dt">data =</span> trainData, </span>
<span id="cb24-5"><a href="general-cross-validation-methods.html#cb24-5"></a>                       <span class="dt">method =</span> <span class="st">&quot;rpart&quot;</span>, </span>
<span id="cb24-6"><a href="general-cross-validation-methods.html#cb24-6"></a>                       <span class="dt">trControl =</span> control)</span></code></pre></div>
<p>Visualize model,</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="general-cross-validation-methods.html#cb25-1"></a><span class="co">#Visualize cross validation tree</span></span>
<span id="cb25-2"><a href="general-cross-validation-methods.html#cb25-2"></a></span>
<span id="cb25-3"><a href="general-cross-validation-methods.html#cb25-3"></a><span class="kw">rpart.plot</span>(tree_model3_cv<span class="op">$</span>finalModel, <span class="dt">extra=</span><span class="dv">4</span>)</span>
<span id="cb25-4"><a href="general-cross-validation-methods.html#cb25-4"></a></span>
<span id="cb25-5"><a href="general-cross-validation-methods.html#cb25-5"></a><span class="kw">print.train</span>(tree_model3_cv)</span></code></pre></div>
<pre><code>## CART 
## 
## 712 samples
##   8 predictor
##   2 classes: &#39;0&#39;, &#39;1&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 5 times) 
## Summary of sample sizes: 641, 641, 641, 641, 641, 641, ... 
## Resampling results across tuning parameters:
## 
##   cp          Accuracy   Kappa    
##   0.03802281  0.8209755  0.6124019
##   0.05323194  0.7934831  0.5627884
##   0.42585551  0.6979987  0.2637528
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was cp = 0.03802281.</code></pre>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="general-cross-validation-methods.html#cb27-1"></a><span class="kw">plot.train</span>(tree_model3_cv)</span>
<span id="cb27-2"><a href="general-cross-validation-methods.html#cb27-2"></a>model_accuracy &lt;-<span class="st"> </span>tree_model3_cv<span class="op">$</span>results<span class="op">$</span>Accuracy[<span class="dv">1</span>]</span>
<span id="cb27-3"><a href="general-cross-validation-methods.html#cb27-3"></a><span class="co"># accuracy is 0.82.</span></span></code></pre></div>
<div class="figure">
<img src="09-Model-Cross-Validation_files/figure-html/tree_model3_CV-1.svg" alt="Decision Tree CV model3." width="32.8%" /><img src="09-Model-Cross-Validation_files/figure-html/tree_model3_CV-2.svg" alt="Decision Tree CV model3." width="32.8%" />
<p class="caption">
(#fig:tree_model3_CV)Decision Tree CV model3.
</p>
</div>
<p>Record model’s accuracy,</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="general-cross-validation-methods.html#cb28-1"></a><span class="co">### Access accuracy on different datasets</span></span>
<span id="cb28-2"><a href="general-cross-validation-methods.html#cb28-2"></a><span class="co">#predict on train</span></span>
<span id="cb28-3"><a href="general-cross-validation-methods.html#cb28-3"></a>predict_train &lt;-<span class="kw">predict</span>(tree_model3_cv, trainData)</span>
<span id="cb28-4"><a href="general-cross-validation-methods.html#cb28-4"></a>conMat &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(predict_train, trainData<span class="op">$</span>Survived)</span>
<span id="cb28-5"><a href="general-cross-validation-methods.html#cb28-5"></a>conMat<span class="op">$</span>table</span></code></pre></div>
<pre><code>##           Reference
## Prediction   0   1
##          0 387  61
##          1  62 202</code></pre>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="general-cross-validation-methods.html#cb30-1"></a><span class="co">#conMat$overall</span></span>
<span id="cb30-2"><a href="general-cross-validation-methods.html#cb30-2"></a>predict_train_accuracy &lt;-<span class="st"> </span>conMat<span class="op">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>]</span>
<span id="cb30-3"><a href="general-cross-validation-methods.html#cb30-3"></a>predict_train_accuracy</span></code></pre></div>
<pre><code>##  Accuracy 
## 0.8272472</code></pre>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="general-cross-validation-methods.html#cb32-1"></a><span class="co">#predict on valid</span></span>
<span id="cb32-2"><a href="general-cross-validation-methods.html#cb32-2"></a>predict_valid &lt;-<span class="kw">predict</span>(tree_model3_cv, validData)</span>
<span id="cb32-3"><a href="general-cross-validation-methods.html#cb32-3"></a>conMat &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(predict_valid, validData<span class="op">$</span>Survived)</span>
<span id="cb32-4"><a href="general-cross-validation-methods.html#cb32-4"></a>conMat<span class="op">$</span>table</span></code></pre></div>
<pre><code>##           Reference
## Prediction  0  1
##          0 90 24
##          1 10 55</code></pre>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="general-cross-validation-methods.html#cb34-1"></a><span class="co">#conMat$overall</span></span>
<span id="cb34-2"><a href="general-cross-validation-methods.html#cb34-2"></a>predict_valid_accuracy &lt;-<span class="st"> </span>conMat<span class="op">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>]</span>
<span id="cb34-3"><a href="general-cross-validation-methods.html#cb34-3"></a>predict_valid_accuracy</span></code></pre></div>
<pre><code>##  Accuracy 
## 0.8100559</code></pre>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="general-cross-validation-methods.html#cb36-1"></a><span class="co">#predict on test</span></span>
<span id="cb36-2"><a href="general-cross-validation-methods.html#cb36-2"></a>predict_test &lt;-<span class="kw">predict</span>(tree_model3_cv, test)</span>
<span id="cb36-3"><a href="general-cross-validation-methods.html#cb36-3"></a>submit &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">PassengerId =</span> test<span class="op">$</span>PassengerId, <span class="dt">Survived =</span> <span class="kw">as.factor</span>(predict_test))</span>
<span id="cb36-4"><a href="general-cross-validation-methods.html#cb36-4"></a><span class="kw">write.csv</span>(submit, <span class="dt">file =</span> <span class="st">&quot;Tree_model3_CV.CSV&quot;</span>, <span class="dt">row.names =</span> <span class="ot">FALSE</span>)</span>
<span id="cb36-5"><a href="general-cross-validation-methods.html#cb36-5"></a></span>
<span id="cb36-6"><a href="general-cross-validation-methods.html#cb36-6"></a><span class="co">## test accuracy 0.77751</span></span>
<span id="cb36-7"><a href="general-cross-validation-methods.html#cb36-7"></a><span class="co"># accumulate model&#39;s accuracy</span></span>
<span id="cb36-8"><a href="general-cross-validation-methods.html#cb36-8"></a>Tree_model3_CV_accuracy &lt;-<span class="st"> </span><span class="kw">c</span>(model_accuracy, predict_train_accuracy, predict_valid_accuracy, <span class="fl">0.77751</span>)</span>
<span id="cb36-9"><a href="general-cross-validation-methods.html#cb36-9"></a>Tree_model3_CV_accuracy</span></code></pre></div>
<pre><code>##            Accuracy  Accuracy           
## 0.8209755 0.8272472 0.8100559 0.7775100</code></pre>
<p>The results shows a consistent prediction accuracy. The accuracy on the test dataset has been increased from 0.77033 (Tree model3) to 0.7775. The point perhaps is that the increase of predictors does improve the accuracy (so far).</p>
<p>Based on the two cross validation we did on the two decision tree models: model2 and model3, we can conclude that the decision tree model default setting are nearly reaches the best setting. This is because after we used 10 folds and repeat 5 times cross validation and Grid search for best parameters, we did not improve much of the models’ accuracy.</p>
<p>Now, Let us try the same cross validation with the two Random forest models constructed in the Chapter 9.</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="general-cross-validation-methods.html#cb38-1"></a><span class="co"># set seed for reproduction</span></span>
<span id="cb38-2"><a href="general-cross-validation-methods.html#cb38-2"></a><span class="kw">set.seed</span>(<span class="dv">2307</span>)</span>
<span id="cb38-3"><a href="general-cross-validation-methods.html#cb38-3"></a>RF_model1_cv &lt;-<span class="st"> </span><span class="kw">train</span>(Survived <span class="op">~</span><span class="st"> </span>Sex <span class="op">+</span><span class="st"> </span>Pclass <span class="op">+</span><span class="st"> </span>HasCabinNum <span class="op">+</span><span class="st">      </span>Deck <span class="op">+</span><span class="st"> </span>Fare_pp,  </span>
<span id="cb38-4"><a href="general-cross-validation-methods.html#cb38-4"></a>                       <span class="dt">data =</span> trainData, </span>
<span id="cb38-5"><a href="general-cross-validation-methods.html#cb38-5"></a>                       <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>, </span>
<span id="cb38-6"><a href="general-cross-validation-methods.html#cb38-6"></a>                       <span class="dt">trControl =</span> control)</span>
<span id="cb38-7"><a href="general-cross-validation-methods.html#cb38-7"></a></span>
<span id="cb38-8"><a href="general-cross-validation-methods.html#cb38-8"></a><span class="kw">print</span>(RF_model1_cv)</span></code></pre></div>
<pre><code>## Random Forest 
## 
## 712 samples
##   5 predictor
##   2 classes: &#39;0&#39;, &#39;1&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 5 times) 
## Summary of sample sizes: 641, 642, 640, 641, 641, 641, ... 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa    
##    2    0.7685740  0.4567166
##    7    0.8387568  0.6378935
##   12    0.8284003  0.6259470
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was mtry = 7.</code></pre>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="general-cross-validation-methods.html#cb40-1"></a><span class="kw">print</span>(RF_model1_cv<span class="op">$</span>results)</span></code></pre></div>
<pre><code>##   mtry  Accuracy     Kappa AccuracySD    KappaSD
## 1    2 0.7685740 0.4567166 0.05952452 0.14714638
## 2    7 0.8387568 0.6378935 0.04129952 0.09534059
## 3   12 0.8284003 0.6259470 0.04530653 0.09853010</code></pre>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="general-cross-validation-methods.html#cb42-1"></a>model_accuracy &lt;-<span class="st"> </span>RF_model1_cv<span class="op">$</span>results<span class="op">$</span>Accuracy[<span class="dv">2</span>]</span>
<span id="cb42-2"><a href="general-cross-validation-methods.html#cb42-2"></a>model_accuracy</span></code></pre></div>
<pre><code>## [1] 0.8387568</code></pre>
<p>We can see that the best model parameters are <em>mtry = 7</em> and <em>ntree = 500</em>, The trained model’s best accuracy is 83.87%.</p>
<p>Let us verify on validate dataset and make prediction on test dataset.</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="general-cross-validation-methods.html#cb44-1"></a><span class="co">### Access accuracy on different datasets</span></span>
<span id="cb44-2"><a href="general-cross-validation-methods.html#cb44-2"></a><span class="co">#predict on train</span></span>
<span id="cb44-3"><a href="general-cross-validation-methods.html#cb44-3"></a>predict_train &lt;-<span class="kw">predict</span>(RF_model1_cv, trainData)</span>
<span id="cb44-4"><a href="general-cross-validation-methods.html#cb44-4"></a>conMat &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(predict_train, trainData<span class="op">$</span>Survived)</span>
<span id="cb44-5"><a href="general-cross-validation-methods.html#cb44-5"></a>conMat<span class="op">$</span>table</span></code></pre></div>
<pre><code>##           Reference
## Prediction   0   1
##          0 432  72
##          1  17 191</code></pre>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="general-cross-validation-methods.html#cb46-1"></a><span class="co">#conMat$overall</span></span>
<span id="cb46-2"><a href="general-cross-validation-methods.html#cb46-2"></a>predict_train_accuracy &lt;-<span class="st"> </span>conMat<span class="op">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>]</span>
<span id="cb46-3"><a href="general-cross-validation-methods.html#cb46-3"></a>predict_train_accuracy</span></code></pre></div>
<pre><code>## Accuracy 
##    0.875</code></pre>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="general-cross-validation-methods.html#cb48-1"></a><span class="co">#predict on valid</span></span>
<span id="cb48-2"><a href="general-cross-validation-methods.html#cb48-2"></a>predict_valid &lt;-<span class="kw">predict</span>(RF_model1_cv, validData)</span>
<span id="cb48-3"><a href="general-cross-validation-methods.html#cb48-3"></a>conMat &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(predict_valid, validData<span class="op">$</span>Survived)</span>
<span id="cb48-4"><a href="general-cross-validation-methods.html#cb48-4"></a>conMat<span class="op">$</span>table</span></code></pre></div>
<pre><code>##           Reference
## Prediction  0  1
##          0 88 34
##          1 12 45</code></pre>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="general-cross-validation-methods.html#cb50-1"></a><span class="co">#conMat$overall</span></span>
<span id="cb50-2"><a href="general-cross-validation-methods.html#cb50-2"></a>predict_valid_accuracy &lt;-<span class="st"> </span>conMat<span class="op">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>]</span>
<span id="cb50-3"><a href="general-cross-validation-methods.html#cb50-3"></a>predict_valid_accuracy</span></code></pre></div>
<pre><code>##  Accuracy 
## 0.7430168</code></pre>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="general-cross-validation-methods.html#cb52-1"></a><span class="co">#predict on test</span></span>
<span id="cb52-2"><a href="general-cross-validation-methods.html#cb52-2"></a>predict_test &lt;-<span class="kw">predict</span>(RF_model1_cv, test)</span>
<span id="cb52-3"><a href="general-cross-validation-methods.html#cb52-3"></a>submit &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">PassengerId =</span> test<span class="op">$</span>PassengerId, <span class="dt">Survived =</span> <span class="kw">as.factor</span>(predict_test))</span>
<span id="cb52-4"><a href="general-cross-validation-methods.html#cb52-4"></a><span class="kw">write.csv</span>(submit, <span class="dt">file =</span> <span class="st">&quot;RF_model1_CV.CSV&quot;</span>, <span class="dt">row.names =</span> <span class="ot">FALSE</span>)</span>
<span id="cb52-5"><a href="general-cross-validation-methods.html#cb52-5"></a></span>
<span id="cb52-6"><a href="general-cross-validation-methods.html#cb52-6"></a><span class="co">## test accuracy 74641</span></span>
<span id="cb52-7"><a href="general-cross-validation-methods.html#cb52-7"></a><span class="co"># accumulate model&#39;s accuracy</span></span>
<span id="cb52-8"><a href="general-cross-validation-methods.html#cb52-8"></a></span>
<span id="cb52-9"><a href="general-cross-validation-methods.html#cb52-9"></a>RF_model1_cv_accuracy &lt;-<span class="st"> </span><span class="kw">c</span>(model_accuracy, predict_train_accuracy, predict_valid_accuracy, <span class="fl">0.74641</span>)</span>
<span id="cb52-10"><a href="general-cross-validation-methods.html#cb52-10"></a>RF_model1_cv_accuracy</span></code></pre></div>
<pre><code>##            Accuracy  Accuracy           
## 0.8387568 0.8750000 0.7430168 0.7464100</code></pre>
<p>The trainData set (randomly selected 80 percent of train dataset ), the random forest parameter (mtry = 7, ntree = 500) and the cross validation settings (fold = 10 and repeats= 5) combined together a model. Its prediction accuracy is pretty bad with 74.6% accuracy on the test dataset. The same predictors using default random forest settings(mtry = 1, ntree = 500) and trained on the train dataset has a prediction accuracy of 0.76555.</p>
<p>Let us try on random forest model2,</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="general-cross-validation-methods.html#cb54-1"></a><span class="co"># set seed for reproduction</span></span>
<span id="cb54-2"><a href="general-cross-validation-methods.html#cb54-2"></a><span class="kw">set.seed</span>(<span class="dv">2300</span>)</span>
<span id="cb54-3"><a href="general-cross-validation-methods.html#cb54-3"></a></span>
<span id="cb54-4"><a href="general-cross-validation-methods.html#cb54-4"></a>RF_model2_cv &lt;-<span class="st"> </span><span class="kw">train</span>(Survived <span class="op">~</span><span class="st"> </span>Pclass <span class="op">+</span><span class="st"> </span>Title <span class="op">+</span><span class="st"> </span>Sex <span class="op">+</span><span class="st"> </span>Age_group <span class="op">+</span><span class="st"> </span>Group_size <span class="op">+</span><span class="st"> </span>Ticket_class  <span class="op">+</span><span class="st"> </span>Fare_pp <span class="op">+</span><span class="st"> </span>Deck <span class="op">+</span><span class="st"> </span>HasCabinNum <span class="op">+</span><span class="st"> </span>Embarked, </span>
<span id="cb54-5"><a href="general-cross-validation-methods.html#cb54-5"></a>                       <span class="dt">data =</span> trainData, </span>
<span id="cb54-6"><a href="general-cross-validation-methods.html#cb54-6"></a>                       <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>, </span>
<span id="cb54-7"><a href="general-cross-validation-methods.html#cb54-7"></a>                       <span class="dt">trControl =</span> control)</span>
<span id="cb54-8"><a href="general-cross-validation-methods.html#cb54-8"></a></span>
<span id="cb54-9"><a href="general-cross-validation-methods.html#cb54-9"></a><span class="kw">print</span>(RF_model2_cv)</span></code></pre></div>
<pre><code>## Random Forest 
## 
## 712 samples
##  10 predictor
##   2 classes: &#39;0&#39;, &#39;1&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 5 times) 
## Summary of sample sizes: 641, 640, 642, 641, 640, 641, ... 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa    
##    2    0.8159326  0.5841530
##   21    0.8398931  0.6512953
##   41    0.8320097  0.6343455
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was mtry = 21.</code></pre>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="general-cross-validation-methods.html#cb56-1"></a><span class="kw">print</span>(RF_model2_cv<span class="op">$</span>results)</span></code></pre></div>
<pre><code>##   mtry  Accuracy     Kappa AccuracySD    KappaSD
## 1    2 0.8159326 0.5841530 0.03485475 0.08201532
## 2   21 0.8398931 0.6512953 0.03669218 0.08092936
## 3   41 0.8320097 0.6343455 0.03890207 0.08559051</code></pre>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="general-cross-validation-methods.html#cb58-1"></a>model_accuracy &lt;-<span class="st"> </span>RF_model2_cv<span class="op">$</span>results<span class="op">$</span>Accuracy[<span class="dv">2</span>]</span>
<span id="cb58-2"><a href="general-cross-validation-methods.html#cb58-2"></a>model_accuracy</span></code></pre></div>
<pre><code>## [1] 0.8398931</code></pre>
<p>Let us calculate model’s accuracy,</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="general-cross-validation-methods.html#cb60-1"></a><span class="co">### Access accuracy on different datasets</span></span>
<span id="cb60-2"><a href="general-cross-validation-methods.html#cb60-2"></a><span class="co">#predict on train</span></span>
<span id="cb60-3"><a href="general-cross-validation-methods.html#cb60-3"></a>predict_train &lt;-<span class="kw">predict</span>(RF_model2_cv, trainData)</span>
<span id="cb60-4"><a href="general-cross-validation-methods.html#cb60-4"></a>conMat &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(predict_train, trainData<span class="op">$</span>Survived)</span>
<span id="cb60-5"><a href="general-cross-validation-methods.html#cb60-5"></a>conMat<span class="op">$</span>table</span></code></pre></div>
<pre><code>##           Reference
## Prediction   0   1
##          0 441  16
##          1   8 247</code></pre>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="general-cross-validation-methods.html#cb62-1"></a><span class="co">#conMat$overall</span></span>
<span id="cb62-2"><a href="general-cross-validation-methods.html#cb62-2"></a>predict_train_accuracy &lt;-<span class="st"> </span>conMat<span class="op">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>]</span>
<span id="cb62-3"><a href="general-cross-validation-methods.html#cb62-3"></a>predict_train_accuracy</span></code></pre></div>
<pre><code>##  Accuracy 
## 0.9662921</code></pre>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="general-cross-validation-methods.html#cb64-1"></a><span class="co">#predict on valid</span></span>
<span id="cb64-2"><a href="general-cross-validation-methods.html#cb64-2"></a>predict_valid &lt;-<span class="kw">predict</span>(RF_model2_cv, validData)</span>
<span id="cb64-3"><a href="general-cross-validation-methods.html#cb64-3"></a>conMat &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(predict_valid, validData<span class="op">$</span>Survived)</span>
<span id="cb64-4"><a href="general-cross-validation-methods.html#cb64-4"></a>conMat<span class="op">$</span>table</span></code></pre></div>
<pre><code>##           Reference
## Prediction  0  1
##          0 87 28
##          1 13 51</code></pre>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="general-cross-validation-methods.html#cb66-1"></a><span class="co">#conMat$overall</span></span>
<span id="cb66-2"><a href="general-cross-validation-methods.html#cb66-2"></a>predict_valid_accuracy &lt;-<span class="st"> </span>conMat<span class="op">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>]</span>
<span id="cb66-3"><a href="general-cross-validation-methods.html#cb66-3"></a>predict_valid_accuracy</span></code></pre></div>
<pre><code>##  Accuracy 
## 0.7709497</code></pre>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="general-cross-validation-methods.html#cb68-1"></a><span class="co">#predict on test</span></span>
<span id="cb68-2"><a href="general-cross-validation-methods.html#cb68-2"></a>predict_test &lt;-<span class="kw">predict</span>(RF_model2_cv, test)</span>
<span id="cb68-3"><a href="general-cross-validation-methods.html#cb68-3"></a>submit &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">PassengerId =</span> test<span class="op">$</span>PassengerId, <span class="dt">Survived =</span> <span class="kw">as.factor</span>(predict_test))</span>
<span id="cb68-4"><a href="general-cross-validation-methods.html#cb68-4"></a><span class="kw">write.csv</span>(submit, <span class="dt">file =</span> <span class="st">&quot;RF_model2_CV.CSV&quot;</span>, <span class="dt">row.names =</span> <span class="ot">FALSE</span>)</span>
<span id="cb68-5"><a href="general-cross-validation-methods.html#cb68-5"></a></span>
<span id="cb68-6"><a href="general-cross-validation-methods.html#cb68-6"></a><span class="co">## test accuracy 0.75119</span></span>
<span id="cb68-7"><a href="general-cross-validation-methods.html#cb68-7"></a><span class="co"># accumulate model&#39;s accuracy</span></span>
<span id="cb68-8"><a href="general-cross-validation-methods.html#cb68-8"></a></span>
<span id="cb68-9"><a href="general-cross-validation-methods.html#cb68-9"></a>RF_model2_cv_accuracy &lt;-<span class="st"> </span><span class="kw">c</span>(model_accuracy, predict_train_accuracy, predict_valid_accuracy, <span class="fl">0.75119</span>)</span>
<span id="cb68-10"><a href="general-cross-validation-methods.html#cb68-10"></a>RF_model2_cv_accuracy</span></code></pre></div>
<pre><code>##            Accuracy  Accuracy           
## 0.8398931 0.9662921 0.7709497 0.7511900</code></pre>
<p>We have used 10 folds and repeating 5 times cross validation with 80% of the train dataset to build and validate 4 models we have produced, two from decision tree and two from random forest. The accuracy with different datasets have been collected. let us put them into one table and plot them so we can make a comparison.</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="general-cross-validation-methods.html#cb70-1"></a><span class="kw">library</span>(tidyr)</span></code></pre></div>
<pre><code>## Warning: package &#39;tidyr&#39; was built under R version 3.6.3</code></pre>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="general-cross-validation-methods.html#cb72-1"></a>Model &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Tree_M2&quot;</span>,<span class="st">&quot;Tree_M3&quot;</span>,<span class="st">&quot;RF_model1&quot;</span>,<span class="st">&quot;RF_model2&quot;</span>)</span>
<span id="cb72-2"><a href="general-cross-validation-methods.html#cb72-2"></a>Tree_model2_CV_accuracy</span></code></pre></div>
<pre><code>##            Accuracy  Accuracy           
## 0.8253404 0.8286517 0.7597765 0.7583700</code></pre>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="general-cross-validation-methods.html#cb74-1"></a>Tree_model3_CV_accuracy</span></code></pre></div>
<pre><code>##            Accuracy  Accuracy           
## 0.8209755 0.8272472 0.8100559 0.7775100</code></pre>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="general-cross-validation-methods.html#cb76-1"></a>RF_model1_cv_accuracy</span></code></pre></div>
<pre><code>##            Accuracy  Accuracy           
## 0.8387568 0.8750000 0.7430168 0.7464100</code></pre>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="general-cross-validation-methods.html#cb78-1"></a>RF_model2_cv_accuracy</span></code></pre></div>
<pre><code>##            Accuracy  Accuracy           
## 0.8398931 0.9662921 0.7709497 0.7511900</code></pre>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="general-cross-validation-methods.html#cb80-1"></a>Pre &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Sex, Pclass, HasCabinNum, Deck, Fare_pp&quot;</span>, <span class="st">&quot;Sex, Fare_pp, Pclass, Title, Age_group, Group_size, Ticket_class, Embarked&quot;</span>, <span class="st">&quot;Sex, Pclass, HasCabinNum, Deck, Fare_pp&quot;</span>, <span class="st">&quot;Sex, Fare_pp, Pclass, Title, Age_group, Group_size, Ticket_class, Embarked&quot;</span>)</span>
<span id="cb80-2"><a href="general-cross-validation-methods.html#cb80-2"></a></span>
<span id="cb80-3"><a href="general-cross-validation-methods.html#cb80-3"></a>Learn &lt;-<span class="st"> </span><span class="kw">c</span>(Tree_model2_CV_accuracy[<span class="dv">1</span>]<span class="op">*</span><span class="dv">100</span>, Tree_model3_CV_accuracy[<span class="dv">1</span>]<span class="op">*</span><span class="dv">100</span>, RF_model1_cv_accuracy[<span class="dv">1</span>]<span class="op">*</span><span class="dv">100</span>, RF_model2_cv_accuracy[<span class="dv">1</span>]<span class="op">*</span><span class="dv">100</span>)</span>
<span id="cb80-4"><a href="general-cross-validation-methods.html#cb80-4"></a>Learn</span></code></pre></div>
<pre><code>##                                     
## 82.53404 82.09755 83.87568 83.98931</code></pre>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="general-cross-validation-methods.html#cb82-1"></a>Train &lt;-<span class="st"> </span><span class="kw">c</span>(Tree_model2_CV_accuracy[<span class="dv">2</span>]<span class="op">*</span><span class="dv">100</span>, Tree_model3_CV_accuracy[<span class="dv">2</span>]<span class="op">*</span><span class="dv">100</span>, RF_model1_cv_accuracy[<span class="dv">2</span>]<span class="op">*</span><span class="dv">100</span>, RF_model2_cv_accuracy[<span class="dv">2</span>]<span class="op">*</span><span class="dv">100</span>)</span>
<span id="cb82-2"><a href="general-cross-validation-methods.html#cb82-2"></a>Train</span></code></pre></div>
<pre><code>## Accuracy Accuracy Accuracy Accuracy 
## 82.86517 82.72472 87.50000 96.62921</code></pre>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="general-cross-validation-methods.html#cb84-1"></a>Valid &lt;-<span class="st"> </span><span class="kw">c</span>(Tree_model2_CV_accuracy[<span class="dv">3</span>]<span class="op">*</span><span class="dv">100</span>, Tree_model3_CV_accuracy[<span class="dv">3</span>]<span class="op">*</span><span class="dv">100</span>, RF_model1_cv_accuracy[<span class="dv">3</span>]<span class="op">*</span><span class="dv">100</span>, RF_model2_cv_accuracy[<span class="dv">3</span>]<span class="op">*</span><span class="dv">100</span>)</span>
<span id="cb84-2"><a href="general-cross-validation-methods.html#cb84-2"></a>Valid</span></code></pre></div>
<pre><code>## Accuracy Accuracy Accuracy Accuracy 
## 75.97765 81.00559 74.30168 77.09497</code></pre>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="general-cross-validation-methods.html#cb86-1"></a>Test &lt;-<span class="st"> </span><span class="kw">c</span>(Tree_model2_CV_accuracy[<span class="dv">4</span>]<span class="op">*</span><span class="dv">100</span>, Tree_model3_CV_accuracy[<span class="dv">4</span>]<span class="op">*</span><span class="dv">100</span>, RF_model1_cv_accuracy[<span class="dv">4</span>]<span class="op">*</span><span class="dv">100</span>, RF_model2_cv_accuracy[<span class="dv">4</span>]<span class="op">*</span><span class="dv">100</span>)</span>
<span id="cb86-2"><a href="general-cross-validation-methods.html#cb86-2"></a>Test</span></code></pre></div>
<pre><code>##                             
## 75.837 77.751 74.641 75.119</code></pre>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="general-cross-validation-methods.html#cb88-1"></a>df1 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(Model, Pre, Learn, Train, Valid, Test)</span>
<span id="cb88-2"><a href="general-cross-validation-methods.html#cb88-2"></a>df2 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(Model, Learn, Train, Valid, Test)</span>
<span id="cb88-3"><a href="general-cross-validation-methods.html#cb88-3"></a>knitr<span class="op">::</span><span class="kw">kable</span>(df1, <span class="dt">longtable =</span> <span class="ot">TRUE</span>, <span class="dt">booktabs =</span> <span class="ot">TRUE</span>, <span class="dt">digits =</span> <span class="dv">2</span>, <span class="dt">col.names =</span><span class="kw">c</span>(<span class="st">&quot;Models&quot;</span>, <span class="st">&quot;Predictors&quot;</span>, <span class="st">&quot;Accuracy on Learn&quot;</span>, <span class="st">&quot;Accuracy on Train&quot;</span>, <span class="st">&quot;Accuracy on Valid&quot;</span>,  <span class="st">&quot;Accuracy on Test&quot;</span>), </span>
<span id="cb88-4"><a href="general-cross-validation-methods.html#cb88-4"></a>  <span class="dt">caption =</span> <span class="st">&#39;The Comparision among 4 CV models&#39;</span></span>
<span id="cb88-5"><a href="general-cross-validation-methods.html#cb88-5"></a>)</span></code></pre></div>
<table style="width:100%;">
<caption><span id="tab:unnamed-chunk-11">Table 1.1: </span>The Comparision among 4 CV models</caption>
<colgroup>
<col width="6%" />
<col width="48%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
<col width="10%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Models</th>
<th align="left">Predictors</th>
<th align="right">Accuracy on Learn</th>
<th align="right">Accuracy on Train</th>
<th align="right">Accuracy on Valid</th>
<th align="right">Accuracy on Test</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Tree_M2</td>
<td align="left">Sex, Pclass, HasCabinNum, Deck, Fare_pp</td>
<td align="right">82.53</td>
<td align="right">82.87</td>
<td align="right">75.98</td>
<td align="right">75.84</td>
</tr>
<tr class="even">
<td align="left">Tree_M3</td>
<td align="left">Sex, Fare_pp, Pclass, Title, Age_group, Group_size, Ticket_class, Embarked</td>
<td align="right">82.10</td>
<td align="right">82.72</td>
<td align="right">81.01</td>
<td align="right">77.75</td>
</tr>
<tr class="odd">
<td align="left">RF_model1</td>
<td align="left">Sex, Pclass, HasCabinNum, Deck, Fare_pp</td>
<td align="right">83.88</td>
<td align="right">87.50</td>
<td align="right">74.30</td>
<td align="right">74.64</td>
</tr>
<tr class="even">
<td align="left">RF_model2</td>
<td align="left">Sex, Fare_pp, Pclass, Title, Age_group, Group_size, Ticket_class, Embarked</td>
<td align="right">83.99</td>
<td align="right">96.63</td>
<td align="right">77.09</td>
<td align="right">75.12</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="general-cross-validation-methods.html#cb89-1"></a>df.long &lt;-<span class="st"> </span><span class="kw">gather</span>(df2, Dataset, Accuracy, <span class="op">-</span>Model, <span class="dt">factor_key =</span><span class="ot">TRUE</span>)</span>
<span id="cb89-2"><a href="general-cross-validation-methods.html#cb89-2"></a><span class="kw">ggplot</span>(<span class="dt">data =</span> df.long, <span class="kw">aes</span>(<span class="dt">x =</span> Model, <span class="dt">y =</span> Accuracy, <span class="dt">fill =</span> Dataset)) <span class="op">+</span></span>
<span id="cb89-3"><a href="general-cross-validation-methods.html#cb89-3"></a><span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">position =</span> <span class="kw">position_dodge</span>()) </span></code></pre></div>
<div class="figure"><span id="fig:CVmodelcompare"></span>
<img src="09-Model-Cross-Validation_files/figure-html/CVmodelcompare-1.svg" alt="Cross valid models' accuracy on model learning, Traindata dataset. Validdata and Test dataset." width="672" />
<p class="caption">
Figure 1.2: Cross valid models’ accuracy on model learning, Traindata dataset. Validdata and Test dataset.
</p>
</div>
<p>From the Cross validation results we can conclude that:</p>
<ol style="list-style-type: decimal">
<li>Both decision tree and random forest models default settings are good settings. Despite dynamic search for best parameters, the change of the parameter setting do not affect the prediction accuracy much. So both default settings for the prediction model are acceptable.</li>
<li>Change of training dataset for model building from train dataset to its subset trianData, in 10 fold 5 repeat cross validation settings, does not change the order of models’ performance in terms of decision tree and random forest. It however, when considering a single model, does suggest that the number of samples used for learn a model has an impact on model’s prediction results.</li>
<li>It is clearly shows that the random forest models have an overfitting.</li>
<li>It does not provide a conclusive result that decision tree is better than random forest or vice verse.</li>
</ol>
<p>A general rule seems that, the more features you have, and the more samples you used in the training, the more likely your model will suffer from overfitting and vice verse.</p>
<p>Therefore to choose a model for real prediction, we should choose the model that has the smallest accuracy decrease from the model’s training to verification by the cross validation.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="models-underfitting-and-overfitting.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multiple-models-comparison.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown/edit/master/inst/examples/%s",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "none"
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
