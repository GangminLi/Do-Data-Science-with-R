<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>PCA Analysis | Predictor Selection</title>
  <meta name="description" content="PCA Analysis | Predictor Selection" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="PCA Analysis | Predictor Selection" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="PCA Analysis | Predictor Selection" />
  
  
  

<meta name="author" content="Gangmin Li" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="attributes-correlation-analysis.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Authoring Books with R Markdown</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="predictor-selection.html"><a href="predictor-selection.html"><i class="fa fa-check"></i><b>1</b> Predictor selection</a><ul>
<li class="chapter" data-level="" data-path="attributes-correlation-analysis.html"><a href="attributes-correlation-analysis.html"><i class="fa fa-check"></i>Attributes Correlation Analysis</a></li>
<li class="chapter" data-level="" data-path="pca-analysis.html"><a href="pca-analysis.html"><i class="fa fa-check"></i>PCA Analysis</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Predictor Selection</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="pca-analysis" class="section level2 unnumbered">
<h2>PCA Analysis</h2>
<p>PCA and Factor analysis are most commonly used methods in dimension reduction. In a general data science project, it is possible that a given dataset can has tens or hundreds of features (attributes). For example in the text analysis, if we count words appearance in a document, we could easily have hundreds even thousands of dimensions. If we want reduce the dimension into a manageable numbers, PCA can be very useful. Particularly in visualization, human are not good with anything over three dimensions.</p>
<p>PCA uses <em>Eigenvalues</em> and <em>Eigenvectors</em><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> to reserve the original data information and variation as much as possible. Therefore PCA is simple to calculate the given dataâ€™s Eigenvectors.</p>
<p>PCA normally has the following steps:</p>
<ol style="list-style-type: decimal">
<li>Calculate the Covariance Matrix<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> of the given dataset.</li>
<li>Calculate the Eigenvalues and Eigenvectors of the resulting Covariance Matrix.</li>
<li>The resulting Eigenvector that correspond to the largest Eigenvalue can then be used to reconstruct a large fraction of the variance of the original dataset.</li>
</ol>
<p>In R, we have a function called <code>prcomp()</code>. It takes numerical values. So for demonstration we only use the same 8 attributes we have used in our correlation analysis. Let us take the first</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="pca-analysis.html#cb8-1"></a><span class="co"># RE_data %&gt;%</span></span>
<span id="cb8-2"><a href="pca-analysis.html#cb8-2"></a><span class="co">#   select(Survived, Pclass, Sex, Age_group, Group_size, Ticket_class, Fare_pp, Embarked) %&gt;%</span></span>
<span id="cb8-3"><a href="pca-analysis.html#cb8-3"></a><span class="co"># RE_data[1:891, ]</span></span>
<span id="cb8-4"><a href="pca-analysis.html#cb8-4"></a><span class="co">#summary(RE_data[1:891,c(2:3,5:9,12)])</span></span>
<span id="cb8-5"><a href="pca-analysis.html#cb8-5"></a><span class="co">#summary(RE_data[1:891,c(-1, -8)])</span></span>
<span id="cb8-6"><a href="pca-analysis.html#cb8-6"></a><span class="co">#data.pca &lt;- prcomp(RE_data[1:891,c(2:3,5:9,12)], center = TRUE, scale = TRUE)</span></span>
<span id="cb8-7"><a href="pca-analysis.html#cb8-7"></a>data.pca &lt;-<span class="st"> </span><span class="kw">prcomp</span>(RE_data[<span class="dv">1</span><span class="op">:</span><span class="dv">891</span>,<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">-8</span>)], <span class="dt">center =</span> <span class="ot">TRUE</span>, <span class="dt">scale =</span> <span class="ot">TRUE</span>)</span>
<span id="cb8-8"><a href="pca-analysis.html#cb8-8"></a><span class="kw">summary</span>(data.pca)</span></code></pre></div>
<pre><code>## Importance of components:
##                           PC1    PC2    PC3     PC4     PC5     PC6     PC7
## Standard deviation     2.1657 1.9563 1.3177 1.09265 1.03321 0.92535 0.79382
## Proportion of Variance 0.2931 0.2392 0.1085 0.07462 0.06672 0.05352 0.03938
## Cumulative Proportion  0.2931 0.5323 0.6409 0.71547 0.78219 0.83571 0.87509
##                            PC8    PC9    PC10    PC11    PC12    PC13    PC14
## Standard deviation     0.75698 0.6670 0.62061 0.55204 0.45560 0.19713 0.15089
## Proportion of Variance 0.03581 0.0278 0.02407 0.01905 0.01297 0.00243 0.00142
## Cumulative Proportion  0.91091 0.9387 0.96278 0.98183 0.99480 0.99723 0.99865
##                           PC15      PC16
## Standard deviation     0.14679 1.058e-15
## Proportion of Variance 0.00135 0.000e+00
## Cumulative Proportion  1.00000 1.000e+00</code></pre>
<p>We have seen 16 principal components, which named as PC1 to PC16. Each of these explains a percentage of the total variation in the dataset. That is to say, PC1 explains 29% of the total variance, PC2 explains nearly 24% of the variance. Together over half of the information in the dataset can be encapsulated by just these two principal components. So, by knowing the position of a sample in relation to just PC1 and PC2, you can get a very accurate view on where it stands in relation to other samples, as just PC1 and PC2 can explain 53% of the variance.</p>
<p>Letâ€™s call <code>str()</code> to have a look at the PCA object.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="pca-analysis.html#cb10-1"></a><span class="kw">str</span>(data.pca)</span></code></pre></div>
<pre><code>## List of 5
##  $ sdev    : num [1:16] 2.17 1.96 1.32 1.09 1.03 ...
##  $ rotation: num [1:16, 1:16] 0.0202 -0.1892 0.0781 0.3107 -0.3583 ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. ..$ : chr [1:16] &quot;Survived&quot; &quot;Pclass&quot; &quot;Sex&quot; &quot;Age&quot; ...
##   .. ..$ : chr [1:16] &quot;PC1&quot; &quot;PC2&quot; &quot;PC3&quot; &quot;PC4&quot; ...
##  $ center  : Named num [1:16] 0.384 2.309 1.648 29.452 0.523 ...
##   ..- attr(*, &quot;names&quot;)= chr [1:16] &quot;Survived&quot; &quot;Pclass&quot; &quot;Sex&quot; &quot;Age&quot; ...
##  $ scale   : Named num [1:16] 0.487 0.836 0.478 13.432 1.103 ...
##   ..- attr(*, &quot;names&quot;)= chr [1:16] &quot;Survived&quot; &quot;Pclass&quot; &quot;Sex&quot; &quot;Age&quot; ...
##  $ x       : num [1:891, 1:16] -0.442 1.794 0.032 1.509 0.902 ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. ..$ : chr [1:891] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##   .. ..$ : chr [1:16] &quot;PC1&quot; &quot;PC2&quot; &quot;PC3&quot; &quot;PC4&quot; ...
##  - attr(*, &quot;class&quot;)= chr &quot;prcomp&quot;</code></pre>
<p>The above results contain a lot of details, briefly:</p>
<ul>
<li>The center point (<code>$center</code>), scaling (<code>$scale</code>), standard deviation(<code>sdev</code>) of each principal component</li>
<li>The relationship (correlation or anti-correlation, etc) between the initial variables and the principal components (<code>$rotation</code>)</li>
<li>The values of each sample in terms of the principal components (<code>$x</code>)</li>
</ul>
Let us plot PCA, we need to use <strong>biplot</strong>, which includes both the position of each sample in terms of PC1 and PC2 and also will show how the initial variables map onto this. We need ggbiplot package, which offers a user-friendly and pretty function to plot biplots. A biplot is a type of plot that will allow you to visualize how the samples relate to one another in our PCA (which samples are similar and which are different) and will simultaneously reveal how each variable contributes to each principal component.
<div class="figure" style="text-align: center"><span id="fig:PCA"></span>
<img src="07-Predictor-Selection_files/figure-html/PCA-1.svg" alt="The 1st and the 2nd PCs ploted with ggplot_pca" width="95%" />
<p class="caption">
Figure 1.2: The 1st and the 2nd PCs ploted with ggplot_pca
</p>
</div>
<p>The axes are seen as arrows originating from the center point. Here, you see that the variables <em>Fare_pp</em>, <em>Age_group</em> and <em>Survived</em> contribute to PC1, with higher values in those variables moving the records to the right on this plot. This lets you see how the data points relate to the axes.</p>
We also have other principal components available although they may have less weights in comparison with the first two. Each of other components map differently to the original variables. We can also plot these other components, for example PC3 and PC4. If you look into the PC3 and PC4, they are <em>Sex</em> and <em>Age_group</em>. You may wondering what do they do with our prediction. Well, it can show at least the contribution between them with the dependent variable <em>Survived</em>, in addition, it can also show the covariance of the both with other variables.<br />

<div class="figure" style="text-align: center"><span id="fig:PCA2"></span>
<img src="07-Predictor-Selection_files/figure-html/PCA2-1.svg" alt="The 3rd and the 4th PC ploted with ggplot_pca" width="95%" />
<p class="caption">
Figure 1.3: The 3rd and the 4th PC ploted with ggplot_pca
</p>
</div>
<p>This Plot shows that original attributes <em>Ticket_class</em>, <em>Sex</em>, <em>Fare_PP</em> and <em>Group_size</em> contribute to PC3, which is <em>Sex</em>, in a negative way. It means that with lower values in those variables, the records will move to the left on this plot.</p>
<p>The relationship between original attributes with the newly created Principle Components also indicates the relationship between original attributes and correlation among them.</p>
<p>With these correlation and PCA analyses, We can have a pretty good idea about the attributes. Depending on the models we are constructing, we can be confident to select the number of the predictors and specific predictors to ensure our model has a good performance.</p>
<p>Attribute selection is a parsimonious process that aims to identify a minimal set of predictors for the maximum gain (predictive accuracy). This approach is the opposite of data pre-process where as many meaningful attributes as possible are considered for potential use.</p>
<p>It is also important to recognize that attribute selection cloud be an iterative process that occurs throughout the model building process. It finishes after no more improvement can be achieved in terms of model accuracy.</p>
</div>
<!-- </div> -->







<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>In linear algebra, an Eigenvector or characteristic vector of a linear transformation is a nonzero vector that changes by a scalar factor when that linear transformation is applied to it.<a href="pca-analysis.html#fnref1" class="footnote-back">â†©ï¸Ž</a></p></li>
<li id="fn2"><p>Covariance matrix is a square matrix giving the covariance between each pair of elements of a given random vector.<a href="pca-analysis.html#fnref2" class="footnote-back">â†©ï¸Ž</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="attributes-correlation-analysis.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown/edit/master/inst/examples/%s",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "none"
},
"search": false
});
});
</script>

</body>

</html>
