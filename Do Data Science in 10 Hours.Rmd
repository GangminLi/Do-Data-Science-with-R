--- 
title: "Do Data Science in 10 Hours"
author: "Gangmin Li"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
github-repo: rstudio/bookdown-demo
description: "This is my first book writtn using the bookdown package to write a book. The output format for this book is bookdown::gitbook."
---

#  {-}

Placeholder



<!--chapter:end:index.Rmd-->


# Preface {-}

Placeholder


## What is this book? Why to read it?
## Structure of the Book
## What Can This Course Offer You?
## Schedule
## Notes
## Convention
## Acknowledgements {-}

<!--chapter:end:00-preface.Rmd-->


# Introduction {#intro}

Placeholder


## What is Data Science?
### Data science as Discovery of Data Insight
### Data science as Development of Data Product
## What is Data Scientist?
### The Requisite Skill Set 
#### Mathematics Narrator
#### Computing and Software Engineer Skills
#### Strong Business Acumen
### How to Become a Data Scientist?
## Process of Doing Data Science {#process}
### Step 1: Understand the Problem - Define Objectives {#step1 -}
### Step 2: Undertand Data {#step2 -}
#### Data Collection {-}
#### Data Validation {-}
### Step 3: Data Preprocess {#preprocess -}
### Step 4: Analyze Data{#analyse -}
#### **Descriptive data analysis** {-}
#### **Explorative data analysis** {-}
#### **Predictive data analysis ** {#predictive -}
### Step 5: Results Interpretation and Evaluation {-}
### Step 6: Data Report and Communication) {-}
## Tools used in Doing a Data Science Project
### R {-}
### Python {-}
### SQL {-}
### Hadoop {-}
### Tableau {-}
### Weka {-}
## Applications of Data Science
### Data Science in Healthcare {-}
### Data Science in E-commerce {-}
### Data Science in Manufacturing {-}
### Data Science as Conversational Agents {-}
### Data Science in Transport {-}
## Summary {-}
## Exercise 1 {-}
## furtehr readins
### What is the difference between an analyst and a data scientist?
### What is the difference between Machine Learning and data science?
### What is the difference between data mining and data science?

<!--chapter:end:01-intro.Rmd-->


# Get Your Tools Ready {#tools}

Placeholder


## Brief introductiuon about R and RStudio
### Features of R Programming
### R Scripts
### R Graphical User Interface (RGui)
### RStudio
## Downlaod and Install R and RStudio
### R Download and Installation
### RStudio Download and Installation
### Familiar with RStudio interface {#rs}
#### Pane 1: Script Pane - View Files and Data {-}
#### Pane 2: WorkSpace Pane - Environment and History {-}
#### Pane 3: Console Pane {-}
#### Pane 4: Multifunction Pane {-}
##### **Files tab** {-}
##### **Plots** {-}
##### **Packages** {-}
##### **Help** {-}
##### **Viewer** {-}
## Bootsup your RStudio
## Instructions
### Code {-}
### Tips {-}
### Actions {-}
### Exercise {-}
## Exercise 2 {-}

<!--chapter:end:02-tools.Rmd-->


# Understand Problem {#prob}

Placeholder


## Kaggle Competion
## Titianic at Kaggel
## The Titanic problem
### The challenge {-}
### The data {-}
### Submission {-}
## Reflection
## Exercises 3 {-}

<!--chapter:end:03-problem.Rmd-->


# Understand Data

Placeholder


## Load data 
## Assess Data Quantity 
## General Data Attributes Assessment
## Actual Attributes Types Examination
## Actual Data Attributes Value Examination {#attvalue}
### PassengerID. 
### Survived
### Pclass
### Name
### Sex
### Age
### SibSp 
### Parch 
### Ticket
### Fare
### Cabin
### Embarkded
## Data Recods Level Assessment
## Summary {-}
## Exercises 4 {-}

<!--chapter:end:04-understand-data.Rmd-->


# Data PreProcess

Placeholder


## Dealt with Miss values and Errors (Age, )
## Attributes selection (prediction power) 
## Attribute reengineering ( title from name,  treval famail _ relatives, alone  from ParCh and SibSb)
## Assemble final datasets for modelling

<!--chapter:end:05-data-preprocess.Rmd-->


# Data Analysis

```{r out.width = "80%", fig.align ="center", echo =FALSE}
knitr::include_graphics(here::here("images", "Prediction.png"))

```


“This will be the year of AI!” ...

“Mobil device will dominate the world.” ...

"Pay by face will be a reality in 20XX" ...

All of these are based the data collected. 

How many tiems you heard about this? It basically tells us that data tells us what is going to happening.

The core of Data Sciecne is analyzing data and interpreting what data tells us.

## Predictive Data Analysis

We have used other two data analyzing methods in the previous chapters: **Descriptive data analysis** and **Exploratiory data analysis**. This chapter will practice **Predictive data analysis (PDA)**.

PDA as a method encompasses both of DDA and EDA. It is truying to analyze current and historical data to make predictions about future or unknown data values. The way todo it is building a predictive model through training dataset and testing with testing dataset. After a model is created then it will be evaluated, improved and finally applied to unknown data for applications. 

A classic example of predictive model is a customer scoring as shown in Figure \@ref(fig:modelexam). Customer scoring model factors together individual customer’s attributes (properties or features), weights them and adds them up to produce an overall score.

```{r modelexam, fig.align="center", out.width = "80%", echo=FALSE, fig.cap ="Example of predictive model for customer score" }

knitr::include_graphics(here::here("images", "examplemodel.jpg"))
```

The process of constructing and prediction model is called **predictive modeling**. Predictive modeling is generally involves three steps: **Predictor selection**, **model construction** and **model evaluation**.

### Predictor Selection {-} 

Predictor, in data science, is an attribute that a prediction model used to predict values of another attribute. The attribute to be predicted is called **consequencer** (in some cases also called dependence). Generally, there are a large number of attributes an data object can have and be potentially used as predictors by a model to produce consequencer. The most models do not use all of the data attributes instead only used a number of selected attributes, then it is needed examining the relationship between each predictor and the consequencer using appropriate methods.  Filter and wrapper are the most common methods used in attributes selection: 


-	**Filters**. Filters is a method that examines each predictor in turn. A numerical measure is calculated, representing the strength of the correlation^[Correlation, in statistics, is a measurement of any statistical relationship two attributes. It can be any associations. It commonly refers to the degree to which a pair of attributes are linearly related.] between the predictor attribute and the consequencer. Only predictor attributes where the correlation measure^[The most commonly used measurement of correaltion between two attributes is the "Pearson's correlation coefficient", commonly called simply "the correlation coefficient".] exceeds a given threshold are selected.

-	**Wrappers**. A wrapper takes a group of predictors and considers the “value add” of each attribute compared to other attributes in the group. If two attributes tell you more or less the same thing (e.g. age and date of birth) then one will be discarded because it adds no value. Step-wise linear regression^[In statistics, stepwise linear regression is a method of fitting regression models in which the selection of predictors is carried out by a  procedure that in each step, one attribute is considered for addition to or subtraction from the set of selected attributes based on some pre-specified criterion.] and principal component analysis^[Principal component analysis (PCA) is the process of computing the principal components and using only the first few principal components and ignoring the rest in a prediction or data dimension reduction. The principal components are often computed by eigendecomposition of the data covariance matrix or singular value decomposition of the data matrix.] are two popular wrapper methods.

Attribute selection is a parsimonious process that aims to identify a minimal set of predictors for the maximum gain (predictive accuracy). This approach is the opposite of data pre-process where as many meaningful attributes as possible are considered for potential use. 

It is also important to recognize that attribute selection cloud be an iterative process that occurs throughout the model building process. It finishes after no more improvement can be achieved in terms of model accuracy. 

### Model Construction{-}

Model construction normally involves two phases: **induction** and **deduction**. 

-	Induction is also called model learning, which means learn to predict; 

- Deduction is called model apply, which means model applied to predict. 

The division of model learn and model apply allows a predictive model to be mature while induction using **training dataset** to construct a model and deduction using **testing dataset** to test and adjust the model constructed.

Depends on applications different prediction models can use different mathematical approach and algorithms. Model constricted for classification problem can use decision trees while scoring prediction model can use regressions. There are also **rule based models** and **machine learning** models.


### Model Validation{-}

As explained earlier, a major problem when building predictive models is that it is easy to find relationships that are the result of random patterns in the training and testing datasets, but which may not exist in the unseen datasets. This problem is called model "over-fitting". The result is that if you measure the performance of the model using the test dataset the results will be over-optimistic. The **over-fitting problem** will affect model’s performance when presented with new data when the model is deployed. 

To determine if over-fitting has occurred, the model needs to be tested on "**validation dataset**".  Validation datasets is a subset from the given datasets that have targeted attributes values. This subset was not used to construct the model. Validation dataset is genially taken from the training datasets with certain percentage. 

Over-fitting is quite common and this is not necessarily a problem. However, if the degree of over-fitting is large, the model may need to be reconstructed using a different set of attributes.

Apart from checking model's over-fitting, Depends on the model being constructed, there a number of evaluation methods are available to perform the model validation such as **Confusion Matrix** for nominal output like class labels, AUC (Area Under Curve),accuracy and other evaluation metrics are used fo r evaluate other models.  

## Prediction Models

There are many predictive models exists for different purposes. Many different methods can be used to create a model, and more are being developed all the time. Three broad predictive models based on the model format and the way it is built: 

### Math model.

Mathematical formulated model is the model produced by mathematical formula which combines multiple predictors (attributes) to predict a response (we called it targeted attribute). A predictor is a single attribute in a data object that contributes to the result of the prediction, which is consequencer (also called dependents in same applications). 

A well-known example of math model is regression model. A linear regression model is a target function $f$ that maps each attribute set $X$ into a continuous-valued output $y$ with minimum error. 

\begin{equation} 
  y = f(x) = f(x)= ω_1 x+ω_0,
  (\#eq:binom)
\end{equation} 



where $ω_0$ and  $ω_1$ are parameters of the model and are called the *regression coefficients*. The model is to find the parameters $(ω_1, ω_0)$ that minimize the sum of the squared error (SSE),

\begin{equation} 
 SSE= \Sigma^{N}_{i=1}[y_i-f(x_i)]^2 = \Sigma^{N}_{i=1}[y_i-ω_1 x+ω_0 ]^2
  (\#eq:sse)
\end{equation} 

### Rule-based model

In a rule-based model, the model is a collection of rules. Such as `if the customer is rural, and her monthly usage is high, then the customer will probably renew`. 
In rule-based model, a model is a collection of `if … then …` rules. Table 11.2 shows an example of a classification model generated by a rule-based classifier for the vertebrate classification problem.

```{r include=FALSE }
rules <-  matrix(c("(Gives Birth = no) ∧ (Aerial Creature = yes) → Birds", 
"(Gives Birth = no) ∧ (Aquatic Creature = yes) → Fishes",
"(Gives Birth = yes) ∧ (Body Temperature = warm-blooded) → Mammals", 
"(Gives Birth = no) ∧ (Aerial Creature = no) → Reptiles", 
"(Aquatic Creature = semi) → Amphibians"), ncol=1, byrow=TRUE )
colnames(rules) <- c("Rules of the vertebrate classification")
rownames(rules) <- c("r1", "r2", "r3", "r4", "r5")
ruletable <- as.table(rules) 
```

```{r echo = FALSE}
knitr::kable(head(ruletable),
booktabs = TRUE,
  caption = 'Example of a rule set for the vertebrate classification problem.'
)
```
The rules for the model are represented in a disjunctive normal form $R=(r_1 \vee r_2\vee … \vee r_k)$, where $R$ is known as the rule set and $r_i$ are the model rules.
Each rule is expressed in a form of:

\begin{equation} 
r_i:   (Condition_i) →  y_i.
  (\#eq:rule)
\end{equation} 

The left-hand side of the rule is called the **rule antecedent or precondition**. It contains a conjunction of attribute test:

\begin{equation} 
condition_i = (A_1 op v_1 ) ∧ (A_2 op v_2 ) ∧ … ∧(A_k  op v_k ),
  (\#eq:condition)
\end{equation} 

Where $(A_j\quad op \quad v_j )$ is an attribute-value pair and $op$ is a relation operator chosen from the set $ \{ =, ≠, <, >, ≤, ≥ \} $. Each attribute test $(A_j\quad op \quad v_j )$ is known as a conjunct. The right hand of the rule is called the rule consequent which contains the value of conceqencer $y_i$.


### Machine Learning Model

In many applications the relationship between the predictor set and the concequencer is non-deterministic or it is too difficult to either formulate a model or figure out rules by human. In these cases, advanced technologies are used to generate prediction models automatically taking advantage of massive computer storage and fast computation power of distributed and cloud based computing infrastructure. The models used are ether Neural networks  or statistical math models. 

In the machine learning models, different predictive models like regression, decision tree, and decision forest can be utilized and tested to produce a valid prediction. In general, predictive modeling software undertakes a mixture of training data go through number crunching, trial, and error correction and finally produce a working prediction model. During the process of machine generating model human involvement is much less but needed. It enables fine tune the model and improving on its performance. 

Classification is one form of the predictive analysis. In classification the prediction model is called **classifier**. Its input are training dataset, which has the targeted values in it; Its prediction results are class labels, which nrmally is the test dataset, which the atrgeted value is not there. The most commonly sued classifiers are: **Decision trees**, **Random Forest** and **Gaussian Naive Bayes**. 

Titanic problem as we understood is a prediction problem. The prediction on an passenger's death or survive based on train dataset is actually a classification problem. It on ly has two possibilities , it is also called binary classification. Because we only need to classify a passenger either belongs to survived class or perished class.    

## Data Analysis with Decision Trees

A decision tree is the most commonly used classification model, which in a flowchart-like tree structure. In a decision tree, each internal node (non-leaf node) denotes a test on an attribute, each branch represents an outcome of the test, and each leaf node (or terminal node) holds a class label. The topmost node in a tree is the root node. A typical decision tree is shown in Figure \@ref(ref:decisiontree). 


```{r decisiontree, fig.cap ="An example of decision tree", out.width = "50%", fig.align ="center", echo =FALSE}
knitr::include_graphics(here::here("images", "decision tree.png"))

```

It represents the concept buys_computer, that is, it predicts whether a customer is likely to purchase a computer or not. `Yes` is like to buy and `no` is unlikely to buy. Internal nodes are denoted by rectangles are test conditions, and leaf nodes are denoted by ovals, which are the final predictions. Some decision tree produce only branches, where each internal node branches to exactly two other nodes. Others can produce non-binary trees, like `age?` in the above tree has three branches. A prediction for a input data is actually a traverse from the tree root to a tree leaf through different tree branches. 

Decision tree can be built by the tree **induction** which is the learning of decision trees from class-labeled training sets. 

Once a decision tree has been constructed, classifying a test record is straightforward. Starting from the root node, we apply the test condition to the record and follow the appropriate branch based on the outcome of the test. This will lead us either to another internal node, for which a new test condition is applied, or to a leaf node. The class label associated with the leaf node is then assigned to the record. 

### Decision tree for Titanic 

In the Titanic problem, build a decision tree classier needs to make two decisions: 1) which attributes to use for test conditions? 2) and in what order. 

Let’s take a quick review of the possible attributes we could use. Previously we understand that apart from PassengerID, Passenger Name (passenger name has been re-engineered into titles), all other attributes can all be used to do prediction since they all have some power of prediction. 

Let us consider a simple decision tree firstly. The most simple decision tree perhaps is the one only has one internal note and two branches. There are only one attribute meet with the requirements. That is *Sex*, so our decision tree will be build only base on passenger's gender. Here we go, We need a number of liberties to make our code works.


```{r}
library(rpart)
# build our first model. we only use Sex attribute, check help on rpart, 
# this model only takes Sex as predictor and Survived as the consequencer

model <- rpart(Survived ~ Sex, data = train,
              method="class")
```



<!--chapter:end:06-data-analysis.Rmd-->

`r if (knitr:::is_html_output()) '
# Result Interpretation
'`

<!--chapter:end:07-interpretation.Rmd-->

`r if (knitr:::is_html_output()) '
# Data Report
'`

<!--chapter:end:08-Data-Reprot.Rmd-->


# Apendix {-}

Placeholder


## TitanicDataAnalysis_UnderstandData.R {#UnderstandDatacode}

<!--chapter:end:09-refer.Rmd-->

